param_path: param.yaml
num_of_hidden_nodes: 2
learning_rate: 0.1
num_of_training_epochs: 2000
seed: 0
optimizer: GradientDescentOptimizer
train_data_path: ../train_data/normal.npy
forget_bias: 0.25
size_of_mini_batch: 100
num_of_prediction_epochs: 100
num_of_input_nodes: 1
length_of_sequences: 50
num_of_output_nodes: 1
train_data: [[  0.00000000e+00   1.25333234e-01]
 [  1.25333234e-01   2.48689887e-01]
 [  2.48689887e-01   3.68124553e-01]
 ..., 
 [ -3.68124553e-01  -2.48689887e-01]
 [ -2.48689887e-01  -1.25333234e-01]
 [ -1.25333234e-01   3.92877345e-15]]
train#10, train loss: 5.201771e-01
train#20, train loss: 4.967893e-01
train#30, train loss: 5.096368e-01
train#40, train loss: 5.049562e-01
train#50, train loss: 3.755560e-01
train#60, train loss: 2.912572e-01
train#70, train loss: 2.132778e-01
train#80, train loss: 1.174984e-01
train#90, train loss: 9.318598e-02
train#100, train loss: 7.089359e-02
train#110, train loss: 5.989287e-02
train#120, train loss: 4.475670e-02
train#130, train loss: 4.234770e-02
train#140, train loss: 4.064284e-02
train#150, train loss: 3.767524e-02
train#160, train loss: 3.007711e-02
train#170, train loss: 2.940412e-02
train#180, train loss: 2.668960e-02
train#190, train loss: 2.516526e-02
train#200, train loss: 2.672098e-02
train#210, train loss: 1.861860e-02
train#220, train loss: 2.189485e-02
train#230, train loss: 1.712002e-02
train#240, train loss: 2.030127e-02
train#250, train loss: 1.981830e-02
train#260, train loss: 1.479788e-02
train#270, train loss: 1.627491e-02
train#280, train loss: 1.376686e-02
train#290, train loss: 1.457548e-02
train#300, train loss: 1.291362e-02
train#310, train loss: 1.231200e-02
train#320, train loss: 1.279059e-02
train#330, train loss: 1.141859e-02
train#340, train loss: 1.044355e-02
train#350, train loss: 1.061181e-02
train#360, train loss: 1.156256e-02
train#370, train loss: 9.845900e-03
train#380, train loss: 9.616453e-03
train#390, train loss: 8.440644e-03
train#400, train loss: 8.988542e-03
train#410, train loss: 8.400694e-03
train#420, train loss: 6.868336e-03
train#430, train loss: 7.607914e-03
train#440, train loss: 8.414443e-03
train#450, train loss: 9.154273e-03
train#460, train loss: 8.155680e-03
train#470, train loss: 6.562679e-03
train#480, train loss: 7.137899e-03
train#490, train loss: 6.458325e-03
train#500, train loss: 7.083553e-03
train#510, train loss: 5.401069e-03
train#520, train loss: 6.822991e-03
train#530, train loss: 5.569639e-03
train#540, train loss: 5.793858e-03
train#550, train loss: 5.350182e-03
train#560, train loss: 5.078221e-03
train#570, train loss: 5.713339e-03
train#580, train loss: 5.048343e-03
train#590, train loss: 5.014398e-03
train#600, train loss: 4.244421e-03
train#610, train loss: 4.586773e-03
train#620, train loss: 4.278762e-03
train#630, train loss: 4.784607e-03
train#640, train loss: 4.175595e-03
train#650, train loss: 3.997259e-03
train#660, train loss: 3.280425e-03
train#670, train loss: 3.866181e-03
train#680, train loss: 3.693427e-03
train#690, train loss: 3.466688e-03
train#700, train loss: 3.356649e-03
train#710, train loss: 3.373008e-03
train#720, train loss: 3.684253e-03
train#730, train loss: 3.814348e-03
train#740, train loss: 2.797253e-03
train#750, train loss: 2.893071e-03
train#760, train loss: 2.674952e-03
train#770, train loss: 2.721181e-03
train#780, train loss: 2.573795e-03
train#790, train loss: 2.829597e-03
train#800, train loss: 2.970501e-03
train#810, train loss: 2.624249e-03
train#820, train loss: 2.611419e-03
train#830, train loss: 1.837433e-03
train#840, train loss: 2.566428e-03
train#850, train loss: 2.204273e-03
train#860, train loss: 2.348854e-03
train#870, train loss: 2.048641e-03
train#880, train loss: 1.981103e-03
train#890, train loss: 2.219809e-03
train#900, train loss: 1.816873e-03
train#910, train loss: 1.792554e-03
train#920, train loss: 1.884250e-03
train#930, train loss: 1.667076e-03
train#940, train loss: 1.946725e-03
train#950, train loss: 1.898290e-03
train#960, train loss: 1.485794e-03
train#970, train loss: 1.583317e-03
train#980, train loss: 1.949115e-03
train#990, train loss: 1.652022e-03
train#1000, train loss: 1.506951e-03
train#1010, train loss: 1.320929e-03
train#1020, train loss: 1.483200e-03
train#1030, train loss: 1.441616e-03
train#1040, train loss: 1.479485e-03
train#1050, train loss: 1.285232e-03
train#1060, train loss: 1.165509e-03
train#1070, train loss: 1.474262e-03
train#1080, train loss: 1.250870e-03
train#1090, train loss: 1.290414e-03
train#1100, train loss: 1.187855e-03
train#1110, train loss: 1.192872e-03
train#1120, train loss: 1.088336e-03
train#1130, train loss: 1.163050e-03
train#1140, train loss: 1.245021e-03
train#1150, train loss: 1.187947e-03
train#1160, train loss: 9.602741e-04
train#1170, train loss: 1.208169e-03
train#1180, train loss: 9.775966e-04
train#1190, train loss: 1.041225e-03
train#1200, train loss: 1.062893e-03
train#1210, train loss: 1.084285e-03
train#1220, train loss: 1.030752e-03
train#1230, train loss: 1.089612e-03
train#1240, train loss: 9.994049e-04
train#1250, train loss: 8.356859e-04
train#1260, train loss: 1.001631e-03
train#1270, train loss: 1.123763e-03
train#1280, train loss: 1.078475e-03
train#1290, train loss: 8.951253e-04
train#1300, train loss: 9.780213e-04
train#1310, train loss: 9.414551e-04
train#1320, train loss: 1.020209e-03
train#1330, train loss: 7.215983e-04
train#1340, train loss: 9.163698e-04
train#1350, train loss: 7.702075e-04
train#1360, train loss: 7.749319e-04
train#1370, train loss: 7.934783e-04
train#1380, train loss: 7.064015e-04
train#1390, train loss: 7.674545e-04
train#1400, train loss: 8.886762e-04
train#1410, train loss: 7.865192e-04
train#1420, train loss: 7.828519e-04
train#1430, train loss: 8.597333e-04
train#1440, train loss: 7.183959e-04
train#1450, train loss: 8.122556e-04
train#1460, train loss: 7.771183e-04
train#1470, train loss: 6.922259e-04
train#1480, train loss: 7.554961e-04
train#1490, train loss: 6.376571e-04
train#1500, train loss: 7.956247e-04
train#1510, train loss: 6.479334e-04
train#1520, train loss: 6.525628e-04
train#1530, train loss: 5.986020e-04
train#1540, train loss: 5.518831e-04
train#1550, train loss: 7.308370e-04
train#1560, train loss: 6.650460e-04
train#1570, train loss: 7.467389e-04
train#1580, train loss: 7.518069e-04
train#1590, train loss: 6.968817e-04
train#1600, train loss: 6.619921e-04
train#1610, train loss: 6.407209e-04
train#1620, train loss: 6.313023e-04
train#1630, train loss: 6.232744e-04
train#1640, train loss: 5.287650e-04
train#1650, train loss: 5.719169e-04
train#1660, train loss: 4.973921e-04
train#1670, train loss: 6.281632e-04
train#1680, train loss: 6.214746e-04
train#1690, train loss: 6.082769e-04
train#1700, train loss: 6.107624e-04
train#1710, train loss: 6.220830e-04
train#1720, train loss: 5.088801e-04
train#1730, train loss: 5.419332e-04
train#1740, train loss: 5.399913e-04
train#1750, train loss: 6.126843e-04
train#1760, train loss: 5.677098e-04
train#1770, train loss: 5.958669e-04
train#1780, train loss: 5.412746e-04
train#1790, train loss: 5.245751e-04
train#1800, train loss: 5.742644e-04
train#1810, train loss: 5.110112e-04
train#1820, train loss: 4.683191e-04
train#1830, train loss: 4.703271e-04
train#1840, train loss: 5.552942e-04
train#1850, train loss: 5.338634e-04
train#1860, train loss: 5.637392e-04
train#1870, train loss: 4.717704e-04
train#1880, train loss: 5.744794e-04
train#1890, train loss: 5.906571e-04
train#1900, train loss: 5.298546e-04
train#1910, train loss: 4.170573e-04
train#1920, train loss: 5.536969e-04
train#1930, train loss: 5.378084e-04
train#1940, train loss: 5.719551e-04
train#1950, train loss: 4.588985e-04
train#1960, train loss: 5.453640e-04
train#1970, train loss: 4.808704e-04
train#1980, train loss: 6.055503e-04
train#1990, train loss: 4.717965e-04
train#2000, train loss: 4.299553e-04
losses: [[  1.00000000e+01   5.20177066e-01]
 [  2.00000000e+01   4.96789336e-01]
 [  3.00000000e+01   5.09636819e-01]
 [  4.00000000e+01   5.04956186e-01]
 [  5.00000000e+01   3.75555962e-01]
 [  6.00000000e+01   2.91257203e-01]
 [  7.00000000e+01   2.13277772e-01]
 [  8.00000000e+01   1.17498398e-01]
 [  9.00000000e+01   9.31859761e-02]
 [  1.00000000e+02   7.08935857e-02]
 [  1.10000000e+02   5.98928742e-02]
 [  1.20000000e+02   4.47566994e-02]
 [  1.30000000e+02   4.23476994e-02]
 [  1.40000000e+02   4.06428352e-02]
 [  1.50000000e+02   3.76752391e-02]
 [  1.60000000e+02   3.00771110e-02]
 [  1.70000000e+02   2.94041205e-02]
 [  1.80000000e+02   2.66896002e-02]
 [  1.90000000e+02   2.51652580e-02]
 [  2.00000000e+02   2.67209820e-02]
 [  2.10000000e+02   1.86185986e-02]
 [  2.20000000e+02   2.18948480e-02]
 [  2.30000000e+02   1.71200167e-02]
 [  2.40000000e+02   2.03012750e-02]
 [  2.50000000e+02   1.98183041e-02]
 [  2.60000000e+02   1.47978831e-02]
 [  2.70000000e+02   1.62749123e-02]
 [  2.80000000e+02   1.37668634e-02]
 [  2.90000000e+02   1.45754768e-02]
 [  3.00000000e+02   1.29136201e-02]
 [  3.10000000e+02   1.23119950e-02]
 [  3.20000000e+02   1.27905915e-02]
 [  3.30000000e+02   1.14185950e-02]
 [  3.40000000e+02   1.04435543e-02]
 [  3.50000000e+02   1.06118079e-02]
 [  3.60000000e+02   1.15625644e-02]
 [  3.70000000e+02   9.84590035e-03]
 [  3.80000000e+02   9.61645320e-03]
 [  3.90000000e+02   8.44064448e-03]
 [  4.00000000e+02   8.98854248e-03]
 [  4.10000000e+02   8.40069447e-03]
 [  4.20000000e+02   6.86833635e-03]
 [  4.30000000e+02   7.60791404e-03]
 [  4.40000000e+02   8.41444265e-03]
 [  4.50000000e+02   9.15427320e-03]
 [  4.60000000e+02   8.15568026e-03]
 [  4.70000000e+02   6.56267861e-03]
 [  4.80000000e+02   7.13789929e-03]
 [  4.90000000e+02   6.45832531e-03]
 [  5.00000000e+02   7.08355289e-03]
 [  5.10000000e+02   5.40106883e-03]
 [  5.20000000e+02   6.82299072e-03]
 [  5.30000000e+02   5.56963915e-03]
 [  5.40000000e+02   5.79385832e-03]
 [  5.50000000e+02   5.35018183e-03]
 [  5.60000000e+02   5.07822074e-03]
 [  5.70000000e+02   5.71333896e-03]
 [  5.80000000e+02   5.04834298e-03]
 [  5.90000000e+02   5.01439814e-03]
 [  6.00000000e+02   4.24442114e-03]
 [  6.10000000e+02   4.58677253e-03]
 [  6.20000000e+02   4.27876227e-03]
 [  6.30000000e+02   4.78460733e-03]
 [  6.40000000e+02   4.17559454e-03]
 [  6.50000000e+02   3.99725931e-03]
 [  6.60000000e+02   3.28042475e-03]
 [  6.70000000e+02   3.86618148e-03]
 [  6.80000000e+02   3.69342696e-03]
 [  6.90000000e+02   3.46668786e-03]
 [  7.00000000e+02   3.35664931e-03]
 [  7.10000000e+02   3.37300776e-03]
 [  7.20000000e+02   3.68425250e-03]
 [  7.30000000e+02   3.81434849e-03]
 [  7.40000000e+02   2.79725343e-03]
 [  7.50000000e+02   2.89307069e-03]
 [  7.60000000e+02   2.67495215e-03]
 [  7.70000000e+02   2.72118091e-03]
 [  7.80000000e+02   2.57379538e-03]
 [  7.90000000e+02   2.82959663e-03]
 [  8.00000000e+02   2.97050108e-03]
 [  8.10000000e+02   2.62424862e-03]
 [  8.20000000e+02   2.61141895e-03]
 [  8.30000000e+02   1.83743250e-03]
 [  8.40000000e+02   2.56642769e-03]
 [  8.50000000e+02   2.20427313e-03]
 [  8.60000000e+02   2.34885397e-03]
 [  8.70000000e+02   2.04864074e-03]
 [  8.80000000e+02   1.98110333e-03]
 [  8.90000000e+02   2.21980852e-03]
 [  9.00000000e+02   1.81687286e-03]
 [  9.10000000e+02   1.79255439e-03]
 [  9.20000000e+02   1.88425032e-03]
 [  9.30000000e+02   1.66707626e-03]
 [  9.40000000e+02   1.94672495e-03]
 [  9.50000000e+02   1.89828989e-03]
 [  9.60000000e+02   1.48579408e-03]
 [  9.70000000e+02   1.58331718e-03]
 [  9.80000000e+02   1.94911461e-03]
 [  9.90000000e+02   1.65202236e-03]
 [  1.00000000e+03   1.50695082e-03]
 [  1.01000000e+03   1.32092892e-03]
 [  1.02000000e+03   1.48320047e-03]
 [  1.03000000e+03   1.44161610e-03]
 [  1.04000000e+03   1.47948531e-03]
 [  1.05000000e+03   1.28523167e-03]
 [  1.06000000e+03   1.16550864e-03]
 [  1.07000000e+03   1.47426222e-03]
 [  1.08000000e+03   1.25087018e-03]
 [  1.09000000e+03   1.29041355e-03]
 [  1.10000000e+03   1.18785549e-03]
 [  1.11000000e+03   1.19287195e-03]
 [  1.12000000e+03   1.08833576e-03]
 [  1.13000000e+03   1.16305007e-03]
 [  1.14000000e+03   1.24502112e-03]
 [  1.15000000e+03   1.18794665e-03]
 [  1.16000000e+03   9.60274134e-04]
 [  1.17000000e+03   1.20816904e-03]
 [  1.18000000e+03   9.77596617e-04]
 [  1.19000000e+03   1.04122504e-03]
 [  1.20000000e+03   1.06289284e-03]
 [  1.21000000e+03   1.08428497e-03]
 [  1.22000000e+03   1.03075232e-03]
 [  1.23000000e+03   1.08961167e-03]
 [  1.24000000e+03   9.99404932e-04]
 [  1.25000000e+03   8.35685874e-04]
 [  1.26000000e+03   1.00163068e-03]
 [  1.27000000e+03   1.12376316e-03]
 [  1.28000000e+03   1.07847457e-03]
 [  1.29000000e+03   8.95125268e-04]
 [  1.30000000e+03   9.78021300e-04]
 [  1.31000000e+03   9.41455131e-04]
 [  1.32000000e+03   1.02020858e-03]
 [  1.33000000e+03   7.21598277e-04]
 [  1.34000000e+03   9.16369841e-04]
 [  1.35000000e+03   7.70207494e-04]
 [  1.36000000e+03   7.74931861e-04]
 [  1.37000000e+03   7.93478335e-04]
 [  1.38000000e+03   7.06401479e-04]
 [  1.39000000e+03   7.67454505e-04]
 [  1.40000000e+03   8.88676208e-04]
 [  1.41000000e+03   7.86519202e-04]
 [  1.42000000e+03   7.82851886e-04]
 [  1.43000000e+03   8.59733322e-04]
 [  1.44000000e+03   7.18395866e-04]
 [  1.45000000e+03   8.12255603e-04]
 [  1.46000000e+03   7.77118257e-04]
 [  1.47000000e+03   6.92225934e-04]
 [  1.48000000e+03   7.55496090e-04]
 [  1.49000000e+03   6.37657067e-04]
 [  1.50000000e+03   7.95624685e-04]
 [  1.51000000e+03   6.47933397e-04]
 [  1.52000000e+03   6.52562769e-04]
 [  1.53000000e+03   5.98601997e-04]
 [  1.54000000e+03   5.51883131e-04]
 [  1.55000000e+03   7.30836997e-04]
 [  1.56000000e+03   6.65045984e-04]
 [  1.57000000e+03   7.46738864e-04]
 [  1.58000000e+03   7.51806947e-04]
 [  1.59000000e+03   6.96881732e-04]
 [  1.60000000e+03   6.61992119e-04]
 [  1.61000000e+03   6.40720944e-04]
 [  1.62000000e+03   6.31302304e-04]
 [  1.63000000e+03   6.23274420e-04]
 [  1.64000000e+03   5.28764969e-04]
 [  1.65000000e+03   5.71916869e-04]
 [  1.66000000e+03   4.97392146e-04]
 [  1.67000000e+03   6.28163165e-04]
 [  1.68000000e+03   6.21474581e-04]
 [  1.69000000e+03   6.08276925e-04]
 [  1.70000000e+03   6.10762392e-04]
 [  1.71000000e+03   6.22082967e-04]
 [  1.72000000e+03   5.08880068e-04]
 [  1.73000000e+03   5.41933172e-04]
 [  1.74000000e+03   5.39991306e-04]
 [  1.75000000e+03   6.12684293e-04]
 [  1.76000000e+03   5.67709794e-04]
 [  1.77000000e+03   5.95866935e-04]
 [  1.78000000e+03   5.41274552e-04]
 [  1.79000000e+03   5.24575065e-04]
 [  1.80000000e+03   5.74264443e-04]
 [  1.81000000e+03   5.11011167e-04]
 [  1.82000000e+03   4.68319107e-04]
 [  1.83000000e+03   4.70327068e-04]
 [  1.84000000e+03   5.55294217e-04]
 [  1.85000000e+03   5.33863436e-04]
 [  1.86000000e+03   5.63739159e-04]
 [  1.87000000e+03   4.71770385e-04]
 [  1.88000000e+03   5.74479403e-04]
 [  1.89000000e+03   5.90657059e-04]
 [  1.90000000e+03   5.29854617e-04]
 [  1.91000000e+03   4.17057337e-04]
 [  1.92000000e+03   5.53696940e-04]
 [  1.93000000e+03   5.37808402e-04]
 [  1.94000000e+03   5.71955112e-04]
 [  1.95000000e+03   4.58898459e-04]
 [  1.96000000e+03   5.45363990e-04]
 [  1.97000000e+03   4.80870367e-04]
 [  1.98000000e+03   6.05550304e-04]
 [  1.99000000e+03   4.71796462e-04]
 [  2.00000000e+03   4.29955282e-04]]
initial: [  0.00000000e+00   1.25333234e-01   2.48689887e-01   3.68124553e-01
   4.81753674e-01   5.87785252e-01   6.84547106e-01   7.70513243e-01
   8.44327926e-01   9.04827052e-01   9.51056516e-01   9.82287251e-01
   9.98026728e-01   9.98026728e-01   9.82287251e-01   9.51056516e-01
   9.04827052e-01   8.44327926e-01   7.70513243e-01   6.84547106e-01
   5.87785252e-01   4.81753674e-01   3.68124553e-01   2.48689887e-01
   1.25333234e-01  -3.21624530e-16  -1.25333234e-01  -2.48689887e-01
  -3.68124553e-01  -4.81753674e-01  -5.87785252e-01  -6.84547106e-01
  -7.70513243e-01  -8.44327926e-01  -9.04827052e-01  -9.51056516e-01
  -9.82287251e-01  -9.98026728e-01  -9.98026728e-01  -9.82287251e-01
  -9.51056516e-01  -9.04827052e-01  -8.44327926e-01  -7.70513243e-01
  -6.84547106e-01  -5.87785252e-01  -4.81753674e-01  -3.68124553e-01
  -2.48689887e-01  -1.25333234e-01]
prediction#1, output: 0.014285
prediction#2, output: 0.169484
prediction#3, output: 0.344209
prediction#4, output: 0.531247
prediction#5, output: 0.709421
prediction#6, output: 0.850019
prediction#7, output: 0.936880
prediction#8, output: 0.975929
prediction#9, output: 0.982446
prediction#10, output: 0.968998
prediction#11, output: 0.943566
prediction#12, output: 0.910989
prediction#13, output: 0.874225
prediction#14, output: 0.835110
prediction#15, output: 0.794800
prediction#16, output: 0.754025
prediction#17, output: 0.713235
prediction#18, output: 0.672700
prediction#19, output: 0.632562
prediction#20, output: 0.592875
prediction#21, output: 0.553626
prediction#22, output: 0.514750
prediction#23, output: 0.476136
prediction#24, output: 0.437636
prediction#25, output: 0.399058
prediction#26, output: 0.360169
prediction#27, output: 0.320689
prediction#28, output: 0.280286
prediction#29, output: 0.238571
prediction#30, output: 0.195089
prediction#31, output: 0.149330
prediction#32, output: 0.100727
prediction#33, output: 0.048693
prediction#34, output: -0.007332
prediction#35, output: -0.067786
prediction#36, output: -0.132848
prediction#37, output: -0.202248
prediction#38, output: -0.275064
prediction#39, output: -0.349581
prediction#40, output: -0.423308
prediction#41, output: -0.493254
prediction#42, output: -0.556451
prediction#43, output: -0.610555
prediction#44, output: -0.654270
prediction#45, output: -0.687447
prediction#46, output: -0.710876
prediction#47, output: -0.725917
prediction#48, output: -0.734151
prediction#49, output: -0.737123
prediction#50, output: -0.736203
prediction#51, output: -0.732524
prediction#52, output: -0.726987
prediction#53, output: -0.720286
prediction#54, output: -0.712938
prediction#55, output: -0.705322
prediction#56, output: -0.697710
prediction#57, output: -0.690294
prediction#58, output: -0.683202
prediction#59, output: -0.676516
prediction#60, output: -0.670287
prediction#61, output: -0.664541
prediction#62, output: -0.659284
prediction#63, output: -0.654510
prediction#64, output: -0.650207
prediction#65, output: -0.646353
prediction#66, output: -0.642925
prediction#67, output: -0.639894
prediction#68, output: -0.637233
prediction#69, output: -0.634914
prediction#70, output: -0.632906
prediction#71, output: -0.631182
prediction#72, output: -0.629715
prediction#73, output: -0.628478
prediction#74, output: -0.627447
prediction#75, output: -0.626599
prediction#76, output: -0.625912
prediction#77, output: -0.625366
prediction#78, output: -0.624942
prediction#79, output: -0.624624
prediction#80, output: -0.624395
prediction#81, output: -0.624243
prediction#82, output: -0.624155
prediction#83, output: -0.624119
prediction#84, output: -0.624125
prediction#85, output: -0.624165
prediction#86, output: -0.624232
prediction#87, output: -0.624318
prediction#88, output: -0.624419
prediction#89, output: -0.624529
prediction#90, output: -0.624645
prediction#91, output: -0.624763
prediction#92, output: -0.624882
prediction#93, output: -0.624997
prediction#94, output: -0.625109
prediction#95, output: -0.625215
prediction#96, output: -0.625315
prediction#97, output: -0.625409
prediction#98, output: -0.625495
prediction#99, output: -0.625574
prediction#100, output: -0.625646
outputs: [ 0.01428467  0.1694836   0.34420919  0.53124654  0.70942104  0.85001886
  0.93688023  0.9759289   0.98244596  0.96899819  0.94356585  0.91098893
  0.87422454  0.83510983  0.79480034  0.75402451  0.71323466  0.67269951
  0.63256192  0.59287524  0.55362636  0.51474988  0.47613645  0.43763581
  0.3990576   0.3601687   0.32068911  0.28028649  0.23857057  0.19508937
  0.14932959  0.10072708  0.04869321 -0.00733167 -0.0677864  -0.13284847
 -0.20224753 -0.27506354 -0.34958073 -0.42330757 -0.49325356 -0.5564512
 -0.61055481 -0.6542697  -0.68744743 -0.71087635 -0.7259171  -0.73415101
 -0.73712337 -0.7362026  -0.73252356 -0.72698724 -0.72028589 -0.71293759
 -0.70532167 -0.69771028 -0.69029391 -0.68320155 -0.67651618 -0.67028749
 -0.66454089 -0.65928364 -0.65451038 -0.65020728 -0.64635348 -0.6429249
 -0.63989437 -0.6372335  -0.63491356 -0.63290572 -0.63118184 -0.62971473
 -0.62847793 -0.62744713 -0.62659895 -0.62591183 -0.62536561 -0.62494195
 -0.62462366 -0.62439549 -0.62424338 -0.62415481 -0.62411857 -0.62412488
 -0.62416518 -0.6242317  -0.624318   -0.62441885 -0.62452924 -0.62464523
 -0.62476337 -0.62488163 -0.62499714 -0.62510872 -0.62521517 -0.62531519
 -0.62540877 -0.6254952  -0.62557411 -0.62564576]

real	4m27.725s
user	2m41.816s
sys	3m50.489s
