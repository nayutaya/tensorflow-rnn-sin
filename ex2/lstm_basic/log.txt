param_path: param.yaml
num_of_output_nodes: 1
train_data_path: ../train_data/normal.npy
num_of_hidden_nodes: 2
seed: 0
num_of_prediction_epochs: 100
optimizer: GradientDescentOptimizer
forget_bias: 1.0
learning_rate: 0.1
num_of_input_nodes: 1
size_of_mini_batch: 100
length_of_sequences: 50
num_of_training_epochs: 2000
train_data: [[  0.00000000e+00   1.25333234e-01]
 [  1.25333234e-01   2.48689887e-01]
 [  2.48689887e-01   3.68124553e-01]
 ..., 
 [ -3.68124553e-01  -2.48689887e-01]
 [ -2.48689887e-01  -1.25333234e-01]
 [ -1.25333234e-01   3.92877345e-15]]
train#10, train loss: 5.237434e-01
train#20, train loss: 4.948913e-01
train#30, train loss: 4.987105e-01
train#40, train loss: 4.678741e-01
train#50, train loss: 3.104841e-01
train#60, train loss: 2.221957e-01
train#70, train loss: 1.638018e-01
train#80, train loss: 8.901013e-02
train#90, train loss: 6.872350e-02
train#100, train loss: 5.472891e-02
train#110, train loss: 4.631434e-02
train#120, train loss: 3.396133e-02
train#130, train loss: 3.412957e-02
train#140, train loss: 3.252294e-02
train#150, train loss: 2.568328e-02
train#160, train loss: 2.233965e-02
train#170, train loss: 2.264171e-02
train#180, train loss: 2.087775e-02
train#190, train loss: 1.723391e-02
train#200, train loss: 1.999823e-02
train#210, train loss: 1.350019e-02
train#220, train loss: 1.450247e-02
train#230, train loss: 1.197545e-02
train#240, train loss: 1.304017e-02
train#250, train loss: 1.170931e-02
train#260, train loss: 1.089160e-02
train#270, train loss: 1.055024e-02
train#280, train loss: 8.839828e-03
train#290, train loss: 7.256823e-03
train#300, train loss: 7.825033e-03
train#310, train loss: 7.674092e-03
train#320, train loss: 7.348606e-03
train#330, train loss: 6.079764e-03
train#340, train loss: 5.743842e-03
train#350, train loss: 4.584024e-03
train#360, train loss: 6.282428e-03
train#370, train loss: 5.288947e-03
train#380, train loss: 4.987182e-03
train#390, train loss: 5.197642e-03
train#400, train loss: 4.776262e-03
train#410, train loss: 4.622184e-03
train#420, train loss: 3.799458e-03
train#430, train loss: 3.914041e-03
train#440, train loss: 3.404761e-03
train#450, train loss: 3.790077e-03
train#460, train loss: 3.243015e-03
train#470, train loss: 2.857479e-03
train#480, train loss: 2.980915e-03
train#490, train loss: 3.062394e-03
train#500, train loss: 2.921604e-03
train#510, train loss: 2.399136e-03
train#520, train loss: 2.930292e-03
train#530, train loss: 2.292558e-03
train#540, train loss: 2.458153e-03
train#550, train loss: 2.797390e-03
train#560, train loss: 2.724117e-03
train#570, train loss: 2.077252e-03
train#580, train loss: 2.327539e-03
train#590, train loss: 1.935804e-03
train#600, train loss: 2.194517e-03
train#610, train loss: 1.851825e-03
train#620, train loss: 2.115652e-03
train#630, train loss: 1.607610e-03
train#640, train loss: 1.910482e-03
train#650, train loss: 1.709675e-03
train#660, train loss: 1.751863e-03
train#670, train loss: 1.701466e-03
train#680, train loss: 1.736063e-03
train#690, train loss: 1.499393e-03
train#700, train loss: 1.673124e-03
train#710, train loss: 1.611779e-03
train#720, train loss: 1.636230e-03
train#730, train loss: 1.534467e-03
train#740, train loss: 1.347119e-03
train#750, train loss: 1.375984e-03
train#760, train loss: 1.421066e-03
train#770, train loss: 1.100417e-03
train#780, train loss: 1.105909e-03
train#790, train loss: 1.036938e-03
train#800, train loss: 1.106930e-03
train#810, train loss: 1.127601e-03
train#820, train loss: 1.364999e-03
train#830, train loss: 1.134219e-03
train#840, train loss: 9.829572e-04
train#850, train loss: 1.278791e-03
train#860, train loss: 1.184867e-03
train#870, train loss: 9.789199e-04
train#880, train loss: 9.167587e-04
train#890, train loss: 1.051030e-03
train#900, train loss: 8.410297e-04
train#910, train loss: 1.029545e-03
train#920, train loss: 1.093489e-03
train#930, train loss: 9.215967e-04
train#940, train loss: 1.012604e-03
train#950, train loss: 1.154914e-03
train#960, train loss: 9.410281e-04
train#970, train loss: 8.486807e-04
train#980, train loss: 1.090334e-03
train#990, train loss: 9.631361e-04
train#1000, train loss: 8.697314e-04
train#1010, train loss: 8.629766e-04
train#1020, train loss: 8.629535e-04
train#1030, train loss: 9.101632e-04
train#1040, train loss: 7.927481e-04
train#1050, train loss: 6.912824e-04
train#1060, train loss: 8.196633e-04
train#1070, train loss: 1.012098e-03
train#1080, train loss: 8.391845e-04
train#1090, train loss: 8.106472e-04
train#1100, train loss: 8.243609e-04
train#1110, train loss: 7.714970e-04
train#1120, train loss: 7.181689e-04
train#1130, train loss: 7.483908e-04
train#1140, train loss: 8.131532e-04
train#1150, train loss: 7.957825e-04
train#1160, train loss: 7.083161e-04
train#1170, train loss: 8.583441e-04
train#1180, train loss: 7.618588e-04
train#1190, train loss: 6.876287e-04
train#1200, train loss: 6.930295e-04
train#1210, train loss: 7.871201e-04
train#1220, train loss: 7.174773e-04
train#1230, train loss: 7.333168e-04
train#1240, train loss: 6.983754e-04
train#1250, train loss: 5.908588e-04
train#1260, train loss: 7.151892e-04
train#1270, train loss: 6.957434e-04
train#1280, train loss: 7.398180e-04
train#1290, train loss: 6.646618e-04
train#1300, train loss: 6.965947e-04
train#1310, train loss: 6.921984e-04
train#1320, train loss: 7.593161e-04
train#1330, train loss: 5.945484e-04
train#1340, train loss: 6.825064e-04
train#1350, train loss: 6.269377e-04
train#1360, train loss: 6.006353e-04
train#1370, train loss: 6.606839e-04
train#1380, train loss: 5.901381e-04
train#1390, train loss: 5.266108e-04
train#1400, train loss: 6.477021e-04
train#1410, train loss: 6.223155e-04
train#1420, train loss: 5.849630e-04
train#1430, train loss: 6.453970e-04
train#1440, train loss: 5.385769e-04
train#1450, train loss: 6.739915e-04
train#1460, train loss: 6.468795e-04
train#1470, train loss: 5.670784e-04
train#1480, train loss: 6.499336e-04
train#1490, train loss: 4.967768e-04
train#1500, train loss: 6.830679e-04
train#1510, train loss: 5.705743e-04
train#1520, train loss: 5.603872e-04
train#1530, train loss: 4.901650e-04
train#1540, train loss: 4.753332e-04
train#1550, train loss: 5.719775e-04
train#1560, train loss: 5.735338e-04
train#1570, train loss: 5.917877e-04
train#1580, train loss: 6.056090e-04
train#1590, train loss: 5.469828e-04
train#1600, train loss: 5.455596e-04
train#1610, train loss: 5.219230e-04
train#1620, train loss: 5.574342e-04
train#1630, train loss: 5.205588e-04
train#1640, train loss: 4.590003e-04
train#1650, train loss: 5.128484e-04
train#1660, train loss: 4.487028e-04
train#1670, train loss: 5.207814e-04
train#1680, train loss: 4.899200e-04
train#1690, train loss: 4.967019e-04
train#1700, train loss: 5.072826e-04
train#1710, train loss: 5.134289e-04
train#1720, train loss: 4.799640e-04
train#1730, train loss: 4.098425e-04
train#1740, train loss: 4.502310e-04
train#1750, train loss: 5.129410e-04
train#1760, train loss: 5.063143e-04
train#1770, train loss: 5.024049e-04
train#1780, train loss: 4.511791e-04
train#1790, train loss: 4.848480e-04
train#1800, train loss: 5.062069e-04
train#1810, train loss: 4.480274e-04
train#1820, train loss: 3.956865e-04
train#1830, train loss: 4.231300e-04
train#1840, train loss: 4.852513e-04
train#1850, train loss: 4.705099e-04
train#1860, train loss: 4.705607e-04
train#1870, train loss: 4.034820e-04
train#1880, train loss: 5.130002e-04
train#1890, train loss: 4.639591e-04
train#1900, train loss: 4.725382e-04
train#1910, train loss: 3.776360e-04
train#1920, train loss: 4.815491e-04
train#1930, train loss: 4.462463e-04
train#1940, train loss: 4.905290e-04
train#1950, train loss: 4.036356e-04
train#1960, train loss: 4.580884e-04
train#1970, train loss: 4.285215e-04
train#1980, train loss: 5.183602e-04
train#1990, train loss: 4.144756e-04
train#2000, train loss: 3.565143e-04
losses: [[  1.00000000e+01   5.23743391e-01]
 [  2.00000000e+01   4.94891286e-01]
 [  3.00000000e+01   4.98710543e-01]
 [  4.00000000e+01   4.67874080e-01]
 [  5.00000000e+01   3.10484111e-01]
 [  6.00000000e+01   2.22195715e-01]
 [  7.00000000e+01   1.63801759e-01]
 [  8.00000000e+01   8.90101269e-02]
 [  9.00000000e+01   6.87234998e-02]
 [  1.00000000e+02   5.47289141e-02]
 [  1.10000000e+02   4.63143401e-02]
 [  1.20000000e+02   3.39613333e-02]
 [  1.30000000e+02   3.41295712e-02]
 [  1.40000000e+02   3.25229391e-02]
 [  1.50000000e+02   2.56832838e-02]
 [  1.60000000e+02   2.23396495e-02]
 [  1.70000000e+02   2.26417109e-02]
 [  1.80000000e+02   2.08777469e-02]
 [  1.90000000e+02   1.72339063e-02]
 [  2.00000000e+02   1.99982319e-02]
 [  2.10000000e+02   1.35001875e-02]
 [  2.20000000e+02   1.45024657e-02]
 [  2.30000000e+02   1.19754495e-02]
 [  2.40000000e+02   1.30401673e-02]
 [  2.50000000e+02   1.17093120e-02]
 [  2.60000000e+02   1.08915996e-02]
 [  2.70000000e+02   1.05502419e-02]
 [  2.80000000e+02   8.83982796e-03]
 [  2.90000000e+02   7.25682266e-03]
 [  3.00000000e+02   7.82503281e-03]
 [  3.10000000e+02   7.67409196e-03]
 [  3.20000000e+02   7.34860636e-03]
 [  3.30000000e+02   6.07976364e-03]
 [  3.40000000e+02   5.74384211e-03]
 [  3.50000000e+02   4.58402419e-03]
 [  3.60000000e+02   6.28242828e-03]
 [  3.70000000e+02   5.28894737e-03]
 [  3.80000000e+02   4.98718210e-03]
 [  3.90000000e+02   5.19764191e-03]
 [  4.00000000e+02   4.77626221e-03]
 [  4.10000000e+02   4.62218421e-03]
 [  4.20000000e+02   3.79945850e-03]
 [  4.30000000e+02   3.91404144e-03]
 [  4.40000000e+02   3.40476073e-03]
 [  4.50000000e+02   3.79007705e-03]
 [  4.60000000e+02   3.24301491e-03]
 [  4.70000000e+02   2.85747857e-03]
 [  4.80000000e+02   2.98091536e-03]
 [  4.90000000e+02   3.06239421e-03]
 [  5.00000000e+02   2.92160432e-03]
 [  5.10000000e+02   2.39913561e-03]
 [  5.20000000e+02   2.93029239e-03]
 [  5.30000000e+02   2.29255785e-03]
 [  5.40000000e+02   2.45815283e-03]
 [  5.50000000e+02   2.79739033e-03]
 [  5.60000000e+02   2.72411737e-03]
 [  5.70000000e+02   2.07725167e-03]
 [  5.80000000e+02   2.32753926e-03]
 [  5.90000000e+02   1.93580415e-03]
 [  6.00000000e+02   2.19451729e-03]
 [  6.10000000e+02   1.85182493e-03]
 [  6.20000000e+02   2.11565173e-03]
 [  6.30000000e+02   1.60761003e-03]
 [  6.40000000e+02   1.91048207e-03]
 [  6.50000000e+02   1.70967472e-03]
 [  6.60000000e+02   1.75186340e-03]
 [  6.70000000e+02   1.70146569e-03]
 [  6.80000000e+02   1.73606281e-03]
 [  6.90000000e+02   1.49939326e-03]
 [  7.00000000e+02   1.67312380e-03]
 [  7.10000000e+02   1.61177921e-03]
 [  7.20000000e+02   1.63622957e-03]
 [  7.30000000e+02   1.53446663e-03]
 [  7.40000000e+02   1.34711864e-03]
 [  7.50000000e+02   1.37598393e-03]
 [  7.60000000e+02   1.42106565e-03]
 [  7.70000000e+02   1.10041664e-03]
 [  7.80000000e+02   1.10590877e-03]
 [  7.90000000e+02   1.03693840e-03]
 [  8.00000000e+02   1.10693031e-03]
 [  8.10000000e+02   1.12760079e-03]
 [  8.20000000e+02   1.36499945e-03]
 [  8.30000000e+02   1.13421946e-03]
 [  8.40000000e+02   9.82957194e-04]
 [  8.50000000e+02   1.27879053e-03]
 [  8.60000000e+02   1.18486723e-03]
 [  8.70000000e+02   9.78919910e-04]
 [  8.80000000e+02   9.16758727e-04]
 [  8.90000000e+02   1.05102966e-03]
 [  9.00000000e+02   8.41029745e-04]
 [  9.10000000e+02   1.02954498e-03]
 [  9.20000000e+02   1.09348923e-03]
 [  9.30000000e+02   9.21596715e-04]
 [  9.40000000e+02   1.01260410e-03]
 [  9.50000000e+02   1.15491415e-03]
 [  9.60000000e+02   9.41028120e-04]
 [  9.70000000e+02   8.48680735e-04]
 [  9.80000000e+02   1.09033380e-03]
 [  9.90000000e+02   9.63136088e-04]
 [  1.00000000e+03   8.69731361e-04]
 [  1.01000000e+03   8.62976594e-04]
 [  1.02000000e+03   8.62953486e-04]
 [  1.03000000e+03   9.10163217e-04]
 [  1.04000000e+03   7.92748062e-04]
 [  1.05000000e+03   6.91282446e-04]
 [  1.06000000e+03   8.19663343e-04]
 [  1.07000000e+03   1.01209793e-03]
 [  1.08000000e+03   8.39184504e-04]
 [  1.09000000e+03   8.10647151e-04]
 [  1.10000000e+03   8.24360875e-04]
 [  1.11000000e+03   7.71496969e-04]
 [  1.12000000e+03   7.18168856e-04]
 [  1.13000000e+03   7.48390798e-04]
 [  1.14000000e+03   8.13153223e-04]
 [  1.15000000e+03   7.95782486e-04]
 [  1.16000000e+03   7.08316104e-04]
 [  1.17000000e+03   8.58344138e-04]
 [  1.18000000e+03   7.61858828e-04]
 [  1.19000000e+03   6.87628693e-04]
 [  1.20000000e+03   6.93029491e-04]
 [  1.21000000e+03   7.87120138e-04]
 [  1.22000000e+03   7.17477349e-04]
 [  1.23000000e+03   7.33316760e-04]
 [  1.24000000e+03   6.98375399e-04]
 [  1.25000000e+03   5.90858806e-04]
 [  1.26000000e+03   7.15189206e-04]
 [  1.27000000e+03   6.95743365e-04]
 [  1.28000000e+03   7.39817973e-04]
 [  1.29000000e+03   6.64661813e-04]
 [  1.30000000e+03   6.96594710e-04]
 [  1.31000000e+03   6.92198402e-04]
 [  1.32000000e+03   7.59316084e-04]
 [  1.33000000e+03   5.94548357e-04]
 [  1.34000000e+03   6.82506361e-04]
 [  1.35000000e+03   6.26937719e-04]
 [  1.36000000e+03   6.00635307e-04]
 [  1.37000000e+03   6.60683902e-04]
 [  1.38000000e+03   5.90138137e-04]
 [  1.39000000e+03   5.26610762e-04]
 [  1.40000000e+03   6.47702080e-04]
 [  1.41000000e+03   6.22315507e-04]
 [  1.42000000e+03   5.84963011e-04]
 [  1.43000000e+03   6.45396998e-04]
 [  1.44000000e+03   5.38576860e-04]
 [  1.45000000e+03   6.73991453e-04]
 [  1.46000000e+03   6.46879547e-04]
 [  1.47000000e+03   5.67078358e-04]
 [  1.48000000e+03   6.49933645e-04]
 [  1.49000000e+03   4.96776833e-04]
 [  1.50000000e+03   6.83067890e-04]
 [  1.51000000e+03   5.70574310e-04]
 [  1.52000000e+03   5.60387212e-04]
 [  1.53000000e+03   4.90164966e-04]
 [  1.54000000e+03   4.75333189e-04]
 [  1.55000000e+03   5.71977522e-04]
 [  1.56000000e+03   5.73533820e-04]
 [  1.57000000e+03   5.91787684e-04]
 [  1.58000000e+03   6.05609035e-04]
 [  1.59000000e+03   5.46982803e-04]
 [  1.60000000e+03   5.45559626e-04]
 [  1.61000000e+03   5.21923008e-04]
 [  1.62000000e+03   5.57434163e-04]
 [  1.63000000e+03   5.20558795e-04]
 [  1.64000000e+03   4.59000323e-04]
 [  1.65000000e+03   5.12848434e-04]
 [  1.66000000e+03   4.48702805e-04]
 [  1.67000000e+03   5.20781381e-04]
 [  1.68000000e+03   4.89920028e-04]
 [  1.69000000e+03   4.96701919e-04]
 [  1.70000000e+03   5.07282617e-04]
 [  1.71000000e+03   5.13428880e-04]
 [  1.72000000e+03   4.79963957e-04]
 [  1.73000000e+03   4.09842498e-04]
 [  1.74000000e+03   4.50230989e-04]
 [  1.75000000e+03   5.12941042e-04]
 [  1.76000000e+03   5.06314274e-04]
 [  1.77000000e+03   5.02404931e-04]
 [  1.78000000e+03   4.51179076e-04]
 [  1.79000000e+03   4.84848017e-04]
 [  1.80000000e+03   5.06206881e-04]
 [  1.81000000e+03   4.48027393e-04]
 [  1.82000000e+03   3.95686482e-04]
 [  1.83000000e+03   4.23130026e-04]
 [  1.84000000e+03   4.85251279e-04]
 [  1.85000000e+03   4.70509898e-04]
 [  1.86000000e+03   4.70560743e-04]
 [  1.87000000e+03   4.03481972e-04]
 [  1.88000000e+03   5.13000181e-04]
 [  1.89000000e+03   4.63959062e-04]
 [  1.90000000e+03   4.72538173e-04]
 [  1.91000000e+03   3.77635966e-04]
 [  1.92000000e+03   4.81549097e-04]
 [  1.93000000e+03   4.46246297e-04]
 [  1.94000000e+03   4.90528997e-04]
 [  1.95000000e+03   4.03635611e-04]
 [  1.96000000e+03   4.58088354e-04]
 [  1.97000000e+03   4.28521482e-04]
 [  1.98000000e+03   5.18360233e-04]
 [  1.99000000e+03   4.14475566e-04]
 [  2.00000000e+03   3.56514269e-04]]
initial: [  0.00000000e+00   1.25333234e-01   2.48689887e-01   3.68124553e-01
   4.81753674e-01   5.87785252e-01   6.84547106e-01   7.70513243e-01
   8.44327926e-01   9.04827052e-01   9.51056516e-01   9.82287251e-01
   9.98026728e-01   9.98026728e-01   9.82287251e-01   9.51056516e-01
   9.04827052e-01   8.44327926e-01   7.70513243e-01   6.84547106e-01
   5.87785252e-01   4.81753674e-01   3.68124553e-01   2.48689887e-01
   1.25333234e-01  -3.21624530e-16  -1.25333234e-01  -2.48689887e-01
  -3.68124553e-01  -4.81753674e-01  -5.87785252e-01  -6.84547106e-01
  -7.70513243e-01  -8.44327926e-01  -9.04827052e-01  -9.51056516e-01
  -9.82287251e-01  -9.98026728e-01  -9.98026728e-01  -9.82287251e-01
  -9.51056516e-01  -9.04827052e-01  -8.44327926e-01  -7.70513243e-01
  -6.84547106e-01  -5.87785252e-01  -4.81753674e-01  -3.68124553e-01
  -2.48689887e-01  -1.25333234e-01]
prediction#1, output: 0.022206
prediction#2, output: 0.176957
prediction#3, output: 0.336479
prediction#4, output: 0.491632
prediction#5, output: 0.632023
prediction#6, output: 0.749222
prediction#7, output: 0.839129
prediction#8, output: 0.902063
prediction#9, output: 0.941122
prediction#10, output: 0.960343
prediction#11, output: 0.963526
prediction#12, output: 0.953751
prediction#13, output: 0.933306
prediction#14, output: 0.903785
prediction#15, output: 0.866218
prediction#16, output: 0.821186
prediction#17, output: 0.768918
prediction#18, output: 0.709356
prediction#19, output: 0.642210
prediction#20, output: 0.567009
prediction#21, output: 0.483171
prediction#22, output: 0.390099
prediction#23, output: 0.287343
prediction#24, output: 0.174845
prediction#25, output: 0.053285
prediction#26, output: -0.075502
prediction#27, output: -0.208165
prediction#28, output: -0.339783
prediction#29, output: -0.464362
prediction#30, output: -0.575945
prediction#31, output: -0.669954
prediction#32, output: -0.744086
prediction#33, output: -0.798361
prediction#34, output: -0.834474
prediction#35, output: -0.854929
prediction#36, output: -0.862344
prediction#37, output: -0.859055
prediction#38, output: -0.846958
prediction#39, output: -0.827486
prediction#40, output: -0.801650
prediction#41, output: -0.770089
prediction#42, output: -0.733127
prediction#43, output: -0.690801
prediction#44, output: -0.642895
prediction#45, output: -0.588954
prediction#46, output: -0.528294
prediction#47, output: -0.460022
prediction#48, output: -0.383079
prediction#49, output: -0.296331
prediction#50, output: -0.198756
prediction#51, output: -0.089779
prediction#52, output: 0.030215
prediction#53, output: 0.159238
prediction#54, output: 0.293156
prediction#55, output: 0.425696
prediction#56, output: 0.549405
prediction#57, output: 0.657418
prediction#58, output: 0.745168
prediction#59, output: 0.811070
prediction#60, output: 0.856028
prediction#61, output: 0.882351
prediction#62, output: 0.892771
prediction#63, output: 0.889828
prediction#64, output: 0.875604
prediction#65, output: 0.851668
prediction#66, output: 0.819113
prediction#67, output: 0.778625
prediction#68, output: 0.730556
prediction#69, output: 0.674974
prediction#70, output: 0.611728
prediction#71, output: 0.540495
prediction#72, output: 0.460847
prediction#73, output: 0.372355
prediction#74, output: 0.274727
prediction#75, output: 0.168034
prediction#76, output: 0.052998
prediction#77, output: -0.068659
prediction#78, output: -0.193931
prediction#79, output: -0.318481
prediction#80, output: -0.437037
prediction#81, output: -0.544270
prediction#82, output: -0.635895
prediction#83, output: -0.709482
prediction#84, output: -0.764614
prediction#85, output: -0.802450
prediction#86, output: -0.825026
prediction#87, output: -0.834626
prediction#88, output: -0.833384
prediction#89, output: -0.823089
prediction#90, output: -0.805125
prediction#91, output: -0.780487
prediction#92, output: -0.749817
prediction#93, output: -0.713441
prediction#94, output: -0.671406
prediction#95, output: -0.623496
prediction#96, output: -0.569257
prediction#97, output: -0.508002
prediction#98, output: -0.438843
prediction#99, output: -0.360736
prediction#100, output: -0.272596
outputs: [ 0.02220552  0.17695722  0.33647949  0.49163169  0.63202316  0.74922162
  0.83912903  0.90206307  0.94112211  0.96034342  0.96352643  0.95375103
  0.9333064   0.90378541  0.86621767  0.82118589  0.76891816  0.70935625
  0.64220965  0.56700873  0.48317075  0.39009929  0.28734344  0.17484498
  0.05328465 -0.07550181 -0.20816538 -0.33978349 -0.46436173 -0.5759452
 -0.66995436 -0.74408585 -0.79836076 -0.83447415 -0.85492909 -0.86234403
 -0.8590551  -0.8469581  -0.82748622 -0.80164975 -0.77008945 -0.73312664
 -0.69080073 -0.64289522 -0.58895433 -0.52829409 -0.46002239 -0.3830792
 -0.29633063 -0.19875565 -0.08977892  0.03021525  0.15923822  0.29315606
  0.42569607  0.54940462  0.65741789  0.74516785  0.81107044  0.85602802
  0.88235128  0.8927713   0.88982815  0.87560409  0.85166794  0.81911254
  0.77862537  0.73055565  0.67497426  0.61172825  0.54049462  0.46084744
  0.37235501  0.27472743  0.1680339   0.05299815 -0.06865866 -0.19393086
 -0.31848121 -0.43703657 -0.54426974 -0.63589543 -0.70948195 -0.76461357
 -0.80245006 -0.82502568 -0.8346259  -0.83338428 -0.82308871 -0.80512464
 -0.78048694 -0.74981689 -0.71344137 -0.67140561 -0.62349612 -0.56925654
 -0.50800192 -0.43884283 -0.36073628 -0.2725957 ]

real	3m30.844s
user	2m6.487s
sys	2m13.480s
