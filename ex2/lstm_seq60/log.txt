param_path: param.yaml
num_of_output_nodes: 1
forget_bias: 1.0
seed: 0
num_of_hidden_nodes: 2
num_of_prediction_epochs: 100
size_of_mini_batch: 100
train_data_path: ../train_data/normal.npy
num_of_training_epochs: 2000
learning_rate: 0.1
num_of_input_nodes: 1
length_of_sequences: 60
optimizer: GradientDescentOptimizer
train_data: [[  0.00000000e+00   1.25333234e-01]
 [  1.25333234e-01   2.48689887e-01]
 [  2.48689887e-01   3.68124553e-01]
 ..., 
 [ -3.68124553e-01  -2.48689887e-01]
 [ -2.48689887e-01  -1.25333234e-01]
 [ -1.25333234e-01   3.92877345e-15]]
train#10, train loss: 5.064031e-01
train#20, train loss: 4.651003e-01
train#30, train loss: 4.535043e-01
train#40, train loss: 4.306910e-01
train#50, train loss: 4.287207e-01
train#60, train loss: 2.529648e-01
train#70, train loss: 1.280458e-01
train#80, train loss: 9.348729e-02
train#90, train loss: 6.410076e-02
train#100, train loss: 5.140152e-02
train#110, train loss: 4.264731e-02
train#120, train loss: 3.380895e-02
train#130, train loss: 2.287801e-02
train#140, train loss: 1.591081e-02
train#150, train loss: 1.175674e-02
train#160, train loss: 7.277818e-03
train#170, train loss: 5.793337e-03
train#180, train loss: 4.572832e-03
train#190, train loss: 4.753850e-03
train#200, train loss: 3.713566e-03
train#210, train loss: 3.908475e-03
train#220, train loss: 2.942737e-03
train#230, train loss: 3.271872e-03
train#240, train loss: 3.238879e-03
train#250, train loss: 2.810455e-03
train#260, train loss: 2.467765e-03
train#270, train loss: 2.723192e-03
train#280, train loss: 2.483626e-03
train#290, train loss: 2.165958e-03
train#300, train loss: 2.257891e-03
train#310, train loss: 2.258248e-03
train#320, train loss: 2.176764e-03
train#330, train loss: 1.992722e-03
train#340, train loss: 1.860305e-03
train#350, train loss: 1.562562e-03
train#360, train loss: 1.553039e-03
train#370, train loss: 1.694910e-03
train#380, train loss: 1.587578e-03
train#390, train loss: 1.676181e-03
train#400, train loss: 1.474495e-03
train#410, train loss: 1.274371e-03
train#420, train loss: 1.171710e-03
train#430, train loss: 1.232174e-03
train#440, train loss: 1.241563e-03
train#450, train loss: 1.325524e-03
train#460, train loss: 1.125398e-03
train#470, train loss: 1.287574e-03
train#480, train loss: 1.252041e-03
train#490, train loss: 1.161474e-03
train#500, train loss: 9.605972e-04
train#510, train loss: 7.292113e-04
train#520, train loss: 1.062161e-03
train#530, train loss: 9.327678e-04
train#540, train loss: 9.265954e-04
train#550, train loss: 9.563963e-04
train#560, train loss: 7.888263e-04
train#570, train loss: 1.003439e-03
train#580, train loss: 1.006113e-03
train#590, train loss: 9.822542e-04
train#600, train loss: 6.867585e-04
train#610, train loss: 7.129000e-04
train#620, train loss: 7.275489e-04
train#630, train loss: 7.645764e-04
train#640, train loss: 7.580140e-04
train#650, train loss: 7.475527e-04
train#660, train loss: 8.147633e-04
train#670, train loss: 7.394499e-04
train#680, train loss: 8.026031e-04
train#690, train loss: 7.191505e-04
train#700, train loss: 7.026082e-04
train#710, train loss: 6.081500e-04
train#720, train loss: 7.034740e-04
train#730, train loss: 7.084332e-04
train#740, train loss: 7.248615e-04
train#750, train loss: 5.378430e-04
train#760, train loss: 6.414186e-04
train#770, train loss: 5.755074e-04
train#780, train loss: 6.034038e-04
train#790, train loss: 6.540029e-04
train#800, train loss: 5.546542e-04
train#810, train loss: 4.991016e-04
train#820, train loss: 6.566831e-04
train#830, train loss: 5.565409e-04
train#840, train loss: 6.256229e-04
train#850, train loss: 4.450012e-04
train#860, train loss: 5.409712e-04
train#870, train loss: 5.678726e-04
train#880, train loss: 4.755324e-04
train#890, train loss: 4.928307e-04
train#900, train loss: 5.900689e-04
train#910, train loss: 5.116136e-04
train#920, train loss: 4.646975e-04
train#930, train loss: 4.306224e-04
train#940, train loss: 5.595052e-04
train#950, train loss: 5.311898e-04
train#960, train loss: 5.054645e-04
train#970, train loss: 3.569249e-04
train#980, train loss: 4.998680e-04
train#990, train loss: 3.877711e-04
train#1000, train loss: 4.415229e-04
train#1010, train loss: 4.317956e-04
train#1020, train loss: 5.344370e-04
train#1030, train loss: 4.289015e-04
train#1040, train loss: 3.879691e-04
train#1050, train loss: 3.354248e-04
train#1060, train loss: 4.738057e-04
train#1070, train loss: 4.101007e-04
train#1080, train loss: 3.574564e-04
train#1090, train loss: 3.901325e-04
train#1100, train loss: 4.399215e-04
train#1110, train loss: 3.611119e-04
train#1120, train loss: 3.775214e-04
train#1130, train loss: 4.222774e-04
train#1140, train loss: 4.741016e-04
train#1150, train loss: 3.803929e-04
train#1160, train loss: 3.885642e-04
train#1170, train loss: 3.652955e-04
train#1180, train loss: 3.407963e-04
train#1190, train loss: 3.564107e-04
train#1200, train loss: 4.022132e-04
train#1210, train loss: 3.438237e-04
train#1220, train loss: 3.856641e-04
train#1230, train loss: 3.881844e-04
train#1240, train loss: 4.041807e-04
train#1250, train loss: 3.867472e-04
train#1260, train loss: 3.417479e-04
train#1270, train loss: 3.488857e-04
train#1280, train loss: 3.130190e-04
train#1290, train loss: 3.075820e-04
train#1300, train loss: 3.736729e-04
train#1310, train loss: 3.873888e-04
train#1320, train loss: 4.191167e-04
train#1330, train loss: 3.277609e-04
train#1340, train loss: 3.089580e-04
train#1350, train loss: 3.309882e-04
train#1360, train loss: 3.462384e-04
train#1370, train loss: 3.448967e-04
train#1380, train loss: 3.707470e-04
train#1390, train loss: 3.502843e-04
train#1400, train loss: 3.148760e-04
train#1410, train loss: 3.739705e-04
train#1420, train loss: 3.454970e-04
train#1430, train loss: 3.408763e-04
train#1440, train loss: 3.226443e-04
train#1450, train loss: 3.350263e-04
train#1460, train loss: 2.888415e-04
train#1470, train loss: 3.129576e-04
train#1480, train loss: 3.081437e-04
train#1490, train loss: 2.954350e-04
train#1500, train loss: 2.982834e-04
train#1510, train loss: 3.240222e-04
train#1520, train loss: 2.563675e-04
train#1530, train loss: 2.770888e-04
train#1540, train loss: 3.026279e-04
train#1550, train loss: 2.727475e-04
train#1560, train loss: 3.066614e-04
train#1570, train loss: 2.648293e-04
train#1580, train loss: 2.768572e-04
train#1590, train loss: 2.816967e-04
train#1600, train loss: 3.001845e-04
train#1610, train loss: 2.556080e-04
train#1620, train loss: 2.763829e-04
train#1630, train loss: 2.354934e-04
train#1640, train loss: 2.480221e-04
train#1650, train loss: 3.015137e-04
train#1660, train loss: 2.668336e-04
train#1670, train loss: 2.719708e-04
train#1680, train loss: 2.687939e-04
train#1690, train loss: 2.414670e-04
train#1700, train loss: 2.778684e-04
train#1710, train loss: 2.946758e-04
train#1720, train loss: 2.458442e-04
train#1730, train loss: 2.502262e-04
train#1740, train loss: 2.613098e-04
train#1750, train loss: 2.672831e-04
train#1760, train loss: 2.879188e-04
train#1770, train loss: 2.883272e-04
train#1780, train loss: 2.441960e-04
train#1790, train loss: 2.752435e-04
train#1800, train loss: 2.203401e-04
train#1810, train loss: 2.810560e-04
train#1820, train loss: 2.275211e-04
train#1830, train loss: 2.581467e-04
train#1840, train loss: 2.184069e-04
train#1850, train loss: 2.334697e-04
train#1860, train loss: 2.255748e-04
train#1870, train loss: 2.327365e-04
train#1880, train loss: 2.429063e-04
train#1890, train loss: 2.639175e-04
train#1900, train loss: 2.743116e-04
train#1910, train loss: 2.396411e-04
train#1920, train loss: 1.752359e-04
train#1930, train loss: 3.027399e-04
train#1940, train loss: 2.051475e-04
train#1950, train loss: 2.082319e-04
train#1960, train loss: 2.310148e-04
train#1970, train loss: 2.283177e-04
train#1980, train loss: 2.485143e-04
train#1990, train loss: 2.360657e-04
train#2000, train loss: 2.022425e-04
losses: [[  1.00000000e+01   5.06403089e-01]
 [  2.00000000e+01   4.65100288e-01]
 [  3.00000000e+01   4.53504324e-01]
 [  4.00000000e+01   4.30691004e-01]
 [  5.00000000e+01   4.28720653e-01]
 [  6.00000000e+01   2.52964824e-01]
 [  7.00000000e+01   1.28045768e-01]
 [  8.00000000e+01   9.34872925e-02]
 [  9.00000000e+01   6.41007647e-02]
 [  1.00000000e+02   5.14015183e-02]
 [  1.10000000e+02   4.26473096e-02]
 [  1.20000000e+02   3.38089503e-02]
 [  1.30000000e+02   2.28780098e-02]
 [  1.40000000e+02   1.59108117e-02]
 [  1.50000000e+02   1.17567368e-02]
 [  1.60000000e+02   7.27781793e-03]
 [  1.70000000e+02   5.79333678e-03]
 [  1.80000000e+02   4.57283249e-03]
 [  1.90000000e+02   4.75384993e-03]
 [  2.00000000e+02   3.71356611e-03]
 [  2.10000000e+02   3.90847493e-03]
 [  2.20000000e+02   2.94273742e-03]
 [  2.30000000e+02   3.27187241e-03]
 [  2.40000000e+02   3.23887938e-03]
 [  2.50000000e+02   2.81045493e-03]
 [  2.60000000e+02   2.46776524e-03]
 [  2.70000000e+02   2.72319233e-03]
 [  2.80000000e+02   2.48362566e-03]
 [  2.90000000e+02   2.16595759e-03]
 [  3.00000000e+02   2.25789077e-03]
 [  3.10000000e+02   2.25824770e-03]
 [  3.20000000e+02   2.17676419e-03]
 [  3.30000000e+02   1.99272204e-03]
 [  3.40000000e+02   1.86030532e-03]
 [  3.50000000e+02   1.56256172e-03]
 [  3.60000000e+02   1.55303883e-03]
 [  3.70000000e+02   1.69490988e-03]
 [  3.80000000e+02   1.58757810e-03]
 [  3.90000000e+02   1.67618145e-03]
 [  4.00000000e+02   1.47449540e-03]
 [  4.10000000e+02   1.27437117e-03]
 [  4.20000000e+02   1.17170962e-03]
 [  4.30000000e+02   1.23217446e-03]
 [  4.40000000e+02   1.24156335e-03]
 [  4.50000000e+02   1.32552418e-03]
 [  4.60000000e+02   1.12539809e-03]
 [  4.70000000e+02   1.28757383e-03]
 [  4.80000000e+02   1.25204073e-03]
 [  4.90000000e+02   1.16147427e-03]
 [  5.00000000e+02   9.60597245e-04]
 [  5.10000000e+02   7.29211257e-04]
 [  5.20000000e+02   1.06216129e-03]
 [  5.30000000e+02   9.32767813e-04]
 [  5.40000000e+02   9.26595356e-04]
 [  5.50000000e+02   9.56396339e-04]
 [  5.60000000e+02   7.88826321e-04]
 [  5.70000000e+02   1.00343931e-03]
 [  5.80000000e+02   1.00611302e-03]
 [  5.90000000e+02   9.82254161e-04]
 [  6.00000000e+02   6.86758547e-04]
 [  6.10000000e+02   7.12899957e-04]
 [  6.20000000e+02   7.27548904e-04]
 [  6.30000000e+02   7.64576369e-04]
 [  6.40000000e+02   7.58014037e-04]
 [  6.50000000e+02   7.47552665e-04]
 [  6.60000000e+02   8.14763305e-04]
 [  6.70000000e+02   7.39449926e-04]
 [  6.80000000e+02   8.02603085e-04]
 [  6.90000000e+02   7.19150470e-04]
 [  7.00000000e+02   7.02608202e-04]
 [  7.10000000e+02   6.08150032e-04]
 [  7.20000000e+02   7.03473983e-04]
 [  7.30000000e+02   7.08433217e-04]
 [  7.40000000e+02   7.24861457e-04]
 [  7.50000000e+02   5.37842978e-04]
 [  7.60000000e+02   6.41418563e-04]
 [  7.70000000e+02   5.75507409e-04]
 [  7.80000000e+02   6.03403838e-04]
 [  7.90000000e+02   6.54002884e-04]
 [  8.00000000e+02   5.54654165e-04]
 [  8.10000000e+02   4.99101589e-04]
 [  8.20000000e+02   6.56683056e-04]
 [  8.30000000e+02   5.56540850e-04]
 [  8.40000000e+02   6.25622924e-04]
 [  8.50000000e+02   4.45001177e-04]
 [  8.60000000e+02   5.40971174e-04]
 [  8.70000000e+02   5.67872601e-04]
 [  8.80000000e+02   4.75532404e-04]
 [  8.90000000e+02   4.92830703e-04]
 [  9.00000000e+02   5.90068870e-04]
 [  9.10000000e+02   5.11613616e-04]
 [  9.20000000e+02   4.64697456e-04]
 [  9.30000000e+02   4.30622429e-04]
 [  9.40000000e+02   5.59505192e-04]
 [  9.50000000e+02   5.31189842e-04]
 [  9.60000000e+02   5.05464501e-04]
 [  9.70000000e+02   3.56924895e-04]
 [  9.80000000e+02   4.99868009e-04]
 [  9.90000000e+02   3.87771142e-04]
 [  1.00000000e+03   4.41522920e-04]
 [  1.01000000e+03   4.31795575e-04]
 [  1.02000000e+03   5.34437015e-04]
 [  1.03000000e+03   4.28901461e-04]
 [  1.04000000e+03   3.87969078e-04]
 [  1.05000000e+03   3.35424847e-04]
 [  1.06000000e+03   4.73805732e-04]
 [  1.07000000e+03   4.10100678e-04]
 [  1.08000000e+03   3.57456418e-04]
 [  1.09000000e+03   3.90132511e-04]
 [  1.10000000e+03   4.39921481e-04]
 [  1.11000000e+03   3.61111946e-04]
 [  1.12000000e+03   3.77521355e-04]
 [  1.13000000e+03   4.22277371e-04]
 [  1.14000000e+03   4.74101602e-04]
 [  1.15000000e+03   3.80392885e-04]
 [  1.16000000e+03   3.88564164e-04]
 [  1.17000000e+03   3.65295477e-04]
 [  1.18000000e+03   3.40796338e-04]
 [  1.19000000e+03   3.56410659e-04]
 [  1.20000000e+03   4.02213162e-04]
 [  1.21000000e+03   3.43823718e-04]
 [  1.22000000e+03   3.85664112e-04]
 [  1.23000000e+03   3.88184446e-04]
 [  1.24000000e+03   4.04180726e-04]
 [  1.25000000e+03   3.86747182e-04]
 [  1.26000000e+03   3.41747858e-04]
 [  1.27000000e+03   3.48885718e-04]
 [  1.28000000e+03   3.13018973e-04]
 [  1.29000000e+03   3.07582028e-04]
 [  1.30000000e+03   3.73672869e-04]
 [  1.31000000e+03   3.87388834e-04]
 [  1.32000000e+03   4.19116666e-04]
 [  1.33000000e+03   3.27760878e-04]
 [  1.34000000e+03   3.08957970e-04]
 [  1.35000000e+03   3.30988230e-04]
 [  1.36000000e+03   3.46238434e-04]
 [  1.37000000e+03   3.44896660e-04]
 [  1.38000000e+03   3.70746973e-04]
 [  1.39000000e+03   3.50284274e-04]
 [  1.40000000e+03   3.14876030e-04]
 [  1.41000000e+03   3.73970484e-04]
 [  1.42000000e+03   3.45496956e-04]
 [  1.43000000e+03   3.40876257e-04]
 [  1.44000000e+03   3.22644337e-04]
 [  1.45000000e+03   3.35026300e-04]
 [  1.46000000e+03   2.88841547e-04]
 [  1.47000000e+03   3.12957622e-04]
 [  1.48000000e+03   3.08143673e-04]
 [  1.49000000e+03   2.95434991e-04]
 [  1.50000000e+03   2.98283383e-04]
 [  1.51000000e+03   3.24022199e-04]
 [  1.52000000e+03   2.56367523e-04]
 [  1.53000000e+03   2.77088810e-04]
 [  1.54000000e+03   3.02627857e-04]
 [  1.55000000e+03   2.72747478e-04]
 [  1.56000000e+03   3.06661386e-04]
 [  1.57000000e+03   2.64829258e-04]
 [  1.58000000e+03   2.76857172e-04]
 [  1.59000000e+03   2.81696732e-04]
 [  1.60000000e+03   3.00184474e-04]
 [  1.61000000e+03   2.55607971e-04]
 [  1.62000000e+03   2.76382896e-04]
 [  1.63000000e+03   2.35493426e-04]
 [  1.64000000e+03   2.48022145e-04]
 [  1.65000000e+03   3.01513704e-04]
 [  1.66000000e+03   2.66833609e-04]
 [  1.67000000e+03   2.71970814e-04]
 [  1.68000000e+03   2.68793898e-04]
 [  1.69000000e+03   2.41466987e-04]
 [  1.70000000e+03   2.77868385e-04]
 [  1.71000000e+03   2.94675818e-04]
 [  1.72000000e+03   2.45844160e-04]
 [  1.73000000e+03   2.50226178e-04]
 [  1.74000000e+03   2.61309848e-04]
 [  1.75000000e+03   2.67283089e-04]
 [  1.76000000e+03   2.87918781e-04]
 [  1.77000000e+03   2.88327225e-04]
 [  1.78000000e+03   2.44195980e-04]
 [  1.79000000e+03   2.75243481e-04]
 [  1.80000000e+03   2.20340080e-04]
 [  1.81000000e+03   2.81056040e-04]
 [  1.82000000e+03   2.27521130e-04]
 [  1.83000000e+03   2.58146698e-04]
 [  1.84000000e+03   2.18406873e-04]
 [  1.85000000e+03   2.33469735e-04]
 [  1.86000000e+03   2.25574753e-04]
 [  1.87000000e+03   2.32736464e-04]
 [  1.88000000e+03   2.42906332e-04]
 [  1.89000000e+03   2.63917493e-04]
 [  1.90000000e+03   2.74311577e-04]
 [  1.91000000e+03   2.39641056e-04]
 [  1.92000000e+03   1.75235909e-04]
 [  1.93000000e+03   3.02739878e-04]
 [  1.94000000e+03   2.05147531e-04]
 [  1.95000000e+03   2.08231912e-04]
 [  1.96000000e+03   2.31014754e-04]
 [  1.97000000e+03   2.28317673e-04]
 [  1.98000000e+03   2.48514290e-04]
 [  1.99000000e+03   2.36065680e-04]
 [  2.00000000e+03   2.02242474e-04]]
initial: [  0.00000000e+00   1.25333234e-01   2.48689887e-01   3.68124553e-01
   4.81753674e-01   5.87785252e-01   6.84547106e-01   7.70513243e-01
   8.44327926e-01   9.04827052e-01   9.51056516e-01   9.82287251e-01
   9.98026728e-01   9.98026728e-01   9.82287251e-01   9.51056516e-01
   9.04827052e-01   8.44327926e-01   7.70513243e-01   6.84547106e-01
   5.87785252e-01   4.81753674e-01   3.68124553e-01   2.48689887e-01
   1.25333234e-01  -3.21624530e-16  -1.25333234e-01  -2.48689887e-01
  -3.68124553e-01  -4.81753674e-01  -5.87785252e-01  -6.84547106e-01
  -7.70513243e-01  -8.44327926e-01  -9.04827052e-01  -9.51056516e-01
  -9.82287251e-01  -9.98026728e-01  -9.98026728e-01  -9.82287251e-01
  -9.51056516e-01  -9.04827052e-01  -8.44327926e-01  -7.70513243e-01
  -6.84547106e-01  -5.87785252e-01  -4.81753674e-01  -3.68124553e-01
  -2.48689887e-01  -1.25333234e-01   6.43249060e-16   1.25333234e-01
   2.48689887e-01   3.68124553e-01   4.81753674e-01   5.87785252e-01
   6.84547106e-01   7.70513243e-01   8.44327926e-01   9.04827052e-01]
prediction#1, output: 0.970542
prediction#2, output: 0.995427
prediction#3, output: 0.996643
prediction#4, output: 0.979806
prediction#5, output: 0.949034
prediction#6, output: 0.907244
prediction#7, output: 0.856229
prediction#8, output: 0.796840
prediction#9, output: 0.729173
prediction#10, output: 0.652740
prediction#11, output: 0.566630
prediction#12, output: 0.469715
prediction#13, output: 0.360993
prediction#14, output: 0.240148
prediction#15, output: 0.108353
prediction#16, output: -0.030926
prediction#17, output: -0.171790
prediction#18, output: -0.307158
prediction#19, output: -0.431183
prediction#20, output: -0.541158
prediction#21, output: -0.637438
prediction#22, output: -0.721832
prediction#23, output: -0.795864
prediction#24, output: -0.859728
prediction#25, output: -0.912108
prediction#26, output: -0.950872
prediction#27, output: -0.974262
prediction#28, output: -0.981757
prediction#29, output: -0.974038
prediction#30, output: -0.952317
prediction#31, output: -0.917668
prediction#32, output: -0.870653
prediction#33, output: -0.811245
prediction#34, output: -0.738929
prediction#35, output: -0.652983
prediction#36, output: -0.552960
prediction#37, output: -0.439408
prediction#38, output: -0.314687
prediction#39, output: -0.183392
prediction#40, output: -0.051717
prediction#41, output: 0.074439
prediction#42, output: 0.191645
prediction#43, output: 0.299946
prediction#44, output: 0.402204
prediction#45, output: 0.502405
prediction#46, output: 0.603581
prediction#47, output: 0.705562
prediction#48, output: 0.803332
prediction#49, output: 0.887989
prediction#50, output: 0.951031
prediction#51, output: 0.988565
prediction#52, output: 1.001764
prediction#53, output: 0.994553
prediction#54, output: 0.971276
prediction#55, output: 0.935481
prediction#56, output: 0.889593
prediction#57, output: 0.834991
prediction#58, output: 0.772186
prediction#59, output: 0.701015
prediction#60, output: 0.620791
prediction#61, output: 0.530480
prediction#62, output: 0.428944
prediction#63, output: 0.315364
prediction#64, output: 0.189899
prediction#65, output: 0.054541
prediction#66, output: -0.086240
prediction#67, output: -0.225840
prediction#68, output: -0.357352
prediction#69, output: -0.476026
prediction#70, output: -0.580482
prediction#71, output: -0.671878
prediction#72, output: -0.752094
prediction#73, output: -0.822213
prediction#74, output: -0.881809
prediction#75, output: -0.929121
prediction#76, output: -0.962018
prediction#77, output: -0.979172
prediction#78, output: -0.980585
prediction#79, output: -0.967238
prediction#80, output: -0.940356
prediction#81, output: -0.900838
prediction#82, output: -0.849016
prediction#83, output: -0.784647
prediction#84, output: -0.707093
prediction#85, output: -0.615668
prediction#86, output: -0.510218
prediction#87, output: -0.391905
prediction#88, output: -0.263953
prediction#89, output: -0.131736
prediction#90, output: -0.001606
prediction#91, output: 0.121280
prediction#92, output: 0.234822
prediction#93, output: 0.340319
prediction#94, output: 0.441302
prediction#95, output: 0.541648
prediction#96, output: 0.643404
prediction#97, output: 0.744615
prediction#98, output: 0.838428
prediction#99, output: 0.915478
prediction#100, output: 0.968729
outputs: [ 0.97054219  0.99542677  0.99664259  0.97980571  0.94903433  0.90724421
  0.85622942  0.79683995  0.72917295  0.65274036  0.56663024  0.46971533
  0.360993    0.24014762  0.1083529  -0.0309262  -0.17179006 -0.3071579
 -0.43118346 -0.5411582  -0.63743806 -0.72183192 -0.79586411 -0.85972786
 -0.9121083  -0.95087218 -0.97426164 -0.98175704 -0.974038   -0.95231724
 -0.91766751 -0.87065327 -0.8112452  -0.73892903 -0.65298265 -0.55295956
 -0.43940848 -0.3146871  -0.18339175 -0.05171674  0.07443893  0.19164547
  0.29994646  0.40220353  0.50240505  0.60358119  0.70556152  0.80333221
  0.88798857  0.95103145  0.98856533  1.00176418  0.99455345  0.97127593
  0.93548083  0.88959348  0.83499062  0.7721864   0.70101511  0.6207912
  0.53047967  0.42894408  0.31536409  0.18989888  0.05454114 -0.08623961
 -0.22583987 -0.35735172 -0.47602576 -0.58048177 -0.67187834 -0.75209439
 -0.82221299 -0.88180852 -0.92912066 -0.96201837 -0.97917163 -0.98058474
 -0.96723819 -0.94035602 -0.90083849 -0.84901559 -0.78464675 -0.707093
 -0.61566848 -0.51021785 -0.39190477 -0.26395342 -0.13173604 -0.00160569
  0.12127978  0.23482224  0.34031877  0.44130209  0.54164779  0.64340353
  0.74461508  0.8384285   0.91547823  0.96872914]

real	4m25.459s
user	2m34.557s
sys	2m41.253s
