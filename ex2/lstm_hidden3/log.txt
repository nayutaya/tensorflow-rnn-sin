param_path: param.yaml
optimizer: GradientDescentOptimizer
num_of_prediction_epochs: 100
num_of_input_nodes: 1
learning_rate: 0.1
num_of_output_nodes: 1
seed: 0
size_of_mini_batch: 100
length_of_sequences: 50
num_of_training_epochs: 2000
train_data_path: ../train_data/normal.npy
forget_bias: 1.0
num_of_hidden_nodes: 3
train_data: [[  0.00000000e+00   1.25333234e-01]
 [  1.25333234e-01   2.48689887e-01]
 [  2.48689887e-01   3.68124553e-01]
 ..., 
 [ -3.68124553e-01  -2.48689887e-01]
 [ -2.48689887e-01  -1.25333234e-01]
 [ -1.25333234e-01   3.92877345e-15]]
train#10, train loss: 5.176402e-01
train#20, train loss: 4.587492e-01
train#30, train loss: 2.875751e-01
train#40, train loss: 1.028749e-01
train#50, train loss: 2.689414e-02
train#60, train loss: 9.217706e-03
train#70, train loss: 4.338605e-03
train#80, train loss: 2.479325e-03
train#90, train loss: 1.765823e-03
train#100, train loss: 1.083254e-03
train#110, train loss: 1.311488e-03
train#120, train loss: 1.114693e-03
train#130, train loss: 1.121478e-03
train#140, train loss: 9.035007e-04
train#150, train loss: 1.319862e-03
train#160, train loss: 1.068936e-03
train#170, train loss: 1.052515e-03
train#180, train loss: 9.638811e-04
train#190, train loss: 9.657028e-04
train#200, train loss: 7.775394e-04
train#210, train loss: 7.096544e-04
train#220, train loss: 8.985767e-04
train#230, train loss: 8.856630e-04
train#240, train loss: 8.548516e-04
train#250, train loss: 8.333282e-04
train#260, train loss: 7.328426e-04
train#270, train loss: 7.194166e-04
train#280, train loss: 7.291216e-04
train#290, train loss: 6.741452e-04
train#300, train loss: 6.208589e-04
train#310, train loss: 5.732828e-04
train#320, train loss: 5.512293e-04
train#330, train loss: 5.212054e-04
train#340, train loss: 5.806081e-04
train#350, train loss: 6.630452e-04
train#360, train loss: 7.472372e-04
train#370, train loss: 5.583765e-04
train#380, train loss: 5.324742e-04
train#390, train loss: 5.641604e-04
train#400, train loss: 5.883074e-04
train#410, train loss: 4.757645e-04
train#420, train loss: 5.202790e-04
train#430, train loss: 5.855976e-04
train#440, train loss: 5.145582e-04
train#450, train loss: 4.701576e-04
train#460, train loss: 5.423183e-04
train#470, train loss: 5.696559e-04
train#480, train loss: 5.794539e-04
train#490, train loss: 5.018078e-04
train#500, train loss: 5.618746e-04
train#510, train loss: 5.628410e-04
train#520, train loss: 5.051510e-04
train#530, train loss: 5.136317e-04
train#540, train loss: 4.583130e-04
train#550, train loss: 3.602615e-04
train#560, train loss: 3.632967e-04
train#570, train loss: 4.562864e-04
train#580, train loss: 3.756109e-04
train#590, train loss: 3.885370e-04
train#600, train loss: 4.582486e-04
train#610, train loss: 4.352792e-04
train#620, train loss: 4.540503e-04
train#630, train loss: 4.814693e-04
train#640, train loss: 4.091839e-04
train#650, train loss: 4.576093e-04
train#660, train loss: 4.266953e-04
train#670, train loss: 4.128010e-04
train#680, train loss: 3.893566e-04
train#690, train loss: 3.016524e-04
train#700, train loss: 3.948610e-04
train#710, train loss: 2.844167e-04
train#720, train loss: 3.873856e-04
train#730, train loss: 3.985436e-04
train#740, train loss: 3.846534e-04
train#750, train loss: 3.938832e-04
train#760, train loss: 3.718013e-04
train#770, train loss: 3.771192e-04
train#780, train loss: 3.710194e-04
train#790, train loss: 3.922131e-04
train#800, train loss: 3.177074e-04
train#810, train loss: 3.305186e-04
train#820, train loss: 3.605707e-04
train#830, train loss: 3.100188e-04
train#840, train loss: 3.232023e-04
train#850, train loss: 3.222681e-04
train#860, train loss: 3.669545e-04
train#870, train loss: 3.109776e-04
train#880, train loss: 3.424156e-04
train#890, train loss: 3.034737e-04
train#900, train loss: 3.056685e-04
train#910, train loss: 2.832273e-04
train#920, train loss: 3.171780e-04
train#930, train loss: 2.984636e-04
train#940, train loss: 2.567214e-04
train#950, train loss: 3.054213e-04
train#960, train loss: 2.678350e-04
train#970, train loss: 2.977795e-04
train#980, train loss: 2.943209e-04
train#990, train loss: 3.030715e-04
train#1000, train loss: 3.298372e-04
train#1010, train loss: 3.033273e-04
train#1020, train loss: 2.942316e-04
train#1030, train loss: 2.783693e-04
train#1040, train loss: 2.413547e-04
train#1050, train loss: 2.624412e-04
train#1060, train loss: 3.117639e-04
train#1070, train loss: 2.632005e-04
train#1080, train loss: 2.709605e-04
train#1090, train loss: 2.445628e-04
train#1100, train loss: 2.518549e-04
train#1110, train loss: 3.004974e-04
train#1120, train loss: 2.120327e-04
train#1130, train loss: 2.806447e-04
train#1140, train loss: 2.240274e-04
train#1150, train loss: 2.451796e-04
train#1160, train loss: 2.369736e-04
train#1170, train loss: 2.580924e-04
train#1180, train loss: 2.212171e-04
train#1190, train loss: 2.430803e-04
train#1200, train loss: 2.267738e-04
train#1210, train loss: 2.486595e-04
train#1220, train loss: 2.417464e-04
train#1230, train loss: 2.417321e-04
train#1240, train loss: 2.472407e-04
train#1250, train loss: 2.262573e-04
train#1260, train loss: 2.410222e-04
train#1270, train loss: 2.129923e-04
train#1280, train loss: 2.069072e-04
train#1290, train loss: 2.369893e-04
train#1300, train loss: 2.016671e-04
train#1310, train loss: 2.102820e-04
train#1320, train loss: 2.104992e-04
train#1330, train loss: 1.885922e-04
train#1340, train loss: 1.860432e-04
train#1350, train loss: 2.346382e-04
train#1360, train loss: 1.645847e-04
train#1370, train loss: 2.145102e-04
train#1380, train loss: 2.022443e-04
train#1390, train loss: 2.352632e-04
train#1400, train loss: 1.856673e-04
train#1410, train loss: 2.243004e-04
train#1420, train loss: 1.990492e-04
train#1430, train loss: 1.842217e-04
train#1440, train loss: 2.412124e-04
train#1450, train loss: 2.007606e-04
train#1460, train loss: 1.914819e-04
train#1470, train loss: 1.880556e-04
train#1480, train loss: 1.885980e-04
train#1490, train loss: 1.721727e-04
train#1500, train loss: 1.639777e-04
train#1510, train loss: 1.852990e-04
train#1520, train loss: 2.109155e-04
train#1530, train loss: 2.287245e-04
train#1540, train loss: 2.070802e-04
train#1550, train loss: 1.758568e-04
train#1560, train loss: 1.885814e-04
train#1570, train loss: 1.775118e-04
train#1580, train loss: 1.751645e-04
train#1590, train loss: 1.542949e-04
train#1600, train loss: 1.969388e-04
train#1610, train loss: 2.110874e-04
train#1620, train loss: 1.815425e-04
train#1630, train loss: 1.701678e-04
train#1640, train loss: 2.065811e-04
train#1650, train loss: 1.564686e-04
train#1660, train loss: 1.417335e-04
train#1670, train loss: 1.781462e-04
train#1680, train loss: 1.845861e-04
train#1690, train loss: 1.737242e-04
train#1700, train loss: 2.030037e-04
train#1710, train loss: 1.778290e-04
train#1720, train loss: 1.541854e-04
train#1730, train loss: 1.948214e-04
train#1740, train loss: 1.760685e-04
train#1750, train loss: 1.534229e-04
train#1760, train loss: 1.498665e-04
train#1770, train loss: 1.824545e-04
train#1780, train loss: 1.560820e-04
train#1790, train loss: 1.817414e-04
train#1800, train loss: 1.737849e-04
train#1810, train loss: 1.406401e-04
train#1820, train loss: 1.473293e-04
train#1830, train loss: 1.472859e-04
train#1840, train loss: 1.588198e-04
train#1850, train loss: 1.373739e-04
train#1860, train loss: 1.493616e-04
train#1870, train loss: 1.672064e-04
train#1880, train loss: 1.394677e-04
train#1890, train loss: 1.399927e-04
train#1900, train loss: 1.640106e-04
train#1910, train loss: 1.795352e-04
train#1920, train loss: 1.448583e-04
train#1930, train loss: 1.576048e-04
train#1940, train loss: 1.505221e-04
train#1950, train loss: 1.700857e-04
train#1960, train loss: 1.664190e-04
train#1970, train loss: 1.575566e-04
train#1980, train loss: 1.442913e-04
train#1990, train loss: 1.473318e-04
train#2000, train loss: 1.278522e-04
losses: [[  1.00000000e+01   5.17640173e-01]
 [  2.00000000e+01   4.58749175e-01]
 [  3.00000000e+01   2.87575126e-01]
 [  4.00000000e+01   1.02874897e-01]
 [  5.00000000e+01   2.68941447e-02]
 [  6.00000000e+01   9.21770558e-03]
 [  7.00000000e+01   4.33860486e-03]
 [  8.00000000e+01   2.47932505e-03]
 [  9.00000000e+01   1.76582334e-03]
 [  1.00000000e+02   1.08325377e-03]
 [  1.10000000e+02   1.31148845e-03]
 [  1.20000000e+02   1.11469300e-03]
 [  1.30000000e+02   1.12147781e-03]
 [  1.40000000e+02   9.03500710e-04]
 [  1.50000000e+02   1.31986197e-03]
 [  1.60000000e+02   1.06893585e-03]
 [  1.70000000e+02   1.05251546e-03]
 [  1.80000000e+02   9.63881146e-04]
 [  1.90000000e+02   9.65702813e-04]
 [  2.00000000e+02   7.77539390e-04]
 [  2.10000000e+02   7.09654414e-04]
 [  2.20000000e+02   8.98576691e-04]
 [  2.30000000e+02   8.85663030e-04]
 [  2.40000000e+02   8.54851620e-04]
 [  2.50000000e+02   8.33328231e-04]
 [  2.60000000e+02   7.32842600e-04]
 [  2.70000000e+02   7.19416596e-04]
 [  2.80000000e+02   7.29121617e-04]
 [  2.90000000e+02   6.74145238e-04]
 [  3.00000000e+02   6.20858918e-04]
 [  3.10000000e+02   5.73282829e-04]
 [  3.20000000e+02   5.51229285e-04]
 [  3.30000000e+02   5.21205424e-04]
 [  3.40000000e+02   5.80608146e-04]
 [  3.50000000e+02   6.63045212e-04]
 [  3.60000000e+02   7.47237180e-04]
 [  3.70000000e+02   5.58376545e-04]
 [  3.80000000e+02   5.32474194e-04]
 [  3.90000000e+02   5.64160408e-04]
 [  4.00000000e+02   5.88307390e-04]
 [  4.10000000e+02   4.75764507e-04]
 [  4.20000000e+02   5.20279049e-04]
 [  4.30000000e+02   5.85597591e-04]
 [  4.40000000e+02   5.14558167e-04]
 [  4.50000000e+02   4.70157625e-04]
 [  4.60000000e+02   5.42318274e-04]
 [  4.70000000e+02   5.69655909e-04]
 [  4.80000000e+02   5.79453947e-04]
 [  4.90000000e+02   5.01807837e-04]
 [  5.00000000e+02   5.61874593e-04]
 [  5.10000000e+02   5.62841014e-04]
 [  5.20000000e+02   5.05150994e-04]
 [  5.30000000e+02   5.13631734e-04]
 [  5.40000000e+02   4.58313007e-04]
 [  5.50000000e+02   3.60261503e-04]
 [  5.60000000e+02   3.63296713e-04]
 [  5.70000000e+02   4.56286449e-04]
 [  5.80000000e+02   3.75610893e-04]
 [  5.90000000e+02   3.88536952e-04]
 [  6.00000000e+02   4.58248600e-04]
 [  6.10000000e+02   4.35279158e-04]
 [  6.20000000e+02   4.54050343e-04]
 [  6.30000000e+02   4.81469266e-04]
 [  6.40000000e+02   4.09183878e-04]
 [  6.50000000e+02   4.57609305e-04]
 [  6.60000000e+02   4.26695275e-04]
 [  6.70000000e+02   4.12801048e-04]
 [  6.80000000e+02   3.89356603e-04]
 [  6.90000000e+02   3.01652413e-04]
 [  7.00000000e+02   3.94860952e-04]
 [  7.10000000e+02   2.84416717e-04]
 [  7.20000000e+02   3.87385575e-04]
 [  7.30000000e+02   3.98543634e-04]
 [  7.40000000e+02   3.84653424e-04]
 [  7.50000000e+02   3.93883209e-04]
 [  7.60000000e+02   3.71801318e-04]
 [  7.70000000e+02   3.77119170e-04]
 [  7.80000000e+02   3.71019385e-04]
 [  7.90000000e+02   3.92213085e-04]
 [  8.00000000e+02   3.17707425e-04]
 [  8.10000000e+02   3.30518553e-04]
 [  8.20000000e+02   3.60570702e-04]
 [  8.30000000e+02   3.10018833e-04]
 [  8.40000000e+02   3.23202315e-04]
 [  8.50000000e+02   3.22268053e-04]
 [  8.60000000e+02   3.66954482e-04]
 [  8.70000000e+02   3.10977630e-04]
 [  8.80000000e+02   3.42415617e-04]
 [  8.90000000e+02   3.03473702e-04]
 [  9.00000000e+02   3.05668538e-04]
 [  9.10000000e+02   2.83227273e-04]
 [  9.20000000e+02   3.17177997e-04]
 [  9.30000000e+02   2.98463594e-04]
 [  9.40000000e+02   2.56721425e-04]
 [  9.50000000e+02   3.05421301e-04]
 [  9.60000000e+02   2.67835043e-04]
 [  9.70000000e+02   2.97779508e-04]
 [  9.80000000e+02   2.94320867e-04]
 [  9.90000000e+02   3.03071487e-04]
 [  1.00000000e+03   3.29837203e-04]
 [  1.01000000e+03   3.03327251e-04]
 [  1.02000000e+03   2.94231577e-04]
 [  1.03000000e+03   2.78369291e-04]
 [  1.04000000e+03   2.41354704e-04]
 [  1.05000000e+03   2.62441201e-04]
 [  1.06000000e+03   3.11763928e-04]
 [  1.07000000e+03   2.63200549e-04]
 [  1.08000000e+03   2.70960474e-04]
 [  1.09000000e+03   2.44562805e-04]
 [  1.10000000e+03   2.51854857e-04]
 [  1.11000000e+03   3.00497399e-04]
 [  1.12000000e+03   2.12032668e-04]
 [  1.13000000e+03   2.80644657e-04]
 [  1.14000000e+03   2.24027390e-04]
 [  1.15000000e+03   2.45179632e-04]
 [  1.16000000e+03   2.36973618e-04]
 [  1.17000000e+03   2.58092419e-04]
 [  1.18000000e+03   2.21217095e-04]
 [  1.19000000e+03   2.43080329e-04]
 [  1.20000000e+03   2.26773802e-04]
 [  1.21000000e+03   2.48659519e-04]
 [  1.22000000e+03   2.41746413e-04]
 [  1.23000000e+03   2.41732079e-04]
 [  1.24000000e+03   2.47240736e-04]
 [  1.25000000e+03   2.26257311e-04]
 [  1.26000000e+03   2.41022164e-04]
 [  1.27000000e+03   2.12992323e-04]
 [  1.28000000e+03   2.06907163e-04]
 [  1.29000000e+03   2.36989275e-04]
 [  1.30000000e+03   2.01667062e-04]
 [  1.31000000e+03   2.10282014e-04]
 [  1.32000000e+03   2.10499202e-04]
 [  1.33000000e+03   1.88592181e-04]
 [  1.34000000e+03   1.86043180e-04]
 [  1.35000000e+03   2.34638224e-04]
 [  1.36000000e+03   1.64584737e-04]
 [  1.37000000e+03   2.14510219e-04]
 [  1.38000000e+03   2.02244337e-04]
 [  1.39000000e+03   2.35263215e-04]
 [  1.40000000e+03   1.85667319e-04]
 [  1.41000000e+03   2.24300442e-04]
 [  1.42000000e+03   1.99049231e-04]
 [  1.43000000e+03   1.84221717e-04]
 [  1.44000000e+03   2.41212416e-04]
 [  1.45000000e+03   2.00760594e-04]
 [  1.46000000e+03   1.91481930e-04]
 [  1.47000000e+03   1.88055623e-04]
 [  1.48000000e+03   1.88597987e-04]
 [  1.49000000e+03   1.72172746e-04]
 [  1.50000000e+03   1.63977689e-04]
 [  1.51000000e+03   1.85298952e-04]
 [  1.52000000e+03   2.10915474e-04]
 [  1.53000000e+03   2.28724486e-04]
 [  1.54000000e+03   2.07080186e-04]
 [  1.55000000e+03   1.75856767e-04]
 [  1.56000000e+03   1.88581398e-04]
 [  1.57000000e+03   1.77511800e-04]
 [  1.58000000e+03   1.75164503e-04]
 [  1.59000000e+03   1.54294947e-04]
 [  1.60000000e+03   1.96938752e-04]
 [  1.61000000e+03   2.11087376e-04]
 [  1.62000000e+03   1.81542462e-04]
 [  1.63000000e+03   1.70167827e-04]
 [  1.64000000e+03   2.06581142e-04]
 [  1.65000000e+03   1.56468639e-04]
 [  1.66000000e+03   1.41733530e-04]
 [  1.67000000e+03   1.78146220e-04]
 [  1.68000000e+03   1.84586082e-04]
 [  1.69000000e+03   1.73724184e-04]
 [  1.70000000e+03   2.03003699e-04]
 [  1.71000000e+03   1.77829046e-04]
 [  1.72000000e+03   1.54185356e-04]
 [  1.73000000e+03   1.94821376e-04]
 [  1.74000000e+03   1.76068468e-04]
 [  1.75000000e+03   1.53422850e-04]
 [  1.76000000e+03   1.49866522e-04]
 [  1.77000000e+03   1.82454532e-04]
 [  1.78000000e+03   1.56082038e-04]
 [  1.79000000e+03   1.81741401e-04]
 [  1.80000000e+03   1.73784880e-04]
 [  1.81000000e+03   1.40640099e-04]
 [  1.82000000e+03   1.47329265e-04]
 [  1.83000000e+03   1.47285915e-04]
 [  1.84000000e+03   1.58819821e-04]
 [  1.85000000e+03   1.37373892e-04]
 [  1.86000000e+03   1.49361615e-04]
 [  1.87000000e+03   1.67206381e-04]
 [  1.88000000e+03   1.39467709e-04]
 [  1.89000000e+03   1.39992699e-04]
 [  1.90000000e+03   1.64010562e-04]
 [  1.91000000e+03   1.79535171e-04]
 [  1.92000000e+03   1.44858321e-04]
 [  1.93000000e+03   1.57604794e-04]
 [  1.94000000e+03   1.50522101e-04]
 [  1.95000000e+03   1.70085696e-04]
 [  1.96000000e+03   1.66418977e-04]
 [  1.97000000e+03   1.57556613e-04]
 [  1.98000000e+03   1.44291349e-04]
 [  1.99000000e+03   1.47331768e-04]
 [  2.00000000e+03   1.27852240e-04]]
initial: [  0.00000000e+00   1.25333234e-01   2.48689887e-01   3.68124553e-01
   4.81753674e-01   5.87785252e-01   6.84547106e-01   7.70513243e-01
   8.44327926e-01   9.04827052e-01   9.51056516e-01   9.82287251e-01
   9.98026728e-01   9.98026728e-01   9.82287251e-01   9.51056516e-01
   9.04827052e-01   8.44327926e-01   7.70513243e-01   6.84547106e-01
   5.87785252e-01   4.81753674e-01   3.68124553e-01   2.48689887e-01
   1.25333234e-01  -3.21624530e-16  -1.25333234e-01  -2.48689887e-01
  -3.68124553e-01  -4.81753674e-01  -5.87785252e-01  -6.84547106e-01
  -7.70513243e-01  -8.44327926e-01  -9.04827052e-01  -9.51056516e-01
  -9.82287251e-01  -9.98026728e-01  -9.98026728e-01  -9.82287251e-01
  -9.51056516e-01  -9.04827052e-01  -8.44327926e-01  -7.70513243e-01
  -6.84547106e-01  -5.87785252e-01  -4.81753674e-01  -3.68124553e-01
  -2.48689887e-01  -1.25333234e-01]
prediction#1, output: 0.009889
prediction#2, output: 0.146951
prediction#3, output: 0.259049
prediction#4, output: 0.372431
prediction#5, output: 0.487577
prediction#6, output: 0.600865
prediction#7, output: 0.706256
prediction#8, output: 0.797672
prediction#9, output: 0.871187
prediction#10, output: 0.925686
prediction#11, output: 0.962068
prediction#12, output: 0.982129
prediction#13, output: 0.987822
prediction#14, output: 0.980871
prediction#15, output: 0.962562
prediction#16, output: 0.933628
prediction#17, output: 0.894194
prediction#18, output: 0.843756
prediction#19, output: 0.781213
prediction#20, output: 0.705015
prediction#21, output: 0.613598
prediction#22, output: 0.506314
prediction#23, output: 0.384868
prediction#24, output: 0.254451
prediction#25, output: 0.122705
prediction#26, output: -0.003940
prediction#27, output: -0.123326
prediction#28, output: -0.236947
prediction#29, output: -0.347279
prediction#30, output: -0.455888
prediction#31, output: -0.562813
prediction#32, output: -0.666388
prediction#33, output: -0.763019
prediction#34, output: -0.847426
prediction#35, output: -0.914292
prediction#36, output: -0.960667
prediction#37, output: -0.986909
prediction#38, output: -0.995534
prediction#39, output: -0.989496
prediction#40, output: -0.971088
prediction#41, output: -0.941544
prediction#42, output: -0.900968
prediction#43, output: -0.848364
prediction#44, output: -0.781728
prediction#45, output: -0.698380
prediction#46, output: -0.595969
prediction#47, output: -0.474687
prediction#48, output: -0.340044
prediction#49, output: -0.202785
prediction#50, output: -0.072974
prediction#51, output: 0.046477
prediction#52, output: 0.159354
prediction#53, output: 0.271055
prediction#54, output: 0.384697
prediction#55, output: 0.499805
prediction#56, output: 0.612410
prediction#57, output: 0.716405
prediction#58, output: 0.805894
prediction#59, output: 0.877263
prediction#60, output: 0.929663
prediction#61, output: 0.964128
prediction#62, output: 0.982490
prediction#63, output: 0.986687
prediction#64, output: 0.978398
prediction#65, output: 0.958845
prediction#66, output: 0.928692
prediction#67, output: 0.887989
prediction#68, output: 0.836155
prediction#69, output: 0.772021
prediction#70, output: 0.694001
prediction#71, output: 0.600579
prediction#72, output: 0.491316
prediction#73, output: 0.368332
prediction#74, output: 0.237269
prediction#75, output: 0.105872
prediction#76, output: -0.019870
prediction#77, output: -0.138390
prediction#78, output: -0.251467
prediction#79, output: -0.361530
prediction#80, output: -0.469959
prediction#81, output: -0.576582
prediction#82, output: -0.679494
prediction#83, output: -0.774852
prediction#84, output: -0.857246
prediction#85, output: -0.921539
prediction#86, output: -0.965210
prediction#87, output: -0.988992
prediction#88, output: -0.995550
prediction#89, output: -0.987793
prediction#90, output: -0.967889
prediction#91, output: -0.936925
prediction#92, output: -0.894861
prediction#93, output: -0.840570
prediction#94, output: -0.771936
prediction#95, output: -0.686249
prediction#96, output: -0.581336
prediction#97, output: -0.457919
prediction#98, output: -0.322282
prediction#99, output: -0.185502
prediction#100, output: -0.056991
outputs: [ 0.00988895  0.14695144  0.25904918  0.37243086  0.48757735  0.60086477
  0.70625579  0.79767245  0.87118709  0.92568642  0.96206832  0.98212868
  0.98782188  0.98087126  0.96256214  0.93362796  0.89419365  0.84375602
  0.78121251  0.70501488  0.61359841  0.5063135   0.38486832  0.25445098
  0.1227048  -0.00394048 -0.12332624 -0.23694739 -0.34727857 -0.45588797
 -0.56281322 -0.66638774 -0.76301855 -0.84742582 -0.91429216 -0.96066731
 -0.98690897 -0.99553448 -0.98949629 -0.97108847 -0.94154423 -0.90096766
 -0.84836352 -0.78172845 -0.69837976 -0.5959689  -0.47468704 -0.3400445
 -0.20278543 -0.07297406  0.04647714  0.15935385  0.27105466  0.38469699
  0.49980545  0.61241013  0.71640521  0.80589384  0.87726289  0.929663
  0.96412772  0.98248988  0.98668706  0.97839779  0.95884544  0.9286924
  0.88798875  0.83615476  0.77202064  0.69400114  0.60057926  0.49131578
  0.36833155  0.23726918  0.1058723  -0.01986998 -0.13839036 -0.25146723
 -0.36152959 -0.4699595  -0.57658154 -0.67949384 -0.77485186 -0.85724586
 -0.92153937 -0.96520978 -0.98899168 -0.99554962 -0.98779291 -0.96788913
 -0.93692487 -0.89486128 -0.84056956 -0.77193618 -0.68624902 -0.5813356
 -0.4579193  -0.32228211 -0.18550214 -0.05699062]

real	4m36.324s
user	2m42.847s
sys	3m57.192s
