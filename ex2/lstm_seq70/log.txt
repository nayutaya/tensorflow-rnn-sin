param_path: param.yaml
num_of_hidden_nodes: 2
learning_rate: 0.1
length_of_sequences: 70
train_data_path: ../train_data/normal.npy
seed: 0
num_of_training_epochs: 2000
forget_bias: 1.0
size_of_mini_batch: 100
num_of_prediction_epochs: 100
num_of_output_nodes: 1
optimizer: GradientDescentOptimizer
num_of_input_nodes: 1
train_data: [[  0.00000000e+00   1.25333234e-01]
 [  1.25333234e-01   2.48689887e-01]
 [  2.48689887e-01   3.68124553e-01]
 ..., 
 [ -3.68124553e-01  -2.48689887e-01]
 [ -2.48689887e-01  -1.25333234e-01]
 [ -1.25333234e-01   3.92877345e-15]]
train#10, train loss: 4.796186e-01
train#20, train loss: 5.401077e-01
train#30, train loss: 5.153419e-01
train#40, train loss: 4.955109e-01
train#50, train loss: 4.945677e-01
train#60, train loss: 4.783421e-01
train#70, train loss: 3.757050e-01
train#80, train loss: 3.294629e-01
train#90, train loss: 2.248099e-01
train#100, train loss: 1.656089e-01
train#110, train loss: 1.249142e-01
train#120, train loss: 9.904041e-02
train#130, train loss: 8.222300e-02
train#140, train loss: 6.861221e-02
train#150, train loss: 5.316510e-02
train#160, train loss: 4.651732e-02
train#170, train loss: 3.759258e-02
train#180, train loss: 3.093119e-02
train#190, train loss: 3.175754e-02
train#200, train loss: 2.183435e-02
train#210, train loss: 2.061408e-02
train#220, train loss: 1.675729e-02
train#230, train loss: 1.362756e-02
train#240, train loss: 9.447212e-03
train#250, train loss: 8.437477e-03
train#260, train loss: 7.998711e-03
train#270, train loss: 5.435003e-03
train#280, train loss: 5.759644e-03
train#290, train loss: 4.187161e-03
train#300, train loss: 3.068268e-03
train#310, train loss: 3.118476e-03
train#320, train loss: 2.699803e-03
train#330, train loss: 3.208845e-03
train#340, train loss: 2.744558e-03
train#350, train loss: 2.472926e-03
train#360, train loss: 3.137127e-03
train#370, train loss: 2.770931e-03
train#380, train loss: 2.908822e-03
train#390, train loss: 2.759646e-03
train#400, train loss: 2.616544e-03
train#410, train loss: 2.362983e-03
train#420, train loss: 1.897157e-03
train#430, train loss: 2.725989e-03
train#440, train loss: 2.353880e-03
train#450, train loss: 2.186480e-03
train#460, train loss: 2.008676e-03
train#470, train loss: 2.314161e-03
train#480, train loss: 1.719742e-03
train#490, train loss: 2.096004e-03
train#500, train loss: 1.859766e-03
train#510, train loss: 2.055695e-03
train#520, train loss: 1.657851e-03
train#530, train loss: 2.028192e-03
train#540, train loss: 2.021110e-03
train#550, train loss: 1.816189e-03
train#560, train loss: 1.892689e-03
train#570, train loss: 2.163564e-03
train#580, train loss: 2.115963e-03
train#590, train loss: 1.801425e-03
train#600, train loss: 1.648362e-03
train#610, train loss: 1.778189e-03
train#620, train loss: 1.679771e-03
train#630, train loss: 1.666242e-03
train#640, train loss: 1.678930e-03
train#650, train loss: 1.821520e-03
train#660, train loss: 1.767223e-03
train#670, train loss: 1.728120e-03
train#680, train loss: 1.483732e-03
train#690, train loss: 1.692293e-03
train#700, train loss: 1.311370e-03
train#710, train loss: 1.539966e-03
train#720, train loss: 1.254632e-03
train#730, train loss: 1.597914e-03
train#740, train loss: 1.435143e-03
train#750, train loss: 1.392780e-03
train#760, train loss: 1.531243e-03
train#770, train loss: 1.351497e-03
train#780, train loss: 1.532387e-03
train#790, train loss: 1.406845e-03
train#800, train loss: 1.278705e-03
train#810, train loss: 1.226033e-03
train#820, train loss: 1.145122e-03
train#830, train loss: 1.383151e-03
train#840, train loss: 1.397016e-03
train#850, train loss: 1.336279e-03
train#860, train loss: 1.264896e-03
train#870, train loss: 1.138961e-03
train#880, train loss: 1.269270e-03
train#890, train loss: 1.368431e-03
train#900, train loss: 1.314265e-03
train#910, train loss: 1.238486e-03
train#920, train loss: 1.332530e-03
train#930, train loss: 1.221377e-03
train#940, train loss: 1.208450e-03
train#950, train loss: 1.252269e-03
train#960, train loss: 1.099447e-03
train#970, train loss: 1.213501e-03
train#980, train loss: 1.275495e-03
train#990, train loss: 1.205821e-03
train#1000, train loss: 1.193635e-03
train#1010, train loss: 1.177025e-03
train#1020, train loss: 1.158899e-03
train#1030, train loss: 1.135125e-03
train#1040, train loss: 1.100944e-03
train#1050, train loss: 1.091459e-03
train#1060, train loss: 1.176367e-03
train#1070, train loss: 1.076611e-03
train#1080, train loss: 1.071778e-03
train#1090, train loss: 1.152566e-03
train#1100, train loss: 1.061106e-03
train#1110, train loss: 1.058940e-03
train#1120, train loss: 1.051673e-03
train#1130, train loss: 1.074057e-03
train#1140, train loss: 9.142919e-04
train#1150, train loss: 9.553215e-04
train#1160, train loss: 9.079676e-04
train#1170, train loss: 9.844250e-04
train#1180, train loss: 9.435982e-04
train#1190, train loss: 1.014638e-03
train#1200, train loss: 1.006211e-03
train#1210, train loss: 9.813919e-04
train#1220, train loss: 7.852375e-04
train#1230, train loss: 1.034068e-03
train#1240, train loss: 8.760886e-04
train#1250, train loss: 1.060728e-03
train#1260, train loss: 9.427693e-04
train#1270, train loss: 8.394580e-04
train#1280, train loss: 9.491652e-04
train#1290, train loss: 8.400340e-04
train#1300, train loss: 9.602442e-04
train#1310, train loss: 7.374054e-04
train#1320, train loss: 8.397663e-04
train#1330, train loss: 8.133503e-04
train#1340, train loss: 8.138458e-04
train#1350, train loss: 8.063684e-04
train#1360, train loss: 8.663282e-04
train#1370, train loss: 7.943492e-04
train#1380, train loss: 8.644490e-04
train#1390, train loss: 8.339095e-04
train#1400, train loss: 8.259013e-04
train#1410, train loss: 8.592847e-04
train#1420, train loss: 8.805400e-04
train#1430, train loss: 6.526296e-04
train#1440, train loss: 6.981866e-04
train#1450, train loss: 8.460273e-04
train#1460, train loss: 7.138064e-04
train#1470, train loss: 7.847644e-04
train#1480, train loss: 6.750494e-04
train#1490, train loss: 8.296118e-04
train#1500, train loss: 7.665718e-04
train#1510, train loss: 7.867038e-04
train#1520, train loss: 7.582788e-04
train#1530, train loss: 7.491559e-04
train#1540, train loss: 7.773240e-04
train#1550, train loss: 6.747292e-04
train#1560, train loss: 8.115657e-04
train#1570, train loss: 7.403136e-04
train#1580, train loss: 7.402573e-04
train#1590, train loss: 6.888307e-04
train#1600, train loss: 6.257913e-04
train#1610, train loss: 6.566489e-04
train#1620, train loss: 7.149242e-04
train#1630, train loss: 7.831462e-04
train#1640, train loss: 6.698117e-04
train#1650, train loss: 6.500233e-04
train#1660, train loss: 6.811656e-04
train#1670, train loss: 6.203064e-04
train#1680, train loss: 6.854939e-04
train#1690, train loss: 7.690707e-04
train#1700, train loss: 6.272398e-04
train#1710, train loss: 6.440567e-04
train#1720, train loss: 6.392658e-04
train#1730, train loss: 7.886963e-04
train#1740, train loss: 6.127408e-04
train#1750, train loss: 6.237622e-04
train#1760, train loss: 6.333459e-04
train#1770, train loss: 6.080349e-04
train#1780, train loss: 6.655093e-04
train#1790, train loss: 5.662563e-04
train#1800, train loss: 7.157618e-04
train#1810, train loss: 6.154856e-04
train#1820, train loss: 6.831001e-04
train#1830, train loss: 6.790432e-04
train#1840, train loss: 6.317766e-04
train#1850, train loss: 5.987133e-04
train#1860, train loss: 6.440687e-04
train#1870, train loss: 6.197105e-04
train#1880, train loss: 6.024193e-04
train#1890, train loss: 5.361190e-04
train#1900, train loss: 6.155973e-04
train#1910, train loss: 6.274694e-04
train#1920, train loss: 6.235983e-04
train#1930, train loss: 6.306779e-04
train#1940, train loss: 6.191928e-04
train#1950, train loss: 6.066200e-04
train#1960, train loss: 5.416253e-04
train#1970, train loss: 6.273279e-04
train#1980, train loss: 5.652665e-04
train#1990, train loss: 6.046668e-04
train#2000, train loss: 5.444124e-04
losses: [[  1.00000000e+01   4.79618609e-01]
 [  2.00000000e+01   5.40107667e-01]
 [  3.00000000e+01   5.15341938e-01]
 [  4.00000000e+01   4.95510876e-01]
 [  5.00000000e+01   4.94567722e-01]
 [  6.00000000e+01   4.78342146e-01]
 [  7.00000000e+01   3.75705034e-01]
 [  8.00000000e+01   3.29462916e-01]
 [  9.00000000e+01   2.24809900e-01]
 [  1.00000000e+02   1.65608898e-01]
 [  1.10000000e+02   1.24914169e-01]
 [  1.20000000e+02   9.90404114e-02]
 [  1.30000000e+02   8.22229981e-02]
 [  1.40000000e+02   6.86122105e-02]
 [  1.50000000e+02   5.31651005e-02]
 [  1.60000000e+02   4.65173200e-02]
 [  1.70000000e+02   3.75925787e-02]
 [  1.80000000e+02   3.09311897e-02]
 [  1.90000000e+02   3.17575373e-02]
 [  2.00000000e+02   2.18343455e-02]
 [  2.10000000e+02   2.06140764e-02]
 [  2.20000000e+02   1.67572852e-02]
 [  2.30000000e+02   1.36275645e-02]
 [  2.40000000e+02   9.44721233e-03]
 [  2.50000000e+02   8.43747705e-03]
 [  2.60000000e+02   7.99871143e-03]
 [  2.70000000e+02   5.43500297e-03]
 [  2.80000000e+02   5.75964432e-03]
 [  2.90000000e+02   4.18716064e-03]
 [  3.00000000e+02   3.06826760e-03]
 [  3.10000000e+02   3.11847567e-03]
 [  3.20000000e+02   2.69980310e-03]
 [  3.30000000e+02   3.20884516e-03]
 [  3.40000000e+02   2.74455780e-03]
 [  3.50000000e+02   2.47292593e-03]
 [  3.60000000e+02   3.13712680e-03]
 [  3.70000000e+02   2.77093076e-03]
 [  3.80000000e+02   2.90882168e-03]
 [  3.90000000e+02   2.75964569e-03]
 [  4.00000000e+02   2.61654425e-03]
 [  4.10000000e+02   2.36298260e-03]
 [  4.20000000e+02   1.89715694e-03]
 [  4.30000000e+02   2.72598863e-03]
 [  4.40000000e+02   2.35387962e-03]
 [  4.50000000e+02   2.18647951e-03]
 [  4.60000000e+02   2.00867606e-03]
 [  4.70000000e+02   2.31416081e-03]
 [  4.80000000e+02   1.71974243e-03]
 [  4.90000000e+02   2.09600385e-03]
 [  5.00000000e+02   1.85976585e-03]
 [  5.10000000e+02   2.05569528e-03]
 [  5.20000000e+02   1.65785069e-03]
 [  5.30000000e+02   2.02819193e-03]
 [  5.40000000e+02   2.02111038e-03]
 [  5.50000000e+02   1.81618938e-03]
 [  5.60000000e+02   1.89268915e-03]
 [  5.70000000e+02   2.16356432e-03]
 [  5.80000000e+02   2.11596349e-03]
 [  5.90000000e+02   1.80142466e-03]
 [  6.00000000e+02   1.64836238e-03]
 [  6.10000000e+02   1.77818921e-03]
 [  6.20000000e+02   1.67977111e-03]
 [  6.30000000e+02   1.66624179e-03]
 [  6.40000000e+02   1.67892966e-03]
 [  6.50000000e+02   1.82152027e-03]
 [  6.60000000e+02   1.76722324e-03]
 [  6.70000000e+02   1.72811956e-03]
 [  6.80000000e+02   1.48373167e-03]
 [  6.90000000e+02   1.69229286e-03]
 [  7.00000000e+02   1.31136982e-03]
 [  7.10000000e+02   1.53996621e-03]
 [  7.20000000e+02   1.25463249e-03]
 [  7.30000000e+02   1.59791415e-03]
 [  7.40000000e+02   1.43514259e-03]
 [  7.50000000e+02   1.39277999e-03]
 [  7.60000000e+02   1.53124274e-03]
 [  7.70000000e+02   1.35149702e-03]
 [  7.80000000e+02   1.53238745e-03]
 [  7.90000000e+02   1.40684459e-03]
 [  8.00000000e+02   1.27870543e-03]
 [  8.10000000e+02   1.22603297e-03]
 [  8.20000000e+02   1.14512246e-03]
 [  8.30000000e+02   1.38315081e-03]
 [  8.40000000e+02   1.39701576e-03]
 [  8.50000000e+02   1.33627886e-03]
 [  8.60000000e+02   1.26489555e-03]
 [  8.70000000e+02   1.13896106e-03]
 [  8.80000000e+02   1.26927032e-03]
 [  8.90000000e+02   1.36843114e-03]
 [  9.00000000e+02   1.31426542e-03]
 [  9.10000000e+02   1.23848603e-03]
 [  9.20000000e+02   1.33252994e-03]
 [  9.30000000e+02   1.22137694e-03]
 [  9.40000000e+02   1.20844983e-03]
 [  9.50000000e+02   1.25226867e-03]
 [  9.60000000e+02   1.09944749e-03]
 [  9.70000000e+02   1.21350121e-03]
 [  9.80000000e+02   1.27549528e-03]
 [  9.90000000e+02   1.20582082e-03]
 [  1.00000000e+03   1.19363505e-03]
 [  1.01000000e+03   1.17702549e-03]
 [  1.02000000e+03   1.15889893e-03]
 [  1.03000000e+03   1.13512506e-03]
 [  1.04000000e+03   1.10094366e-03]
 [  1.05000000e+03   1.09145883e-03]
 [  1.06000000e+03   1.17636693e-03]
 [  1.07000000e+03   1.07661111e-03]
 [  1.08000000e+03   1.07177789e-03]
 [  1.09000000e+03   1.15256640e-03]
 [  1.10000000e+03   1.06110633e-03]
 [  1.11000000e+03   1.05894019e-03]
 [  1.12000000e+03   1.05167320e-03]
 [  1.13000000e+03   1.07405696e-03]
 [  1.14000000e+03   9.14291944e-04]
 [  1.15000000e+03   9.55321477e-04]
 [  1.16000000e+03   9.07967624e-04]
 [  1.17000000e+03   9.84424958e-04]
 [  1.18000000e+03   9.43598163e-04]
 [  1.19000000e+03   1.01463776e-03]
 [  1.20000000e+03   1.00621104e-03]
 [  1.21000000e+03   9.81391873e-04]
 [  1.22000000e+03   7.85237527e-04]
 [  1.23000000e+03   1.03406829e-03]
 [  1.24000000e+03   8.76088568e-04]
 [  1.25000000e+03   1.06072787e-03]
 [  1.26000000e+03   9.42769344e-04]
 [  1.27000000e+03   8.39457964e-04]
 [  1.28000000e+03   9.49165202e-04]
 [  1.29000000e+03   8.40033987e-04]
 [  1.30000000e+03   9.60244215e-04]
 [  1.31000000e+03   7.37405440e-04]
 [  1.32000000e+03   8.39766290e-04]
 [  1.33000000e+03   8.13350256e-04]
 [  1.34000000e+03   8.13845836e-04]
 [  1.35000000e+03   8.06368422e-04]
 [  1.36000000e+03   8.66328191e-04]
 [  1.37000000e+03   7.94349180e-04]
 [  1.38000000e+03   8.64449015e-04]
 [  1.39000000e+03   8.33909493e-04]
 [  1.40000000e+03   8.25901341e-04]
 [  1.41000000e+03   8.59284715e-04]
 [  1.42000000e+03   8.80539999e-04]
 [  1.43000000e+03   6.52629649e-04]
 [  1.44000000e+03   6.98186632e-04]
 [  1.45000000e+03   8.46027280e-04]
 [  1.46000000e+03   7.13806367e-04]
 [  1.47000000e+03   7.84764416e-04]
 [  1.48000000e+03   6.75049436e-04]
 [  1.49000000e+03   8.29611847e-04]
 [  1.50000000e+03   7.66571844e-04]
 [  1.51000000e+03   7.86703837e-04]
 [  1.52000000e+03   7.58278824e-04]
 [  1.53000000e+03   7.49155879e-04]
 [  1.54000000e+03   7.77323963e-04]
 [  1.55000000e+03   6.74729177e-04]
 [  1.56000000e+03   8.11565726e-04]
 [  1.57000000e+03   7.40313611e-04]
 [  1.58000000e+03   7.40257325e-04]
 [  1.59000000e+03   6.88830740e-04]
 [  1.60000000e+03   6.25791261e-04]
 [  1.61000000e+03   6.56648888e-04]
 [  1.62000000e+03   7.14924186e-04]
 [  1.63000000e+03   7.83146184e-04]
 [  1.64000000e+03   6.69811678e-04]
 [  1.65000000e+03   6.50023343e-04]
 [  1.66000000e+03   6.81165606e-04]
 [  1.67000000e+03   6.20306411e-04]
 [  1.68000000e+03   6.85493869e-04]
 [  1.69000000e+03   7.69070699e-04]
 [  1.70000000e+03   6.27239817e-04]
 [  1.71000000e+03   6.44056650e-04]
 [  1.72000000e+03   6.39265752e-04]
 [  1.73000000e+03   7.88696285e-04]
 [  1.74000000e+03   6.12740812e-04]
 [  1.75000000e+03   6.23762200e-04]
 [  1.76000000e+03   6.33345917e-04]
 [  1.77000000e+03   6.08034898e-04]
 [  1.78000000e+03   6.65509258e-04]
 [  1.79000000e+03   5.66256291e-04]
 [  1.80000000e+03   7.15761795e-04]
 [  1.81000000e+03   6.15485595e-04]
 [  1.82000000e+03   6.83100079e-04]
 [  1.83000000e+03   6.79043238e-04]
 [  1.84000000e+03   6.31776580e-04]
 [  1.85000000e+03   5.98713290e-04]
 [  1.86000000e+03   6.44068699e-04]
 [  1.87000000e+03   6.19710481e-04]
 [  1.88000000e+03   6.02419255e-04]
 [  1.89000000e+03   5.36119041e-04]
 [  1.90000000e+03   6.15597295e-04]
 [  1.91000000e+03   6.27469446e-04]
 [  1.92000000e+03   6.23598346e-04]
 [  1.93000000e+03   6.30677911e-04]
 [  1.94000000e+03   6.19192841e-04]
 [  1.95000000e+03   6.06620044e-04]
 [  1.96000000e+03   5.41625312e-04]
 [  1.97000000e+03   6.27327943e-04]
 [  1.98000000e+03   5.65266469e-04]
 [  1.99000000e+03   6.04666828e-04]
 [  2.00000000e+03   5.44412411e-04]]
initial: [  0.00000000e+00   1.25333234e-01   2.48689887e-01   3.68124553e-01
   4.81753674e-01   5.87785252e-01   6.84547106e-01   7.70513243e-01
   8.44327926e-01   9.04827052e-01   9.51056516e-01   9.82287251e-01
   9.98026728e-01   9.98026728e-01   9.82287251e-01   9.51056516e-01
   9.04827052e-01   8.44327926e-01   7.70513243e-01   6.84547106e-01
   5.87785252e-01   4.81753674e-01   3.68124553e-01   2.48689887e-01
   1.25333234e-01  -3.21624530e-16  -1.25333234e-01  -2.48689887e-01
  -3.68124553e-01  -4.81753674e-01  -5.87785252e-01  -6.84547106e-01
  -7.70513243e-01  -8.44327926e-01  -9.04827052e-01  -9.51056516e-01
  -9.82287251e-01  -9.98026728e-01  -9.98026728e-01  -9.82287251e-01
  -9.51056516e-01  -9.04827052e-01  -8.44327926e-01  -7.70513243e-01
  -6.84547106e-01  -5.87785252e-01  -4.81753674e-01  -3.68124553e-01
  -2.48689887e-01  -1.25333234e-01   6.43249060e-16   1.25333234e-01
   2.48689887e-01   3.68124553e-01   4.81753674e-01   5.87785252e-01
   6.84547106e-01   7.70513243e-01   8.44327926e-01   9.04827052e-01
   9.51056516e-01   9.82287251e-01   9.98026728e-01   9.98026728e-01
   9.82287251e-01   9.51056516e-01   9.04827052e-01   8.44327926e-01
   7.70513243e-01   6.84547106e-01]
prediction#1, output: 0.623153
prediction#2, output: 0.546655
prediction#3, output: 0.455305
prediction#4, output: 0.351394
prediction#5, output: 0.234117
prediction#6, output: 0.103909
prediction#7, output: -0.037050
prediction#8, output: -0.184471
prediction#9, output: -0.331998
prediction#10, output: -0.471859
prediction#11, output: -0.596374
prediction#12, output: -0.699932
prediction#13, output: -0.780254
prediction#14, output: -0.838137
prediction#15, output: -0.876181
prediction#16, output: -0.897489
prediction#17, output: -0.904860
prediction#18, output: -0.900461
prediction#19, output: -0.885778
prediction#20, output: -0.861674
prediction#21, output: -0.828471
prediction#22, output: -0.786029
prediction#23, output: -0.733809
prediction#24, output: -0.670939
prediction#25, output: -0.596312
prediction#26, output: -0.508751
prediction#27, output: -0.407303
prediction#28, output: -0.291689
prediction#29, output: -0.162917
prediction#30, output: -0.023900
prediction#31, output: 0.120265
prediction#32, output: 0.262749
prediction#33, output: 0.396274
prediction#34, output: 0.514726
prediction#35, output: 0.614297
prediction#36, output: 0.693699
prediction#37, output: 0.753625
prediction#38, output: 0.795938
prediction#39, output: 0.822946
prediction#40, output: 0.836923
prediction#41, output: 0.839840
prediction#42, output: 0.833264
prediction#43, output: 0.818332
prediction#44, output: 0.795768
prediction#45, output: 0.765920
prediction#46, output: 0.728779
prediction#47, output: 0.684014
prediction#48, output: 0.630987
prediction#49, output: 0.568795
prediction#50, output: 0.496340
prediction#51, output: 0.412474
prediction#52, output: 0.316239
prediction#53, output: 0.207250
prediction#54, output: 0.086166
prediction#55, output: -0.044834
prediction#56, output: -0.181762
prediction#57, output: -0.318865
prediction#58, output: -0.449229
prediction#59, output: -0.566031
prediction#60, output: -0.664133
prediction#61, output: -0.741128
prediction#62, output: -0.797244
prediction#63, output: -0.834392
prediction#64, output: -0.855096
prediction#65, output: -0.861744
prediction#66, output: -0.856241
prediction#67, output: -0.839897
prediction#68, output: -0.813451
prediction#69, output: -0.777129
prediction#70, output: -0.730709
prediction#71, output: -0.673594
prediction#72, output: -0.604907
prediction#73, output: -0.523639
prediction#74, output: -0.428893
prediction#75, output: -0.320280
prediction#76, output: -0.198447
prediction#77, output: -0.065680
prediction#78, output: 0.073725
prediction#79, output: 0.213659
prediction#80, output: 0.347169
prediction#81, output: 0.467929
prediction#82, output: 0.571500
prediction#83, output: 0.655824
prediction#84, output: 0.720923
prediction#85, output: 0.768201
prediction#86, output: 0.799713
prediction#87, output: 0.817634
prediction#88, output: 0.823937
prediction#89, output: 0.820238
prediction#90, output: 0.807747
prediction#91, output: 0.787269
prediction#92, output: 0.759228
prediction#93, output: 0.723689
prediction#94, output: 0.680383
prediction#95, output: 0.628736
prediction#96, output: 0.567897
prediction#97, output: 0.496819
prediction#98, output: 0.414388
prediction#99, output: 0.319661
prediction#100, output: 0.212233
outputs: [ 0.62315255  0.54665452  0.45530486  0.35139382  0.23411691  0.10390853
 -0.03704954 -0.18447071 -0.33199799 -0.47185934 -0.59637409 -0.69993216
 -0.78025371 -0.83813661 -0.87618113 -0.89748937 -0.90486014 -0.90046138
 -0.88577843 -0.86167377 -0.82847089 -0.7860294  -0.73380947 -0.67093927
 -0.59631169 -0.50875121 -0.40730312 -0.29168874 -0.16291696 -0.02390003
  0.12026483  0.26274908  0.39627424  0.51472646  0.61429727  0.69369882
  0.75362498  0.7959376   0.82294619  0.83692265  0.83984011  0.83326429
  0.8183316   0.79576826  0.76591957  0.72877949  0.68401432  0.63098687
  0.56879461  0.49634039  0.41247401  0.31623939  0.20725003  0.08616637
 -0.04483444 -0.18176198 -0.31886524 -0.44922858 -0.56603056 -0.66413277
 -0.74112803 -0.79724371 -0.83439213 -0.85509562 -0.86174446 -0.85624093
 -0.83989686 -0.81345129 -0.77712923 -0.73070878 -0.6735937  -0.60490686
 -0.52363855 -0.42889339 -0.32027954 -0.19844738 -0.0656803   0.07372547
  0.21365884  0.34716868  0.46792889  0.57150036  0.65582365  0.72092319
  0.76820105  0.79971325  0.81763446  0.82393724  0.82023782  0.80774677
  0.78726935  0.75922829  0.7236889   0.68038338  0.62873554  0.56789714
  0.4968195   0.41438788  0.3196609   0.21223342]

real	5m38.550s
user	3m12.109s
sys	3m27.875s
