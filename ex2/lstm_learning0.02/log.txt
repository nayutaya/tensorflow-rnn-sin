param_path: param.yaml
train_data_path: ../train_data/normal.npy
optimizer: GradientDescentOptimizer
seed: 0
num_of_output_nodes: 1
num_of_input_nodes: 1
forget_bias: 1.0
size_of_mini_batch: 100
learning_rate: 0.02
num_of_hidden_nodes: 2
length_of_sequences: 50
num_of_prediction_epochs: 100
num_of_training_epochs: 2000
train_data: [[  0.00000000e+00   1.25333234e-01]
 [  1.25333234e-01   2.48689887e-01]
 [  2.48689887e-01   3.68124553e-01]
 ..., 
 [ -3.68124553e-01  -2.48689887e-01]
 [ -2.48689887e-01  -1.25333234e-01]
 [ -1.25333234e-01   3.92877345e-15]]
train#10, train loss: 5.178598e-01
train#20, train loss: 4.989980e-01
train#30, train loss: 5.175398e-01
train#40, train loss: 5.336843e-01
train#50, train loss: 4.501205e-01
train#60, train loss: 4.665460e-01
train#70, train loss: 5.051399e-01
train#80, train loss: 4.553227e-01
train#90, train loss: 4.422649e-01
train#100, train loss: 5.339562e-01
train#110, train loss: 5.008378e-01
train#120, train loss: 5.289752e-01
train#130, train loss: 5.354017e-01
train#140, train loss: 4.873277e-01
train#150, train loss: 4.230170e-01
train#160, train loss: 4.573110e-01
train#170, train loss: 4.684450e-01
train#180, train loss: 4.574842e-01
train#190, train loss: 4.083286e-01
train#200, train loss: 3.757493e-01
train#210, train loss: 3.989440e-01
train#220, train loss: 3.375991e-01
train#230, train loss: 3.647095e-01
train#240, train loss: 2.711872e-01
train#250, train loss: 2.513455e-01
train#260, train loss: 2.645585e-01
train#270, train loss: 2.217464e-01
train#280, train loss: 1.937827e-01
train#290, train loss: 1.873496e-01
train#300, train loss: 1.764170e-01
train#310, train loss: 1.413040e-01
train#320, train loss: 1.309748e-01
train#330, train loss: 1.187912e-01
train#340, train loss: 1.120173e-01
train#350, train loss: 1.025680e-01
train#360, train loss: 8.548210e-02
train#370, train loss: 8.040916e-02
train#380, train loss: 7.721795e-02
train#390, train loss: 6.633179e-02
train#400, train loss: 6.812777e-02
train#410, train loss: 7.298394e-02
train#420, train loss: 5.787010e-02
train#430, train loss: 6.362269e-02
train#440, train loss: 6.090401e-02
train#450, train loss: 6.052181e-02
train#460, train loss: 5.739931e-02
train#470, train loss: 5.357455e-02
train#480, train loss: 5.155231e-02
train#490, train loss: 4.793866e-02
train#500, train loss: 5.054293e-02
train#510, train loss: 4.915944e-02
train#520, train loss: 4.919541e-02
train#530, train loss: 4.473815e-02
train#540, train loss: 5.068080e-02
train#550, train loss: 4.239507e-02
train#560, train loss: 3.719100e-02
train#570, train loss: 4.467141e-02
train#580, train loss: 4.086556e-02
train#590, train loss: 4.092899e-02
train#600, train loss: 3.610691e-02
train#610, train loss: 3.811004e-02
train#620, train loss: 3.787158e-02
train#630, train loss: 3.787563e-02
train#640, train loss: 3.598247e-02
train#650, train loss: 3.926979e-02
train#660, train loss: 3.345916e-02
train#670, train loss: 3.740636e-02
train#680, train loss: 3.419144e-02
train#690, train loss: 3.702447e-02
train#700, train loss: 3.090896e-02
train#710, train loss: 2.940000e-02
train#720, train loss: 3.226748e-02
train#730, train loss: 3.284617e-02
train#740, train loss: 2.803489e-02
train#750, train loss: 3.106898e-02
train#760, train loss: 2.765432e-02
train#770, train loss: 2.909089e-02
train#780, train loss: 2.686933e-02
train#790, train loss: 3.137378e-02
train#800, train loss: 3.019778e-02
train#810, train loss: 3.014914e-02
train#820, train loss: 2.725582e-02
train#830, train loss: 2.359485e-02
train#840, train loss: 2.955587e-02
train#850, train loss: 2.389438e-02
train#860, train loss: 2.707057e-02
train#870, train loss: 2.595672e-02
train#880, train loss: 2.448312e-02
train#890, train loss: 2.650992e-02
train#900, train loss: 2.349035e-02
train#910, train loss: 2.397250e-02
train#920, train loss: 2.440698e-02
train#930, train loss: 2.679972e-02
train#940, train loss: 2.287641e-02
train#950, train loss: 2.118755e-02
train#960, train loss: 2.089582e-02
train#970, train loss: 2.317781e-02
train#980, train loss: 2.315118e-02
train#990, train loss: 2.015856e-02
train#1000, train loss: 2.303772e-02
train#1010, train loss: 2.032839e-02
train#1020, train loss: 1.971517e-02
train#1030, train loss: 1.864107e-02
train#1040, train loss: 2.271465e-02
train#1050, train loss: 2.383512e-02
train#1060, train loss: 1.813058e-02
train#1070, train loss: 1.964159e-02
train#1080, train loss: 2.079775e-02
train#1090, train loss: 1.992955e-02
train#1100, train loss: 1.842727e-02
train#1110, train loss: 2.121046e-02
train#1120, train loss: 1.747663e-02
train#1130, train loss: 1.931485e-02
train#1140, train loss: 1.706968e-02
train#1150, train loss: 1.777883e-02
train#1160, train loss: 1.709504e-02
train#1170, train loss: 1.873550e-02
train#1180, train loss: 1.900260e-02
train#1190, train loss: 1.791769e-02
train#1200, train loss: 1.687023e-02
train#1210, train loss: 1.633054e-02
train#1220, train loss: 1.667778e-02
train#1230, train loss: 1.668860e-02
train#1240, train loss: 1.665387e-02
train#1250, train loss: 1.678289e-02
train#1260, train loss: 1.497083e-02
train#1270, train loss: 1.663161e-02
train#1280, train loss: 1.418329e-02
train#1290, train loss: 1.619605e-02
train#1300, train loss: 1.540797e-02
train#1310, train loss: 1.592297e-02
train#1320, train loss: 1.432284e-02
train#1330, train loss: 1.434232e-02
train#1340, train loss: 1.585827e-02
train#1350, train loss: 1.530384e-02
train#1360, train loss: 1.301979e-02
train#1370, train loss: 1.288183e-02
train#1380, train loss: 1.443283e-02
train#1390, train loss: 1.423288e-02
train#1400, train loss: 1.461511e-02
train#1410, train loss: 1.582203e-02
train#1420, train loss: 1.426352e-02
train#1430, train loss: 1.305506e-02
train#1440, train loss: 1.471806e-02
train#1450, train loss: 1.410278e-02
train#1460, train loss: 1.396724e-02
train#1470, train loss: 1.320013e-02
train#1480, train loss: 1.213975e-02
train#1490, train loss: 1.316791e-02
train#1500, train loss: 1.143375e-02
train#1510, train loss: 1.185412e-02
train#1520, train loss: 1.281941e-02
train#1530, train loss: 1.289500e-02
train#1540, train loss: 1.259908e-02
train#1550, train loss: 1.239970e-02
train#1560, train loss: 1.202786e-02
train#1570, train loss: 1.174298e-02
train#1580, train loss: 1.139421e-02
train#1590, train loss: 1.088944e-02
train#1600, train loss: 1.329666e-02
train#1610, train loss: 1.368065e-02
train#1620, train loss: 1.077016e-02
train#1630, train loss: 1.099609e-02
train#1640, train loss: 1.213187e-02
train#1650, train loss: 1.021610e-02
train#1660, train loss: 9.667902e-03
train#1670, train loss: 1.116369e-02
train#1680, train loss: 1.071826e-02
train#1690, train loss: 1.035271e-02
train#1700, train loss: 1.082382e-02
train#1710, train loss: 9.854119e-03
train#1720, train loss: 1.079993e-02
train#1730, train loss: 1.087917e-02
train#1740, train loss: 9.168677e-03
train#1750, train loss: 1.058698e-02
train#1760, train loss: 9.780487e-03
train#1770, train loss: 1.043475e-02
train#1780, train loss: 1.054887e-02
train#1790, train loss: 1.025324e-02
train#1800, train loss: 9.211089e-03
train#1810, train loss: 9.539766e-03
train#1820, train loss: 8.722936e-03
train#1830, train loss: 8.773645e-03
train#1840, train loss: 8.851408e-03
train#1850, train loss: 9.624203e-03
train#1860, train loss: 7.605155e-03
train#1870, train loss: 8.912044e-03
train#1880, train loss: 8.456364e-03
train#1890, train loss: 9.039036e-03
train#1900, train loss: 9.326696e-03
train#1910, train loss: 8.618741e-03
train#1920, train loss: 7.981301e-03
train#1930, train loss: 9.297179e-03
train#1940, train loss: 8.177524e-03
train#1950, train loss: 8.426525e-03
train#1960, train loss: 8.424858e-03
train#1970, train loss: 7.939405e-03
train#1980, train loss: 7.883090e-03
train#1990, train loss: 7.140182e-03
train#2000, train loss: 7.141339e-03
losses: [[  1.00000000e+01   5.17859817e-01]
 [  2.00000000e+01   4.98998046e-01]
 [  3.00000000e+01   5.17539799e-01]
 [  4.00000000e+01   5.33684254e-01]
 [  5.00000000e+01   4.50120538e-01]
 [  6.00000000e+01   4.66546029e-01]
 [  7.00000000e+01   5.05139887e-01]
 [  8.00000000e+01   4.55322713e-01]
 [  9.00000000e+01   4.42264915e-01]
 [  1.00000000e+02   5.33956170e-01]
 [  1.10000000e+02   5.00837803e-01]
 [  1.20000000e+02   5.28975248e-01]
 [  1.30000000e+02   5.35401702e-01]
 [  1.40000000e+02   4.87327665e-01]
 [  1.50000000e+02   4.23016965e-01]
 [  1.60000000e+02   4.57310975e-01]
 [  1.70000000e+02   4.68445003e-01]
 [  1.80000000e+02   4.57484215e-01]
 [  1.90000000e+02   4.08328593e-01]
 [  2.00000000e+02   3.75749350e-01]
 [  2.10000000e+02   3.98944020e-01]
 [  2.20000000e+02   3.37599069e-01]
 [  2.30000000e+02   3.64709496e-01]
 [  2.40000000e+02   2.71187246e-01]
 [  2.50000000e+02   2.51345515e-01]
 [  2.60000000e+02   2.64558494e-01]
 [  2.70000000e+02   2.21746430e-01]
 [  2.80000000e+02   1.93782657e-01]
 [  2.90000000e+02   1.87349617e-01]
 [  3.00000000e+02   1.76416963e-01]
 [  3.10000000e+02   1.41304001e-01]
 [  3.20000000e+02   1.30974799e-01]
 [  3.30000000e+02   1.18791178e-01]
 [  3.40000000e+02   1.12017252e-01]
 [  3.50000000e+02   1.02567978e-01]
 [  3.60000000e+02   8.54820982e-02]
 [  3.70000000e+02   8.04091617e-02]
 [  3.80000000e+02   7.72179514e-02]
 [  3.90000000e+02   6.63317889e-02]
 [  4.00000000e+02   6.81277737e-02]
 [  4.10000000e+02   7.29839429e-02]
 [  4.20000000e+02   5.78701012e-02]
 [  4.30000000e+02   6.36226907e-02]
 [  4.40000000e+02   6.09040111e-02]
 [  4.50000000e+02   6.05218075e-02]
 [  4.60000000e+02   5.73993102e-02]
 [  4.70000000e+02   5.35745509e-02]
 [  4.80000000e+02   5.15523143e-02]
 [  4.90000000e+02   4.79386561e-02]
 [  5.00000000e+02   5.05429320e-02]
 [  5.10000000e+02   4.91594411e-02]
 [  5.20000000e+02   4.91954088e-02]
 [  5.30000000e+02   4.47381511e-02]
 [  5.40000000e+02   5.06808050e-02]
 [  5.50000000e+02   4.23950665e-02]
 [  5.60000000e+02   3.71910036e-02]
 [  5.70000000e+02   4.46714051e-02]
 [  5.80000000e+02   4.08655629e-02]
 [  5.90000000e+02   4.09289896e-02]
 [  6.00000000e+02   3.61069068e-02]
 [  6.10000000e+02   3.81100364e-02]
 [  6.20000000e+02   3.78715843e-02]
 [  6.30000000e+02   3.78756300e-02]
 [  6.40000000e+02   3.59824747e-02]
 [  6.50000000e+02   3.92697901e-02]
 [  6.60000000e+02   3.34591568e-02]
 [  6.70000000e+02   3.74063626e-02]
 [  6.80000000e+02   3.41914445e-02]
 [  6.90000000e+02   3.70244682e-02]
 [  7.00000000e+02   3.09089608e-02]
 [  7.10000000e+02   2.93999966e-02]
 [  7.20000000e+02   3.22674774e-02]
 [  7.30000000e+02   3.28461677e-02]
 [  7.40000000e+02   2.80348882e-02]
 [  7.50000000e+02   3.10689788e-02]
 [  7.60000000e+02   2.76543181e-02]
 [  7.70000000e+02   2.90908907e-02]
 [  7.80000000e+02   2.68693343e-02]
 [  7.90000000e+02   3.13737765e-02]
 [  8.00000000e+02   3.01977824e-02]
 [  8.10000000e+02   3.01491395e-02]
 [  8.20000000e+02   2.72558220e-02]
 [  8.30000000e+02   2.35948507e-02]
 [  8.40000000e+02   2.95558739e-02]
 [  8.50000000e+02   2.38943808e-02]
 [  8.60000000e+02   2.70705745e-02]
 [  8.70000000e+02   2.59567164e-02]
 [  8.80000000e+02   2.44831219e-02]
 [  8.90000000e+02   2.65099239e-02]
 [  9.00000000e+02   2.34903544e-02]
 [  9.10000000e+02   2.39725038e-02]
 [  9.20000000e+02   2.44069807e-02]
 [  9.30000000e+02   2.67997161e-02]
 [  9.40000000e+02   2.28764098e-02]
 [  9.50000000e+02   2.11875495e-02]
 [  9.60000000e+02   2.08958201e-02]
 [  9.70000000e+02   2.31778137e-02]
 [  9.80000000e+02   2.31511835e-02]
 [  9.90000000e+02   2.01585628e-02]
 [  1.00000000e+03   2.30377223e-02]
 [  1.01000000e+03   2.03283932e-02]
 [  1.02000000e+03   1.97151657e-02]
 [  1.03000000e+03   1.86410733e-02]
 [  1.04000000e+03   2.27146503e-02]
 [  1.05000000e+03   2.38351244e-02]
 [  1.06000000e+03   1.81305818e-02]
 [  1.07000000e+03   1.96415894e-02]
 [  1.08000000e+03   2.07977481e-02]
 [  1.09000000e+03   1.99295487e-02]
 [  1.10000000e+03   1.84272658e-02]
 [  1.11000000e+03   2.12104600e-02]
 [  1.12000000e+03   1.74766257e-02]
 [  1.13000000e+03   1.93148535e-02]
 [  1.14000000e+03   1.70696788e-02]
 [  1.15000000e+03   1.77788325e-02]
 [  1.16000000e+03   1.70950405e-02]
 [  1.17000000e+03   1.87355001e-02]
 [  1.18000000e+03   1.90025978e-02]
 [  1.19000000e+03   1.79176908e-02]
 [  1.20000000e+03   1.68702286e-02]
 [  1.21000000e+03   1.63305420e-02]
 [  1.22000000e+03   1.66777819e-02]
 [  1.23000000e+03   1.66886039e-02]
 [  1.24000000e+03   1.66538712e-02]
 [  1.25000000e+03   1.67828854e-02]
 [  1.26000000e+03   1.49708334e-02]
 [  1.27000000e+03   1.66316107e-02]
 [  1.28000000e+03   1.41832912e-02]
 [  1.29000000e+03   1.61960535e-02]
 [  1.30000000e+03   1.54079655e-02]
 [  1.31000000e+03   1.59229729e-02]
 [  1.32000000e+03   1.43228360e-02]
 [  1.33000000e+03   1.43423248e-02]
 [  1.34000000e+03   1.58582684e-02]
 [  1.35000000e+03   1.53038381e-02]
 [  1.36000000e+03   1.30197909e-02]
 [  1.37000000e+03   1.28818275e-02]
 [  1.38000000e+03   1.44328317e-02]
 [  1.39000000e+03   1.42328823e-02]
 [  1.40000000e+03   1.46151092e-02]
 [  1.41000000e+03   1.58220306e-02]
 [  1.42000000e+03   1.42635154e-02]
 [  1.43000000e+03   1.30550573e-02]
 [  1.44000000e+03   1.47180595e-02]
 [  1.45000000e+03   1.41027831e-02]
 [  1.46000000e+03   1.39672421e-02]
 [  1.47000000e+03   1.32001350e-02]
 [  1.48000000e+03   1.21397497e-02]
 [  1.49000000e+03   1.31679084e-02]
 [  1.50000000e+03   1.14337495e-02]
 [  1.51000000e+03   1.18541168e-02]
 [  1.52000000e+03   1.28194140e-02]
 [  1.53000000e+03   1.28950002e-02]
 [  1.54000000e+03   1.25990808e-02]
 [  1.55000000e+03   1.23996986e-02]
 [  1.56000000e+03   1.20278625e-02]
 [  1.57000000e+03   1.17429821e-02]
 [  1.58000000e+03   1.13942139e-02]
 [  1.59000000e+03   1.08894408e-02]
 [  1.60000000e+03   1.32966591e-02]
 [  1.61000000e+03   1.36806490e-02]
 [  1.62000000e+03   1.07701560e-02]
 [  1.63000000e+03   1.09960940e-02]
 [  1.64000000e+03   1.21318670e-02]
 [  1.65000000e+03   1.02160964e-02]
 [  1.66000000e+03   9.66790225e-03]
 [  1.67000000e+03   1.11636901e-02]
 [  1.68000000e+03   1.07182637e-02]
 [  1.69000000e+03   1.03527093e-02]
 [  1.70000000e+03   1.08238189e-02]
 [  1.71000000e+03   9.85411927e-03]
 [  1.72000000e+03   1.07999323e-02]
 [  1.73000000e+03   1.08791664e-02]
 [  1.74000000e+03   9.16867703e-03]
 [  1.75000000e+03   1.05869761e-02]
 [  1.76000000e+03   9.78048705e-03]
 [  1.77000000e+03   1.04347467e-02]
 [  1.78000000e+03   1.05488654e-02]
 [  1.79000000e+03   1.02532366e-02]
 [  1.80000000e+03   9.21108946e-03]
 [  1.81000000e+03   9.53976624e-03]
 [  1.82000000e+03   8.72293580e-03]
 [  1.83000000e+03   8.77364539e-03]
 [  1.84000000e+03   8.85140803e-03]
 [  1.85000000e+03   9.62420274e-03]
 [  1.86000000e+03   7.60515500e-03]
 [  1.87000000e+03   8.91204365e-03]
 [  1.88000000e+03   8.45636427e-03]
 [  1.89000000e+03   9.03903600e-03]
 [  1.90000000e+03   9.32669640e-03]
 [  1.91000000e+03   8.61874130e-03]
 [  1.92000000e+03   7.98130129e-03]
 [  1.93000000e+03   9.29717906e-03]
 [  1.94000000e+03   8.17752443e-03]
 [  1.95000000e+03   8.42652470e-03]
 [  1.96000000e+03   8.42485763e-03]
 [  1.97000000e+03   7.93940481e-03]
 [  1.98000000e+03   7.88308959e-03]
 [  1.99000000e+03   7.14018242e-03]
 [  2.00000000e+03   7.14133866e-03]]
initial: [  0.00000000e+00   1.25333234e-01   2.48689887e-01   3.68124553e-01
   4.81753674e-01   5.87785252e-01   6.84547106e-01   7.70513243e-01
   8.44327926e-01   9.04827052e-01   9.51056516e-01   9.82287251e-01
   9.98026728e-01   9.98026728e-01   9.82287251e-01   9.51056516e-01
   9.04827052e-01   8.44327926e-01   7.70513243e-01   6.84547106e-01
   5.87785252e-01   4.81753674e-01   3.68124553e-01   2.48689887e-01
   1.25333234e-01  -3.21624530e-16  -1.25333234e-01  -2.48689887e-01
  -3.68124553e-01  -4.81753674e-01  -5.87785252e-01  -6.84547106e-01
  -7.70513243e-01  -8.44327926e-01  -9.04827052e-01  -9.51056516e-01
  -9.82287251e-01  -9.98026728e-01  -9.98026728e-01  -9.82287251e-01
  -9.51056516e-01  -9.04827052e-01  -8.44327926e-01  -7.70513243e-01
  -6.84547106e-01  -5.87785252e-01  -4.81753674e-01  -3.68124553e-01
  -2.48689887e-01  -1.25333234e-01]
prediction#1, output: -0.095433
prediction#2, output: -0.060627
prediction#3, output: -0.033166
prediction#4, output: -0.012808
prediction#5, output: 0.002106
prediction#6, output: 0.012987
prediction#7, output: 0.020952
prediction#8, output: 0.026849
prediction#9, output: 0.031302
prediction#10, output: 0.034762
prediction#11, output: 0.037551
prediction#12, output: 0.039899
prediction#13, output: 0.041967
prediction#14, output: 0.043872
prediction#15, output: 0.045695
prediction#16, output: 0.047495
prediction#17, output: 0.049315
prediction#18, output: 0.051189
prediction#19, output: 0.053140
prediction#20, output: 0.055190
prediction#21, output: 0.057354
prediction#22, output: 0.059647
prediction#23, output: 0.062083
prediction#24, output: 0.064674
prediction#25, output: 0.067434
prediction#26, output: 0.070374
prediction#27, output: 0.073509
prediction#28, output: 0.076850
prediction#29, output: 0.080412
prediction#30, output: 0.084210
prediction#31, output: 0.088258
prediction#32, output: 0.092573
prediction#33, output: 0.097172
prediction#34, output: 0.102073
prediction#35, output: 0.107293
prediction#36, output: 0.112852
prediction#37, output: 0.118770
prediction#38, output: 0.125068
prediction#39, output: 0.131768
prediction#40, output: 0.138890
prediction#41, output: 0.146459
prediction#42, output: 0.154495
prediction#43, output: 0.163022
prediction#44, output: 0.172061
prediction#45, output: 0.181635
prediction#46, output: 0.191764
prediction#47, output: 0.202466
prediction#48, output: 0.213759
prediction#49, output: 0.225655
prediction#50, output: 0.238164
prediction#51, output: 0.251293
prediction#52, output: 0.265041
prediction#53, output: 0.279403
prediction#54, output: 0.294363
prediction#55, output: 0.309901
prediction#56, output: 0.325985
prediction#57, output: 0.342575
prediction#58, output: 0.359619
prediction#59, output: 0.377055
prediction#60, output: 0.394812
prediction#61, output: 0.412808
prediction#62, output: 0.430952
prediction#63, output: 0.449149
prediction#64, output: 0.467296
prediction#65, output: 0.485289
prediction#66, output: 0.503026
prediction#67, output: 0.520405
prediction#68, output: 0.537332
prediction#69, output: 0.553721
prediction#70, output: 0.569497
prediction#71, output: 0.584594
prediction#72, output: 0.598963
prediction#73, output: 0.612566
prediction#74, output: 0.625379
prediction#75, output: 0.637390
prediction#76, output: 0.648599
prediction#77, output: 0.659015
prediction#78, output: 0.668657
prediction#79, output: 0.677552
prediction#80, output: 0.685729
prediction#81, output: 0.693224
prediction#82, output: 0.700075
prediction#83, output: 0.706323
prediction#84, output: 0.712006
prediction#85, output: 0.717167
prediction#86, output: 0.721844
prediction#87, output: 0.726076
prediction#88, output: 0.729900
prediction#89, output: 0.733350
prediction#90, output: 0.736459
prediction#91, output: 0.739258
prediction#92, output: 0.741776
prediction#93, output: 0.744038
prediction#94, output: 0.746069
prediction#95, output: 0.747892
prediction#96, output: 0.749527
prediction#97, output: 0.750993
prediction#98, output: 0.752305
prediction#99, output: 0.753481
prediction#100, output: 0.754533
outputs: [-0.09543324 -0.06062651 -0.03316562 -0.01280821  0.00210615  0.01298707
  0.02095232  0.02684927  0.03130194  0.03476161  0.03755079  0.03989857
  0.04196724  0.04387192  0.04569472  0.04749483  0.04931542  0.05118895
  0.05314033  0.05518964  0.05735358  0.0596468   0.06208278  0.06467434
  0.06743403  0.07037447  0.07350861  0.07684982  0.08041193  0.08420961
  0.0882581   0.09257342  0.09717241  0.10207273  0.10729285  0.11285202
  0.11877032  0.12506846  0.13176787  0.13889049  0.14645866  0.1544949
  0.16302176  0.17206141  0.18163542  0.19176415  0.20246631  0.21375853
  0.22565451  0.23816422  0.25129312  0.26504138  0.27940261  0.29436323
  0.30990121  0.32598549  0.34257519  0.35961902  0.37705529  0.39481199
  0.41280761  0.43095213  0.44914871  0.46729577  0.48528934  0.50302589
  0.52040505  0.53733224  0.55372131  0.56949651  0.58459395  0.59896296
  0.61256611  0.62537903  0.63738996  0.64859867  0.65901494  0.66865742
  0.67755157  0.68572861  0.69322371  0.70007521  0.70632255  0.71200639
  0.71716714  0.72184432  0.72607636  0.72990006  0.73334992  0.73645908
  0.73925811  0.74177569  0.74403799  0.74606949  0.74789238  0.74952716
  0.75099254  0.75230527  0.75348091  0.75453323]

real	3m46.852s
user	2m13.292s
sys	2m23.887s
