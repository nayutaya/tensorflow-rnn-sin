param_path: param.yaml
num_of_prediction_epochs: 100
num_of_hidden_nodes: 4
learning_rate: 0.1
train_data_path: ../train_data/normal.npy
size_of_mini_batch: 100
length_of_sequences: 50
num_of_input_nodes: 1
seed: 0
num_of_training_epochs: 2000
optimizer: GradientDescentOptimizer
forget_bias: 1.0
num_of_output_nodes: 1
train_data: [[  0.00000000e+00   1.25333234e-01]
 [  1.25333234e-01   2.48689887e-01]
 [  2.48689887e-01   3.68124553e-01]
 ..., 
 [ -3.68124553e-01  -2.48689887e-01]
 [ -2.48689887e-01  -1.25333234e-01]
 [ -1.25333234e-01   3.92877345e-15]]
train#10, train loss: 5.211785e-01
train#20, train loss: 4.750079e-01
train#30, train loss: 3.989320e-01
train#40, train loss: 2.223367e-01
train#50, train loss: 7.357865e-02
train#60, train loss: 2.557583e-02
train#70, train loss: 9.142950e-03
train#80, train loss: 5.437297e-03
train#90, train loss: 3.298388e-03
train#100, train loss: 4.131688e-03
train#110, train loss: 3.829322e-03
train#120, train loss: 2.855771e-03
train#130, train loss: 3.049911e-03
train#140, train loss: 2.326770e-03
train#150, train loss: 1.983223e-03
train#160, train loss: 1.794923e-03
train#170, train loss: 1.742517e-03
train#180, train loss: 1.631805e-03
train#190, train loss: 1.457281e-03
train#200, train loss: 1.351943e-03
train#210, train loss: 1.261320e-03
train#220, train loss: 1.078368e-03
train#230, train loss: 1.057961e-03
train#240, train loss: 1.266620e-03
train#250, train loss: 1.131732e-03
train#260, train loss: 9.502327e-04
train#270, train loss: 9.410243e-04
train#280, train loss: 9.988489e-04
train#290, train loss: 8.943347e-04
train#300, train loss: 1.002357e-03
train#310, train loss: 9.007626e-04
train#320, train loss: 8.898596e-04
train#330, train loss: 8.924526e-04
train#340, train loss: 8.647341e-04
train#350, train loss: 9.398753e-04
train#360, train loss: 7.341020e-04
train#370, train loss: 7.665996e-04
train#380, train loss: 7.706580e-04
train#390, train loss: 7.361383e-04
train#400, train loss: 6.592497e-04
train#410, train loss: 7.439054e-04
train#420, train loss: 6.928241e-04
train#430, train loss: 6.977546e-04
train#440, train loss: 5.670316e-04
train#450, train loss: 6.254705e-04
train#460, train loss: 6.989661e-04
train#470, train loss: 5.817568e-04
train#480, train loss: 5.755038e-04
train#490, train loss: 5.765786e-04
train#500, train loss: 5.585692e-04
train#510, train loss: 6.113572e-04
train#520, train loss: 5.870522e-04
train#530, train loss: 7.056862e-04
train#540, train loss: 4.983433e-04
train#550, train loss: 6.237815e-04
train#560, train loss: 6.011769e-04
train#570, train loss: 5.830326e-04
train#580, train loss: 4.564184e-04
train#590, train loss: 4.560101e-04
train#600, train loss: 5.729162e-04
train#610, train loss: 5.829300e-04
train#620, train loss: 4.795736e-04
train#630, train loss: 4.723688e-04
train#640, train loss: 4.883677e-04
train#650, train loss: 4.770971e-04
train#660, train loss: 4.929555e-04
train#670, train loss: 4.328894e-04
train#680, train loss: 5.053974e-04
train#690, train loss: 4.796994e-04
train#700, train loss: 4.449765e-04
train#710, train loss: 4.490948e-04
train#720, train loss: 3.942765e-04
train#730, train loss: 4.334656e-04
train#740, train loss: 4.728390e-04
train#750, train loss: 3.558029e-04
train#760, train loss: 3.716014e-04
train#770, train loss: 3.687759e-04
train#780, train loss: 4.016292e-04
train#790, train loss: 3.928109e-04
train#800, train loss: 3.712209e-04
train#810, train loss: 3.334778e-04
train#820, train loss: 3.789632e-04
train#830, train loss: 3.669447e-04
train#840, train loss: 3.645117e-04
train#850, train loss: 3.228370e-04
train#860, train loss: 3.228463e-04
train#870, train loss: 3.266694e-04
train#880, train loss: 2.982700e-04
train#890, train loss: 2.813359e-04
train#900, train loss: 3.052171e-04
train#910, train loss: 3.167103e-04
train#920, train loss: 2.595095e-04
train#930, train loss: 3.010276e-04
train#940, train loss: 2.761890e-04
train#950, train loss: 3.048817e-04
train#960, train loss: 2.967467e-04
train#970, train loss: 3.124707e-04
train#980, train loss: 3.137776e-04
train#990, train loss: 3.015888e-04
train#1000, train loss: 2.998707e-04
train#1010, train loss: 2.942934e-04
train#1020, train loss: 2.277874e-04
train#1030, train loss: 2.910407e-04
train#1040, train loss: 2.604942e-04
train#1050, train loss: 2.491183e-04
train#1060, train loss: 2.509906e-04
train#1070, train loss: 2.484088e-04
train#1080, train loss: 2.724401e-04
train#1090, train loss: 2.456503e-04
train#1100, train loss: 2.132277e-04
train#1110, train loss: 2.552504e-04
train#1120, train loss: 2.573628e-04
train#1130, train loss: 2.368154e-04
train#1140, train loss: 2.034505e-04
train#1150, train loss: 2.418407e-04
train#1160, train loss: 2.070969e-04
train#1170, train loss: 1.627932e-04
train#1180, train loss: 2.173249e-04
train#1190, train loss: 1.869585e-04
train#1200, train loss: 2.207565e-04
train#1210, train loss: 2.009859e-04
train#1220, train loss: 1.820072e-04
train#1230, train loss: 2.249569e-04
train#1240, train loss: 1.781022e-04
train#1250, train loss: 2.100404e-04
train#1260, train loss: 1.577515e-04
train#1270, train loss: 1.792802e-04
train#1280, train loss: 1.738869e-04
train#1290, train loss: 1.400781e-04
train#1300, train loss: 1.821247e-04
train#1310, train loss: 1.812374e-04
train#1320, train loss: 1.559749e-04
train#1330, train loss: 1.976054e-04
train#1340, train loss: 1.616444e-04
train#1350, train loss: 1.545065e-04
train#1360, train loss: 1.652802e-04
train#1370, train loss: 1.677396e-04
train#1380, train loss: 1.652639e-04
train#1390, train loss: 1.526967e-04
train#1400, train loss: 1.772382e-04
train#1410, train loss: 1.209428e-04
train#1420, train loss: 1.545882e-04
train#1430, train loss: 1.556525e-04
train#1440, train loss: 1.553683e-04
train#1450, train loss: 1.492277e-04
train#1460, train loss: 1.540489e-04
train#1470, train loss: 1.419022e-04
train#1480, train loss: 1.542288e-04
train#1490, train loss: 1.380375e-04
train#1500, train loss: 1.415477e-04
train#1510, train loss: 1.530156e-04
train#1520, train loss: 1.163702e-04
train#1530, train loss: 1.292876e-04
train#1540, train loss: 1.201984e-04
train#1550, train loss: 1.215325e-04
train#1560, train loss: 1.130888e-04
train#1570, train loss: 1.251129e-04
train#1580, train loss: 1.286698e-04
train#1590, train loss: 1.343954e-04
train#1600, train loss: 9.681478e-05
train#1610, train loss: 1.116916e-04
train#1620, train loss: 1.378275e-04
train#1630, train loss: 9.692011e-05
train#1640, train loss: 1.102140e-04
train#1650, train loss: 1.376932e-04
train#1660, train loss: 1.398189e-04
train#1670, train loss: 9.156829e-05
train#1680, train loss: 8.861601e-05
train#1690, train loss: 1.030469e-04
train#1700, train loss: 1.194232e-04
train#1710, train loss: 9.352460e-05
train#1720, train loss: 1.003042e-04
train#1730, train loss: 2.121550e-04
train#1740, train loss: 9.964027e-05
train#1750, train loss: 1.091243e-04
train#1760, train loss: 8.636522e-05
train#1770, train loss: 8.321840e-05
train#1780, train loss: 9.595885e-05
train#1790, train loss: 9.597273e-05
train#1800, train loss: 1.102133e-04
train#1810, train loss: 9.140185e-05
train#1820, train loss: 8.824967e-05
train#1830, train loss: 9.176599e-05
train#1840, train loss: 7.309744e-05
train#1850, train loss: 1.063753e-04
train#1860, train loss: 9.897172e-05
train#1870, train loss: 7.512425e-05
train#1880, train loss: 8.524046e-05
train#1890, train loss: 8.632345e-05
train#1900, train loss: 7.766233e-05
train#1910, train loss: 7.472674e-05
train#1920, train loss: 1.048125e-04
train#1930, train loss: 8.309283e-05
train#1940, train loss: 1.110872e-04
train#1950, train loss: 1.013333e-04
train#1960, train loss: 7.379666e-05
train#1970, train loss: 6.899976e-05
train#1980, train loss: 9.194376e-05
train#1990, train loss: 6.955712e-05
train#2000, train loss: 6.190849e-05
losses: [[  1.00000000e+01   5.21178484e-01]
 [  2.00000000e+01   4.75007892e-01]
 [  3.00000000e+01   3.98932010e-01]
 [  4.00000000e+01   2.22336680e-01]
 [  5.00000000e+01   7.35786483e-02]
 [  6.00000000e+01   2.55758259e-02]
 [  7.00000000e+01   9.14295018e-03]
 [  8.00000000e+01   5.43729728e-03]
 [  9.00000000e+01   3.29838810e-03]
 [  1.00000000e+02   4.13168827e-03]
 [  1.10000000e+02   3.82932182e-03]
 [  1.20000000e+02   2.85577145e-03]
 [  1.30000000e+02   3.04991123e-03]
 [  1.40000000e+02   2.32677022e-03]
 [  1.50000000e+02   1.98322325e-03]
 [  1.60000000e+02   1.79492251e-03]
 [  1.70000000e+02   1.74251711e-03]
 [  1.80000000e+02   1.63180474e-03]
 [  1.90000000e+02   1.45728095e-03]
 [  2.00000000e+02   1.35194277e-03]
 [  2.10000000e+02   1.26131997e-03]
 [  2.20000000e+02   1.07836840e-03]
 [  2.30000000e+02   1.05796137e-03]
 [  2.40000000e+02   1.26661954e-03]
 [  2.50000000e+02   1.13173237e-03]
 [  2.60000000e+02   9.50232730e-04]
 [  2.70000000e+02   9.41024278e-04]
 [  2.80000000e+02   9.98848933e-04]
 [  2.90000000e+02   8.94334749e-04]
 [  3.00000000e+02   1.00235734e-03]
 [  3.10000000e+02   9.00762621e-04]
 [  3.20000000e+02   8.89859570e-04]
 [  3.30000000e+02   8.92452605e-04]
 [  3.40000000e+02   8.64734116e-04]
 [  3.50000000e+02   9.39875317e-04]
 [  3.60000000e+02   7.34102039e-04]
 [  3.70000000e+02   7.66599609e-04]
 [  3.80000000e+02   7.70658022e-04]
 [  3.90000000e+02   7.36138318e-04]
 [  4.00000000e+02   6.59249723e-04]
 [  4.10000000e+02   7.43905432e-04]
 [  4.20000000e+02   6.92824076e-04]
 [  4.30000000e+02   6.97754615e-04]
 [  4.40000000e+02   5.67031559e-04]
 [  4.50000000e+02   6.25470479e-04]
 [  4.60000000e+02   6.98966091e-04]
 [  4.70000000e+02   5.81756816e-04]
 [  4.80000000e+02   5.75503800e-04]
 [  4.90000000e+02   5.76578605e-04]
 [  5.00000000e+02   5.58569154e-04]
 [  5.10000000e+02   6.11357216e-04]
 [  5.20000000e+02   5.87052200e-04]
 [  5.30000000e+02   7.05686223e-04]
 [  5.40000000e+02   4.98343259e-04]
 [  5.50000000e+02   6.23781467e-04]
 [  5.60000000e+02   6.01176871e-04]
 [  5.70000000e+02   5.83032612e-04]
 [  5.80000000e+02   4.56418406e-04]
 [  5.90000000e+02   4.56010108e-04]
 [  6.00000000e+02   5.72916178e-04]
 [  6.10000000e+02   5.82930050e-04]
 [  6.20000000e+02   4.79573559e-04]
 [  6.30000000e+02   4.72368760e-04]
 [  6.40000000e+02   4.88367747e-04]
 [  6.50000000e+02   4.77097143e-04]
 [  6.60000000e+02   4.92955500e-04]
 [  6.70000000e+02   4.32889385e-04]
 [  6.80000000e+02   5.05397387e-04]
 [  6.90000000e+02   4.79699374e-04]
 [  7.00000000e+02   4.44976467e-04]
 [  7.10000000e+02   4.49094834e-04]
 [  7.20000000e+02   3.94276489e-04]
 [  7.30000000e+02   4.33465553e-04]
 [  7.40000000e+02   4.72839019e-04]
 [  7.50000000e+02   3.55802855e-04]
 [  7.60000000e+02   3.71601403e-04]
 [  7.70000000e+02   3.68775945e-04]
 [  7.80000000e+02   4.01629222e-04]
 [  7.90000000e+02   3.92810878e-04]
 [  8.00000000e+02   3.71220871e-04]
 [  8.10000000e+02   3.33477830e-04]
 [  8.20000000e+02   3.78963246e-04]
 [  8.30000000e+02   3.66944732e-04]
 [  8.40000000e+02   3.64511681e-04]
 [  8.50000000e+02   3.22837033e-04]
 [  8.60000000e+02   3.22846317e-04]
 [  8.70000000e+02   3.26669367e-04]
 [  8.80000000e+02   2.98270024e-04]
 [  8.90000000e+02   2.81335902e-04]
 [  9.00000000e+02   3.05217109e-04]
 [  9.10000000e+02   3.16710328e-04]
 [  9.20000000e+02   2.59509456e-04]
 [  9.30000000e+02   3.01027583e-04]
 [  9.40000000e+02   2.76188977e-04]
 [  9.50000000e+02   3.04881745e-04]
 [  9.60000000e+02   2.96746672e-04]
 [  9.70000000e+02   3.12470715e-04]
 [  9.80000000e+02   3.13777564e-04]
 [  9.90000000e+02   3.01588821e-04]
 [  1.00000000e+03   2.99870735e-04]
 [  1.01000000e+03   2.94293364e-04]
 [  1.02000000e+03   2.27787386e-04]
 [  1.03000000e+03   2.91040662e-04]
 [  1.04000000e+03   2.60494155e-04]
 [  1.05000000e+03   2.49118282e-04]
 [  1.06000000e+03   2.50990590e-04]
 [  1.07000000e+03   2.48408760e-04]
 [  1.08000000e+03   2.72440113e-04]
 [  1.09000000e+03   2.45650270e-04]
 [  1.10000000e+03   2.13227715e-04]
 [  1.11000000e+03   2.55250401e-04]
 [  1.12000000e+03   2.57362844e-04]
 [  1.13000000e+03   2.36815438e-04]
 [  1.14000000e+03   2.03450472e-04]
 [  1.15000000e+03   2.41840738e-04]
 [  1.16000000e+03   2.07096949e-04]
 [  1.17000000e+03   1.62793192e-04]
 [  1.18000000e+03   2.17324909e-04]
 [  1.19000000e+03   1.86958467e-04]
 [  1.20000000e+03   2.20756498e-04]
 [  1.21000000e+03   2.00985931e-04]
 [  1.22000000e+03   1.82007178e-04]
 [  1.23000000e+03   2.24956893e-04]
 [  1.24000000e+03   1.78102200e-04]
 [  1.25000000e+03   2.10040365e-04]
 [  1.26000000e+03   1.57751536e-04]
 [  1.27000000e+03   1.79280192e-04]
 [  1.28000000e+03   1.73886860e-04]
 [  1.29000000e+03   1.40078118e-04]
 [  1.30000000e+03   1.82124655e-04]
 [  1.31000000e+03   1.81237439e-04]
 [  1.32000000e+03   1.55974863e-04]
 [  1.33000000e+03   1.97605375e-04]
 [  1.34000000e+03   1.61644406e-04]
 [  1.35000000e+03   1.54506488e-04]
 [  1.36000000e+03   1.65280231e-04]
 [  1.37000000e+03   1.67739636e-04]
 [  1.38000000e+03   1.65263933e-04]
 [  1.39000000e+03   1.52696695e-04]
 [  1.40000000e+03   1.77238180e-04]
 [  1.41000000e+03   1.20942816e-04]
 [  1.42000000e+03   1.54588182e-04]
 [  1.43000000e+03   1.55652480e-04]
 [  1.44000000e+03   1.55368267e-04]
 [  1.45000000e+03   1.49227693e-04]
 [  1.46000000e+03   1.54048888e-04]
 [  1.47000000e+03   1.41902186e-04]
 [  1.48000000e+03   1.54228750e-04]
 [  1.49000000e+03   1.38037518e-04]
 [  1.50000000e+03   1.41547687e-04]
 [  1.51000000e+03   1.53015630e-04]
 [  1.52000000e+03   1.16370182e-04]
 [  1.53000000e+03   1.29287626e-04]
 [  1.54000000e+03   1.20198391e-04]
 [  1.55000000e+03   1.21532452e-04]
 [  1.56000000e+03   1.13088849e-04]
 [  1.57000000e+03   1.25112871e-04]
 [  1.58000000e+03   1.28669810e-04]
 [  1.59000000e+03   1.34395377e-04]
 [  1.60000000e+03   9.68147797e-05]
 [  1.61000000e+03   1.11691559e-04]
 [  1.62000000e+03   1.37827534e-04]
 [  1.63000000e+03   9.69201137e-05]
 [  1.64000000e+03   1.10213979e-04]
 [  1.65000000e+03   1.37693190e-04]
 [  1.66000000e+03   1.39818949e-04]
 [  1.67000000e+03   9.15682904e-05]
 [  1.68000000e+03   8.86160051e-05]
 [  1.69000000e+03   1.03046907e-04]
 [  1.70000000e+03   1.19423174e-04]
 [  1.71000000e+03   9.35245989e-05]
 [  1.72000000e+03   1.00304162e-04]
 [  1.73000000e+03   2.12155021e-04]
 [  1.74000000e+03   9.96402741e-05]
 [  1.75000000e+03   1.09124296e-04]
 [  1.76000000e+03   8.63652240e-05]
 [  1.77000000e+03   8.32184014e-05]
 [  1.78000000e+03   9.59588506e-05]
 [  1.79000000e+03   9.59727258e-05]
 [  1.80000000e+03   1.10213266e-04]
 [  1.81000000e+03   9.14018528e-05]
 [  1.82000000e+03   8.82496679e-05]
 [  1.83000000e+03   9.17659854e-05]
 [  1.84000000e+03   7.30974352e-05]
 [  1.85000000e+03   1.06375293e-04]
 [  1.86000000e+03   9.89717155e-05]
 [  1.87000000e+03   7.51242478e-05]
 [  1.88000000e+03   8.52404555e-05]
 [  1.89000000e+03   8.63234527e-05]
 [  1.90000000e+03   7.76623347e-05]
 [  1.91000000e+03   7.47267404e-05]
 [  1.92000000e+03   1.04812512e-04]
 [  1.93000000e+03   8.30928329e-05]
 [  1.94000000e+03   1.11087225e-04]
 [  1.95000000e+03   1.01333280e-04]
 [  1.96000000e+03   7.37966620e-05]
 [  1.97000000e+03   6.89997614e-05]
 [  1.98000000e+03   9.19437589e-05]
 [  1.99000000e+03   6.95571216e-05]
 [  2.00000000e+03   6.19084894e-05]]
initial: [  0.00000000e+00   1.25333234e-01   2.48689887e-01   3.68124553e-01
   4.81753674e-01   5.87785252e-01   6.84547106e-01   7.70513243e-01
   8.44327926e-01   9.04827052e-01   9.51056516e-01   9.82287251e-01
   9.98026728e-01   9.98026728e-01   9.82287251e-01   9.51056516e-01
   9.04827052e-01   8.44327926e-01   7.70513243e-01   6.84547106e-01
   5.87785252e-01   4.81753674e-01   3.68124553e-01   2.48689887e-01
   1.25333234e-01  -3.21624530e-16  -1.25333234e-01  -2.48689887e-01
  -3.68124553e-01  -4.81753674e-01  -5.87785252e-01  -6.84547106e-01
  -7.70513243e-01  -8.44327926e-01  -9.04827052e-01  -9.51056516e-01
  -9.82287251e-01  -9.98026728e-01  -9.98026728e-01  -9.82287251e-01
  -9.51056516e-01  -9.04827052e-01  -8.44327926e-01  -7.70513243e-01
  -6.84547106e-01  -5.87785252e-01  -4.81753674e-01  -3.68124553e-01
  -2.48689887e-01  -1.25333234e-01]
prediction#1, output: 0.013006
prediction#2, output: 0.142693
prediction#3, output: 0.263895
prediction#4, output: 0.377606
prediction#5, output: 0.483875
prediction#6, output: 0.581849
prediction#7, output: 0.670418
prediction#8, output: 0.750248
prediction#9, output: 0.823465
prediction#10, output: 0.890247
prediction#11, output: 0.946194
prediction#12, output: 0.983752
prediction#13, output: 0.997088
prediction#14, output: 0.985648
prediction#15, output: 0.953068
prediction#16, output: 0.903971
prediction#17, output: 0.842020
prediction#18, output: 0.769547
prediction#19, output: 0.687837
prediction#20, output: 0.597513
prediction#21, output: 0.498831
prediction#22, output: 0.391938
prediction#23, output: 0.277124
prediction#24, output: 0.155134
prediction#25, output: 0.027506
prediction#26, output: -0.103200
prediction#27, output: -0.233508
prediction#28, output: -0.359562
prediction#29, output: -0.477909
prediction#30, output: -0.586105
prediction#31, output: -0.682830
prediction#32, output: -0.767508
prediction#33, output: -0.839723
prediction#34, output: -0.898821
prediction#35, output: -0.943904
prediction#36, output: -0.974154
prediction#37, output: -0.989160
prediction#38, output: -0.988984
prediction#39, output: -0.974004
prediction#40, output: -0.944692
prediction#41, output: -0.901495
prediction#42, output: -0.844840
prediction#43, output: -0.775217
prediction#44, output: -0.693210
prediction#45, output: -0.599431
prediction#46, output: -0.494411
prediction#47, output: -0.378823
prediction#48, output: -0.254182
prediction#49, output: -0.123632
prediction#50, output: 0.008149
prediction#51, output: 0.136366
prediction#52, output: 0.257960
prediction#53, output: 0.372107
prediction#54, output: 0.478838
prediction#55, output: 0.577369
prediction#56, output: 0.666541
prediction#57, output: 0.746875
prediction#58, output: 0.820475
prediction#59, output: 0.887702
prediction#60, output: 0.944388
prediction#61, output: 0.983039
prediction#62, output: 0.997630
prediction#63, output: 0.987352
prediction#64, output: 0.955718
prediction#65, output: 0.907366
prediction#66, output: 0.846022
prediction#67, output: 0.774082
prediction#68, output: 0.692878
prediction#69, output: 0.603050
prediction#70, output: 0.504852
prediction#71, output: 0.398416
prediction#72, output: 0.284017
prediction#73, output: 0.162393
prediction#74, output: 0.035075
prediction#75, output: -0.095413
prediction#76, output: -0.225657
prediction#77, output: -0.351860
prediction#78, output: -0.470575
prediction#79, output: -0.579307
prediction#80, output: -0.676665
prediction#81, output: -0.762029
prediction#82, output: -0.834979
prediction#83, output: -0.894877
prediction#84, output: -0.940832
prediction#85, output: -0.972004
prediction#86, output: -0.987943
prediction#87, output: -0.988679
prediction#88, output: -0.974568
prediction#89, output: -0.946077
prediction#90, output: -0.903651
prediction#91, output: -0.847720
prediction#92, output: -0.778770
prediction#93, output: -0.697391
prediction#94, output: -0.604201
prediction#95, output: -0.499744
prediction#96, output: -0.384673
prediction#97, output: -0.260440
prediction#98, output: -0.130095
prediction#99, output: 0.001740
prediction#100, output: 0.130229
outputs: [ 0.01300612  0.14269289  0.26389512  0.37760606  0.48387495  0.58184886
  0.67041779  0.75024784  0.82346511  0.89024734  0.9461937   0.98375189
  0.99708796  0.98564827  0.95306802  0.90397108  0.84202039  0.76954663
  0.68783748  0.59751284  0.49883077  0.39193788  0.27712443  0.15513429
  0.02750632 -0.10319978 -0.23350781 -0.3595621  -0.47790885 -0.58610457
 -0.6828301  -0.76750791 -0.83972347 -0.89882112 -0.94390404 -0.97415447
 -0.98915982 -0.98898387 -0.97400367 -0.94469202 -0.90149498 -0.84484041
 -0.77521652 -0.69321048 -0.59943056 -0.49441075 -0.37882268 -0.25418237
 -0.12363175  0.00814852  0.13636568  0.25796035  0.37210748  0.47883782
  0.57736886  0.6665405   0.74687517  0.82047546  0.88770187  0.94438791
  0.98303926  0.99763048  0.98735249  0.95571828  0.90736568  0.84602177
  0.77408195  0.69287813  0.60304952  0.50485206  0.39841565  0.28401664
  0.16239333  0.03507507 -0.09541272 -0.22565687 -0.35185981 -0.47057483
 -0.57930684 -0.67666531 -0.76202875 -0.83497894 -0.89487743 -0.94083214
 -0.97200429 -0.98794317 -0.98867869 -0.97456777 -0.94607675 -0.90365124
 -0.84771967 -0.77876961 -0.69739103 -0.60420144 -0.49974364 -0.38467273
 -0.26044047 -0.13009486  0.00174007  0.13022906]

real	5m30.537s
user	2m45.991s
sys	3m2.707s
