param_path: param.yaml
length_of_sequences: 50
size_of_mini_batch: 100
num_of_training_epochs: 2000
optimizer: GradientDescentOptimizer
num_of_prediction_epochs: 100
num_of_hidden_nodes: 2
learning_rate: 0.1
num_of_input_nodes: 1
seed: 0
train_data_path: ../train_data/normal.npy
num_of_output_nodes: 1
forget_bias: 1.0
train_data: [[  0.00000000e+00   1.25333234e-01]
 [  1.25333234e-01   2.48689887e-01]
 [  2.48689887e-01   3.68124553e-01]
 ..., 
 [ -3.68124553e-01  -2.48689887e-01]
 [ -2.48689887e-01  -1.25333234e-01]
 [ -1.25333234e-01   3.92877345e-15]]
train#10, train loss: 5.202433e-01
train#20, train loss: 4.925954e-01
train#30, train loss: 5.013855e-01
train#40, train loss: 4.913531e-01
train#50, train loss: 3.596662e-01
train#60, train loss: 2.447536e-01
train#70, train loss: 1.190642e-01
train#80, train loss: 5.429629e-02
train#90, train loss: 4.876227e-02
train#100, train loss: 4.003528e-02
train#110, train loss: 3.682441e-02
train#120, train loss: 2.941729e-02
train#130, train loss: 2.730886e-02
train#140, train loss: 2.907437e-02
train#150, train loss: 2.830523e-02
train#160, train loss: 2.258102e-02
train#170, train loss: 2.199498e-02
train#180, train loss: 2.042222e-02
train#190, train loss: 2.018580e-02
train#200, train loss: 2.145303e-02
train#210, train loss: 1.732675e-02
train#220, train loss: 1.837559e-02
train#230, train loss: 1.425880e-02
train#240, train loss: 1.742226e-02
train#250, train loss: 1.743565e-02
train#260, train loss: 1.443965e-02
train#270, train loss: 1.479896e-02
train#280, train loss: 1.394800e-02
train#290, train loss: 1.213926e-02
train#300, train loss: 1.185410e-02
train#310, train loss: 1.162480e-02
train#320, train loss: 1.190993e-02
train#330, train loss: 1.011219e-02
train#340, train loss: 8.984804e-03
train#350, train loss: 9.685775e-03
train#360, train loss: 1.025590e-02
train#370, train loss: 8.608748e-03
train#380, train loss: 8.664947e-03
train#390, train loss: 8.376364e-03
train#400, train loss: 8.469928e-03
train#410, train loss: 7.973446e-03
train#420, train loss: 6.708120e-03
train#430, train loss: 7.189346e-03
train#440, train loss: 7.377046e-03
train#450, train loss: 8.222273e-03
train#460, train loss: 7.404860e-03
train#470, train loss: 6.937781e-03
train#480, train loss: 6.226160e-03
train#490, train loss: 6.159616e-03
train#500, train loss: 6.023316e-03
train#510, train loss: 5.549642e-03
train#520, train loss: 5.635440e-03
train#530, train loss: 4.918780e-03
train#540, train loss: 5.643663e-03
train#550, train loss: 4.839912e-03
train#560, train loss: 4.388629e-03
train#570, train loss: 4.651958e-03
train#580, train loss: 4.113927e-03
train#590, train loss: 4.011226e-03
train#600, train loss: 3.313712e-03
train#610, train loss: 3.610826e-03
train#620, train loss: 3.287051e-03
train#630, train loss: 3.479700e-03
train#640, train loss: 3.130834e-03
train#650, train loss: 3.131007e-03
train#660, train loss: 2.388897e-03
train#670, train loss: 2.989175e-03
train#680, train loss: 2.604039e-03
train#690, train loss: 2.709027e-03
train#700, train loss: 2.287575e-03
train#710, train loss: 2.256348e-03
train#720, train loss: 2.250653e-03
train#730, train loss: 2.114604e-03
train#740, train loss: 1.590699e-03
train#750, train loss: 1.632003e-03
train#760, train loss: 1.612914e-03
train#770, train loss: 1.504480e-03
train#780, train loss: 1.343484e-03
train#790, train loss: 1.367336e-03
train#800, train loss: 1.370107e-03
train#810, train loss: 1.229229e-03
train#820, train loss: 1.179334e-03
train#830, train loss: 9.608341e-04
train#840, train loss: 9.827071e-04
train#850, train loss: 8.965606e-04
train#860, train loss: 9.425264e-04
train#870, train loss: 7.840354e-04
train#880, train loss: 7.716361e-04
train#890, train loss: 7.975185e-04
train#900, train loss: 6.796670e-04
train#910, train loss: 6.361168e-04
train#920, train loss: 7.628922e-04
train#930, train loss: 5.745932e-04
train#940, train loss: 6.538245e-04
train#950, train loss: 6.034499e-04
train#960, train loss: 5.517740e-04
train#970, train loss: 4.809626e-04
train#980, train loss: 5.478087e-04
train#990, train loss: 5.136957e-04
train#1000, train loss: 4.710970e-04
train#1010, train loss: 3.815013e-04
train#1020, train loss: 4.165693e-04
train#1030, train loss: 4.053820e-04
train#1040, train loss: 4.356896e-04
train#1050, train loss: 4.130522e-04
train#1060, train loss: 3.449050e-04
train#1070, train loss: 4.464728e-04
train#1080, train loss: 3.515211e-04
train#1090, train loss: 3.938669e-04
train#1100, train loss: 3.228934e-04
train#1110, train loss: 3.549027e-04
train#1120, train loss: 3.554032e-04
train#1130, train loss: 3.470265e-04
train#1140, train loss: 3.678151e-04
train#1150, train loss: 3.398934e-04
train#1160, train loss: 3.305793e-04
train#1170, train loss: 3.872720e-04
train#1180, train loss: 2.528898e-04
train#1190, train loss: 2.958471e-04
train#1200, train loss: 3.136123e-04
train#1210, train loss: 2.733089e-04
train#1220, train loss: 3.445465e-04
train#1230, train loss: 3.568432e-04
train#1240, train loss: 3.679362e-04
train#1250, train loss: 3.561751e-04
train#1260, train loss: 3.399815e-04
train#1270, train loss: 3.409488e-04
train#1280, train loss: 2.926017e-04
train#1290, train loss: 3.261265e-04
train#1300, train loss: 3.352315e-04
train#1310, train loss: 2.949747e-04
train#1320, train loss: 3.416451e-04
train#1330, train loss: 2.227537e-04
train#1340, train loss: 3.090645e-04
train#1350, train loss: 2.300971e-04
train#1360, train loss: 2.650958e-04
train#1370, train loss: 2.578336e-04
train#1380, train loss: 2.952149e-04
train#1390, train loss: 2.854031e-04
train#1400, train loss: 2.655697e-04
train#1410, train loss: 2.648841e-04
train#1420, train loss: 2.774438e-04
train#1430, train loss: 2.893499e-04
train#1440, train loss: 3.018301e-04
train#1450, train loss: 2.987082e-04
train#1460, train loss: 2.642145e-04
train#1470, train loss: 2.711719e-04
train#1480, train loss: 2.661519e-04
train#1490, train loss: 2.900519e-04
train#1500, train loss: 2.801199e-04
train#1510, train loss: 2.694668e-04
train#1520, train loss: 2.621297e-04
train#1530, train loss: 2.441920e-04
train#1540, train loss: 2.253538e-04
train#1550, train loss: 2.711138e-04
train#1560, train loss: 2.908120e-04
train#1570, train loss: 2.806294e-04
train#1580, train loss: 2.753185e-04
train#1590, train loss: 2.794367e-04
train#1600, train loss: 2.929142e-04
train#1610, train loss: 2.832199e-04
train#1620, train loss: 2.479616e-04
train#1630, train loss: 2.661587e-04
train#1640, train loss: 1.952048e-04
train#1650, train loss: 2.382599e-04
train#1660, train loss: 2.125459e-04
train#1670, train loss: 2.698883e-04
train#1680, train loss: 2.673658e-04
train#1690, train loss: 2.427842e-04
train#1700, train loss: 2.562056e-04
train#1710, train loss: 2.375031e-04
train#1720, train loss: 2.546103e-04
train#1730, train loss: 2.299857e-04
train#1740, train loss: 2.158985e-04
train#1750, train loss: 2.327637e-04
train#1760, train loss: 2.522120e-04
train#1770, train loss: 2.673681e-04
train#1780, train loss: 2.164280e-04
train#1790, train loss: 2.129426e-04
train#1800, train loss: 2.804477e-04
train#1810, train loss: 2.276736e-04
train#1820, train loss: 2.360645e-04
train#1830, train loss: 2.164825e-04
train#1840, train loss: 2.585358e-04
train#1850, train loss: 2.381373e-04
train#1860, train loss: 2.598686e-04
train#1870, train loss: 2.317657e-04
train#1880, train loss: 2.745348e-04
train#1890, train loss: 2.415289e-04
train#1900, train loss: 2.564383e-04
train#1910, train loss: 2.141433e-04
train#1920, train loss: 2.531353e-04
train#1930, train loss: 2.309453e-04
train#1940, train loss: 2.596881e-04
train#1950, train loss: 1.893274e-04
train#1960, train loss: 2.592105e-04
train#1970, train loss: 2.270518e-04
train#1980, train loss: 2.527884e-04
train#1990, train loss: 2.339821e-04
train#2000, train loss: 2.028440e-04
losses: [[  1.00000000e+01   5.20243287e-01]
 [  2.00000000e+01   4.92595434e-01]
 [  3.00000000e+01   5.01385510e-01]
 [  4.00000000e+01   4.91353065e-01]
 [  5.00000000e+01   3.59666169e-01]
 [  6.00000000e+01   2.44753614e-01]
 [  7.00000000e+01   1.19064234e-01]
 [  8.00000000e+01   5.42962924e-02]
 [  9.00000000e+01   4.87622656e-02]
 [  1.00000000e+02   4.00352776e-02]
 [  1.10000000e+02   3.68244089e-02]
 [  1.20000000e+02   2.94172876e-02]
 [  1.30000000e+02   2.73088589e-02]
 [  1.40000000e+02   2.90743727e-02]
 [  1.50000000e+02   2.83052269e-02]
 [  1.60000000e+02   2.25810166e-02]
 [  1.70000000e+02   2.19949819e-02]
 [  1.80000000e+02   2.04222221e-02]
 [  1.90000000e+02   2.01858040e-02]
 [  2.00000000e+02   2.14530285e-02]
 [  2.10000000e+02   1.73267536e-02]
 [  2.20000000e+02   1.83755904e-02]
 [  2.30000000e+02   1.42588047e-02]
 [  2.40000000e+02   1.74222644e-02]
 [  2.50000000e+02   1.74356494e-02]
 [  2.60000000e+02   1.44396471e-02]
 [  2.70000000e+02   1.47989579e-02]
 [  2.80000000e+02   1.39479963e-02]
 [  2.90000000e+02   1.21392598e-02]
 [  3.00000000e+02   1.18540954e-02]
 [  3.10000000e+02   1.16247963e-02]
 [  3.20000000e+02   1.19099328e-02]
 [  3.30000000e+02   1.01121906e-02]
 [  3.40000000e+02   8.98480415e-03]
 [  3.50000000e+02   9.68577527e-03]
 [  3.60000000e+02   1.02559021e-02]
 [  3.70000000e+02   8.60874821e-03]
 [  3.80000000e+02   8.66494700e-03]
 [  3.90000000e+02   8.37636366e-03]
 [  4.00000000e+02   8.46992806e-03]
 [  4.10000000e+02   7.97344558e-03]
 [  4.20000000e+02   6.70812000e-03]
 [  4.30000000e+02   7.18934648e-03]
 [  4.40000000e+02   7.37704569e-03]
 [  4.50000000e+02   8.22227262e-03]
 [  4.60000000e+02   7.40485964e-03]
 [  4.70000000e+02   6.93778135e-03]
 [  4.80000000e+02   6.22616010e-03]
 [  4.90000000e+02   6.15961570e-03]
 [  5.00000000e+02   6.02331618e-03]
 [  5.10000000e+02   5.54964179e-03]
 [  5.20000000e+02   5.63544035e-03]
 [  5.30000000e+02   4.91877971e-03]
 [  5.40000000e+02   5.64366346e-03]
 [  5.50000000e+02   4.83991206e-03]
 [  5.60000000e+02   4.38862899e-03]
 [  5.70000000e+02   4.65195766e-03]
 [  5.80000000e+02   4.11392702e-03]
 [  5.90000000e+02   4.01122635e-03]
 [  6.00000000e+02   3.31371208e-03]
 [  6.10000000e+02   3.61082563e-03]
 [  6.20000000e+02   3.28705134e-03]
 [  6.30000000e+02   3.47970007e-03]
 [  6.40000000e+02   3.13083362e-03]
 [  6.50000000e+02   3.13100684e-03]
 [  6.60000000e+02   2.38889689e-03]
 [  6.70000000e+02   2.98917526e-03]
 [  6.80000000e+02   2.60403869e-03]
 [  6.90000000e+02   2.70902715e-03]
 [  7.00000000e+02   2.28757504e-03]
 [  7.10000000e+02   2.25634803e-03]
 [  7.20000000e+02   2.25065299e-03]
 [  7.30000000e+02   2.11460376e-03]
 [  7.40000000e+02   1.59069884e-03]
 [  7.50000000e+02   1.63200335e-03]
 [  7.60000000e+02   1.61291356e-03]
 [  7.70000000e+02   1.50447991e-03]
 [  7.80000000e+02   1.34348404e-03]
 [  7.90000000e+02   1.36733591e-03]
 [  8.00000000e+02   1.37010694e-03]
 [  8.10000000e+02   1.22922892e-03]
 [  8.20000000e+02   1.17933424e-03]
 [  8.30000000e+02   9.60834092e-04]
 [  8.40000000e+02   9.82707134e-04]
 [  8.50000000e+02   8.96560552e-04]
 [  8.60000000e+02   9.42526443e-04]
 [  8.70000000e+02   7.84035423e-04]
 [  8.80000000e+02   7.71636085e-04]
 [  8.90000000e+02   7.97518471e-04]
 [  9.00000000e+02   6.79667050e-04]
 [  9.10000000e+02   6.36116834e-04]
 [  9.20000000e+02   7.62892189e-04]
 [  9.30000000e+02   5.74593199e-04]
 [  9.40000000e+02   6.53824536e-04]
 [  9.50000000e+02   6.03449880e-04]
 [  9.60000000e+02   5.51773992e-04]
 [  9.70000000e+02   4.80962626e-04]
 [  9.80000000e+02   5.47808653e-04]
 [  9.90000000e+02   5.13695704e-04]
 [  1.00000000e+03   4.71097039e-04]
 [  1.01000000e+03   3.81501304e-04]
 [  1.02000000e+03   4.16569266e-04]
 [  1.03000000e+03   4.05381987e-04]
 [  1.04000000e+03   4.35689639e-04]
 [  1.05000000e+03   4.13052243e-04]
 [  1.06000000e+03   3.44905042e-04]
 [  1.07000000e+03   4.46472841e-04]
 [  1.08000000e+03   3.51521070e-04]
 [  1.09000000e+03   3.93866911e-04]
 [  1.10000000e+03   3.22893437e-04]
 [  1.11000000e+03   3.54902731e-04]
 [  1.12000000e+03   3.55403201e-04]
 [  1.13000000e+03   3.47026507e-04]
 [  1.14000000e+03   3.67815112e-04]
 [  1.15000000e+03   3.39893362e-04]
 [  1.16000000e+03   3.30579322e-04]
 [  1.17000000e+03   3.87271954e-04]
 [  1.18000000e+03   2.52889848e-04]
 [  1.19000000e+03   2.95847130e-04]
 [  1.20000000e+03   3.13612341e-04]
 [  1.21000000e+03   2.73308950e-04]
 [  1.22000000e+03   3.44546512e-04]
 [  1.23000000e+03   3.56843200e-04]
 [  1.24000000e+03   3.67936154e-04]
 [  1.25000000e+03   3.56175093e-04]
 [  1.26000000e+03   3.39981547e-04]
 [  1.27000000e+03   3.40948842e-04]
 [  1.28000000e+03   2.92601733e-04]
 [  1.29000000e+03   3.26126523e-04]
 [  1.30000000e+03   3.35231511e-04]
 [  1.31000000e+03   2.94974714e-04]
 [  1.32000000e+03   3.41645093e-04]
 [  1.33000000e+03   2.22753661e-04]
 [  1.34000000e+03   3.09064519e-04]
 [  1.35000000e+03   2.30097095e-04]
 [  1.36000000e+03   2.65095849e-04]
 [  1.37000000e+03   2.57833599e-04]
 [  1.38000000e+03   2.95214879e-04]
 [  1.39000000e+03   2.85403134e-04]
 [  1.40000000e+03   2.65569688e-04]
 [  1.41000000e+03   2.64884147e-04]
 [  1.42000000e+03   2.77443789e-04]
 [  1.43000000e+03   2.89349933e-04]
 [  1.44000000e+03   3.01830121e-04]
 [  1.45000000e+03   2.98708241e-04]
 [  1.46000000e+03   2.64214497e-04]
 [  1.47000000e+03   2.71171913e-04]
 [  1.48000000e+03   2.66151910e-04]
 [  1.49000000e+03   2.90051859e-04]
 [  1.50000000e+03   2.80119915e-04]
 [  1.51000000e+03   2.69466807e-04]
 [  1.52000000e+03   2.62129674e-04]
 [  1.53000000e+03   2.44191993e-04]
 [  1.54000000e+03   2.25353797e-04]
 [  1.55000000e+03   2.71113822e-04]
 [  1.56000000e+03   2.90811964e-04]
 [  1.57000000e+03   2.80629407e-04]
 [  1.58000000e+03   2.75318482e-04]
 [  1.59000000e+03   2.79436703e-04]
 [  1.60000000e+03   2.92914221e-04]
 [  1.61000000e+03   2.83219939e-04]
 [  1.62000000e+03   2.47961550e-04]
 [  1.63000000e+03   2.66158720e-04]
 [  1.64000000e+03   1.95204804e-04]
 [  1.65000000e+03   2.38259934e-04]
 [  1.66000000e+03   2.12545914e-04]
 [  1.67000000e+03   2.69888318e-04]
 [  1.68000000e+03   2.67365773e-04]
 [  1.69000000e+03   2.42784241e-04]
 [  1.70000000e+03   2.56205589e-04]
 [  1.71000000e+03   2.37503089e-04]
 [  1.72000000e+03   2.54610321e-04]
 [  1.73000000e+03   2.29985730e-04]
 [  1.74000000e+03   2.15898530e-04]
 [  1.75000000e+03   2.32763661e-04]
 [  1.76000000e+03   2.52211990e-04]
 [  1.77000000e+03   2.67368072e-04]
 [  1.78000000e+03   2.16428016e-04]
 [  1.79000000e+03   2.12942599e-04]
 [  1.80000000e+03   2.80447653e-04]
 [  1.81000000e+03   2.27673649e-04]
 [  1.82000000e+03   2.36064487e-04]
 [  1.83000000e+03   2.16482455e-04]
 [  1.84000000e+03   2.58535787e-04]
 [  1.85000000e+03   2.38137320e-04]
 [  1.86000000e+03   2.59868626e-04]
 [  1.87000000e+03   2.31765691e-04]
 [  1.88000000e+03   2.74534803e-04]
 [  1.89000000e+03   2.41528905e-04]
 [  1.90000000e+03   2.56438274e-04]
 [  1.91000000e+03   2.14143307e-04]
 [  1.92000000e+03   2.53135251e-04]
 [  1.93000000e+03   2.30945254e-04]
 [  1.94000000e+03   2.59688095e-04]
 [  1.95000000e+03   1.89327387e-04]
 [  1.96000000e+03   2.59210530e-04]
 [  1.97000000e+03   2.27051845e-04]
 [  1.98000000e+03   2.52788363e-04]
 [  1.99000000e+03   2.33982078e-04]
 [  2.00000000e+03   2.02843963e-04]]
initial: [  0.00000000e+00   1.25333234e-01   2.48689887e-01   3.68124553e-01
   4.81753674e-01   5.87785252e-01   6.84547106e-01   7.70513243e-01
   8.44327926e-01   9.04827052e-01   9.51056516e-01   9.82287251e-01
   9.98026728e-01   9.98026728e-01   9.82287251e-01   9.51056516e-01
   9.04827052e-01   8.44327926e-01   7.70513243e-01   6.84547106e-01
   5.87785252e-01   4.81753674e-01   3.68124553e-01   2.48689887e-01
   1.25333234e-01  -3.21624530e-16  -1.25333234e-01  -2.48689887e-01
  -3.68124553e-01  -4.81753674e-01  -5.87785252e-01  -6.84547106e-01
  -7.70513243e-01  -8.44327926e-01  -9.04827052e-01  -9.51056516e-01
  -9.82287251e-01  -9.98026728e-01  -9.98026728e-01  -9.82287251e-01
  -9.51056516e-01  -9.04827052e-01  -8.44327926e-01  -7.70513243e-01
  -6.84547106e-01  -5.87785252e-01  -4.81753674e-01  -3.68124553e-01
  -2.48689887e-01  -1.25333234e-01]
prediction#1, output: 0.011337
prediction#2, output: 0.154922
prediction#3, output: 0.302720
prediction#4, output: 0.449771
prediction#5, output: 0.589218
prediction#6, output: 0.713241
prediction#7, output: 0.814984
prediction#8, output: 0.890580
prediction#9, output: 0.939988
prediction#10, output: 0.966191
prediction#11, output: 0.973604
prediction#12, output: 0.966708
prediction#13, output: 0.949316
prediction#14, output: 0.924347
prediction#15, output: 0.893873
prediction#16, output: 0.859252
prediction#17, output: 0.821267
prediction#18, output: 0.780238
prediction#19, output: 0.736097
prediction#20, output: 0.688434
prediction#21, output: 0.636507
prediction#22, output: 0.579226
prediction#23, output: 0.515124
prediction#24, output: 0.442325
prediction#25, output: 0.358555
prediction#26, output: 0.261292
prediction#27, output: 0.148202
prediction#28, output: 0.018102
prediction#29, output: -0.127486
prediction#30, output: -0.282706
prediction#31, output: -0.437242
prediction#32, output: -0.579127
prediction#33, output: -0.699136
prediction#34, output: -0.793261
prediction#35, output: -0.861963
prediction#36, output: -0.908035
prediction#37, output: -0.934895
prediction#38, output: -0.945721
prediction#39, output: -0.943149
prediction#40, output: -0.929252
prediction#41, output: -0.905602
prediction#42, output: -0.873364
prediction#43, output: -0.833376
prediction#44, output: -0.786224
prediction#45, output: -0.732294
prediction#46, output: -0.671829
prediction#47, output: -0.604973
prediction#48, output: -0.531814
prediction#49, output: -0.452440
prediction#50, output: -0.366984
prediction#51, output: -0.275697
prediction#52, output: -0.179013
prediction#53, output: -0.077629
prediction#54, output: 0.027404
prediction#55, output: 0.134610
prediction#56, output: 0.242020
prediction#57, output: 0.347166
prediction#58, output: 0.447171
prediction#59, output: 0.538971
prediction#60, output: 0.619697
prediction#61, output: 0.687103
prediction#62, output: 0.739921
prediction#63, output: 0.777985
prediction#64, output: 0.802091
prediction#65, output: 0.813673
prediction#66, output: 0.814445
prediction#67, output: 0.806101
prediction#68, output: 0.790115
prediction#69, output: 0.767641
prediction#70, output: 0.739475
prediction#71, output: 0.706042
prediction#72, output: 0.667403
prediction#73, output: 0.623251
prediction#74, output: 0.572901
prediction#75, output: 0.515258
prediction#76, output: 0.448798
prediction#77, output: 0.371566
prediction#78, output: 0.281278
prediction#79, output: 0.175657
prediction#80, output: 0.053190
prediction#81, output: -0.085521
prediction#82, output: -0.236109
prediction#83, output: -0.389697
prediction#84, output: -0.534675
prediction#85, output: -0.660761
prediction#86, output: -0.762271
prediction#87, output: -0.838342
prediction#88, output: -0.891095
prediction#89, output: -0.923751
prediction#90, output: -0.939528
prediction#91, output: -0.941194
prediction#92, output: -0.930966
prediction#93, output: -0.910549
prediction#94, output: -0.881222
prediction#95, output: -0.843916
prediction#96, output: -0.799292
prediction#97, output: -0.747799
prediction#98, output: -0.689727
prediction#99, output: -0.625254
prediction#100, output: -0.554490
outputs: [ 0.01133673  0.15492176  0.30271977  0.44977117  0.58921814  0.71324146
  0.81498379  0.89058036  0.93998843  0.96619099  0.97360379  0.96670812
  0.94931561  0.92434651  0.89387292  0.85925227  0.82126731  0.78023773
  0.7360968   0.68843406  0.63650692  0.57922614  0.5151242   0.44232476
  0.35855478  0.26129156  0.14820226  0.01810195 -0.12748618 -0.28270563
 -0.43724248 -0.57912713 -0.69913578 -0.79326099 -0.86196303 -0.90803504
 -0.9348954  -0.94572079 -0.94314921 -0.92925185 -0.90560192 -0.87336379
 -0.83337641 -0.78622371 -0.73229378 -0.67182904 -0.60497272 -0.53181446
 -0.45243973 -0.36698425 -0.27569714 -0.17901251 -0.07762931  0.02740432
  0.13461025  0.24202015  0.34716648  0.44717056  0.53897142  0.61969727
  0.68710285  0.73992068  0.7779848   0.80209059  0.81367284  0.81444532
  0.80610102  0.7901147   0.76764125  0.73947489  0.70604163  0.66740257
  0.6232512   0.57290059  0.51525784  0.44879788  0.3715657   0.28127837
  0.17565687  0.05318983 -0.08552061 -0.23610872 -0.3896966  -0.53467548
 -0.66076076 -0.76227063 -0.83834219 -0.8910951  -0.92375076 -0.93952793
 -0.94119412 -0.93096584 -0.91054904 -0.88122153 -0.84391582 -0.79929215
 -0.74779934 -0.68972731 -0.62525392 -0.55449033]

real	4m53.831s
user	2m51.352s
sys	3m46.392s
