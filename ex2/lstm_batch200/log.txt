param_path: param.yaml
num_of_hidden_nodes: 2
num_of_prediction_epochs: 100
num_of_training_epochs: 2000
train_data_path: ../train_data/normal.npy
seed: 0
length_of_sequences: 50
learning_rate: 0.1
optimizer: GradientDescentOptimizer
num_of_output_nodes: 1
num_of_input_nodes: 1
forget_bias: 1.0
size_of_mini_batch: 200
train_data: [[  0.00000000e+00   1.25333234e-01]
 [  1.25333234e-01   2.48689887e-01]
 [  2.48689887e-01   3.68124553e-01]
 ..., 
 [ -3.68124553e-01  -2.48689887e-01]
 [ -2.48689887e-01  -1.25333234e-01]
 [ -1.25333234e-01   3.92877345e-15]]
train#10, train loss: 5.134977e-01
train#20, train loss: 4.710589e-01
train#30, train loss: 3.437723e-01
train#40, train loss: 2.355916e-01
train#50, train loss: 1.627472e-01
train#60, train loss: 1.041895e-01
train#70, train loss: 8.413368e-02
train#80, train loss: 7.132234e-02
train#90, train loss: 6.059470e-02
train#100, train loss: 6.077116e-02
train#110, train loss: 5.094492e-02
train#120, train loss: 4.764974e-02
train#130, train loss: 4.238664e-02
train#140, train loss: 3.795252e-02
train#150, train loss: 3.522444e-02
train#160, train loss: 3.522461e-02
train#170, train loss: 3.168118e-02
train#180, train loss: 2.958595e-02
train#190, train loss: 2.782698e-02
train#200, train loss: 2.512488e-02
train#210, train loss: 2.125138e-02
train#220, train loss: 2.323194e-02
train#230, train loss: 1.996245e-02
train#240, train loss: 1.816244e-02
train#250, train loss: 1.682069e-02
train#260, train loss: 1.602658e-02
train#270, train loss: 1.392981e-02
train#280, train loss: 1.210766e-02
train#290, train loss: 1.083816e-02
train#300, train loss: 9.855058e-03
train#310, train loss: 7.962822e-03
train#320, train loss: 7.290498e-03
train#330, train loss: 6.298663e-03
train#340, train loss: 5.546467e-03
train#350, train loss: 3.991835e-03
train#360, train loss: 4.159973e-03
train#370, train loss: 4.115297e-03
train#380, train loss: 3.755080e-03
train#390, train loss: 3.166043e-03
train#400, train loss: 3.405459e-03
train#410, train loss: 3.138151e-03
train#420, train loss: 3.092147e-03
train#430, train loss: 2.858086e-03
train#440, train loss: 2.649819e-03
train#450, train loss: 3.056918e-03
train#460, train loss: 2.835243e-03
train#470, train loss: 2.707173e-03
train#480, train loss: 2.593537e-03
train#490, train loss: 2.916669e-03
train#500, train loss: 2.649000e-03
train#510, train loss: 2.294978e-03
train#520, train loss: 2.501299e-03
train#530, train loss: 2.642697e-03
train#540, train loss: 2.311811e-03
train#550, train loss: 2.385794e-03
train#560, train loss: 2.128368e-03
train#570, train loss: 2.171537e-03
train#580, train loss: 2.153833e-03
train#590, train loss: 2.279634e-03
train#600, train loss: 2.147160e-03
train#610, train loss: 2.087376e-03
train#620, train loss: 2.136482e-03
train#630, train loss: 2.138152e-03
train#640, train loss: 2.052231e-03
train#650, train loss: 2.011067e-03
train#660, train loss: 1.919952e-03
train#670, train loss: 1.761602e-03
train#680, train loss: 1.854844e-03
train#690, train loss: 1.972555e-03
train#700, train loss: 1.706511e-03
train#710, train loss: 1.884611e-03
train#720, train loss: 1.703358e-03
train#730, train loss: 1.800258e-03
train#740, train loss: 1.687160e-03
train#750, train loss: 1.774024e-03
train#760, train loss: 1.703272e-03
train#770, train loss: 1.418986e-03
train#780, train loss: 1.583489e-03
train#790, train loss: 1.495186e-03
train#800, train loss: 1.613697e-03
train#810, train loss: 1.563811e-03
train#820, train loss: 1.472953e-03
train#830, train loss: 1.405230e-03
train#840, train loss: 1.518539e-03
train#850, train loss: 1.415458e-03
train#860, train loss: 1.406339e-03
train#870, train loss: 1.407215e-03
train#880, train loss: 1.444025e-03
train#890, train loss: 1.352809e-03
train#900, train loss: 1.304751e-03
train#910, train loss: 1.180605e-03
train#920, train loss: 1.218643e-03
train#930, train loss: 1.160252e-03
train#940, train loss: 1.119270e-03
train#950, train loss: 1.151226e-03
train#960, train loss: 1.165327e-03
train#970, train loss: 1.100383e-03
train#980, train loss: 1.115315e-03
train#990, train loss: 1.064735e-03
train#1000, train loss: 9.092026e-04
train#1010, train loss: 9.827046e-04
train#1020, train loss: 8.446995e-04
train#1030, train loss: 1.060023e-03
train#1040, train loss: 8.579560e-04
train#1050, train loss: 9.758462e-04
train#1060, train loss: 7.209040e-04
train#1070, train loss: 7.875327e-04
train#1080, train loss: 7.564850e-04
train#1090, train loss: 8.106759e-04
train#1100, train loss: 7.829942e-04
train#1110, train loss: 7.427105e-04
train#1120, train loss: 7.584787e-04
train#1130, train loss: 6.894767e-04
train#1140, train loss: 7.756235e-04
train#1150, train loss: 8.266333e-04
train#1160, train loss: 7.543297e-04
train#1170, train loss: 6.657343e-04
train#1180, train loss: 6.630453e-04
train#1190, train loss: 5.998716e-04
train#1200, train loss: 6.297547e-04
train#1210, train loss: 6.216359e-04
train#1220, train loss: 6.090939e-04
train#1230, train loss: 6.967975e-04
train#1240, train loss: 6.340861e-04
train#1250, train loss: 5.888513e-04
train#1260, train loss: 5.616230e-04
train#1270, train loss: 5.662774e-04
train#1280, train loss: 5.841675e-04
train#1290, train loss: 5.676867e-04
train#1300, train loss: 4.939599e-04
train#1310, train loss: 5.151359e-04
train#1320, train loss: 5.480321e-04
train#1330, train loss: 5.501573e-04
train#1340, train loss: 4.939070e-04
train#1350, train loss: 5.064348e-04
train#1360, train loss: 4.973192e-04
train#1370, train loss: 5.322678e-04
train#1380, train loss: 4.904658e-04
train#1390, train loss: 4.958643e-04
train#1400, train loss: 4.517442e-04
train#1410, train loss: 3.928309e-04
train#1420, train loss: 4.157270e-04
train#1430, train loss: 4.158641e-04
train#1440, train loss: 4.120010e-04
train#1450, train loss: 4.280723e-04
train#1460, train loss: 4.316126e-04
train#1470, train loss: 4.165047e-04
train#1480, train loss: 4.237605e-04
train#1490, train loss: 3.682635e-04
train#1500, train loss: 3.970936e-04
train#1510, train loss: 3.886603e-04
train#1520, train loss: 3.713338e-04
train#1530, train loss: 4.281595e-04
train#1540, train loss: 3.649998e-04
train#1550, train loss: 3.548221e-04
train#1560, train loss: 3.820538e-04
train#1570, train loss: 3.530469e-04
train#1580, train loss: 3.468176e-04
train#1590, train loss: 3.418533e-04
train#1600, train loss: 2.923144e-04
train#1610, train loss: 3.539405e-04
train#1620, train loss: 3.550844e-04
train#1630, train loss: 3.288208e-04
train#1640, train loss: 3.247806e-04
train#1650, train loss: 2.970651e-04
train#1660, train loss: 3.466102e-04
train#1670, train loss: 3.081019e-04
train#1680, train loss: 3.240016e-04
train#1690, train loss: 3.485822e-04
train#1700, train loss: 3.358051e-04
train#1710, train loss: 3.151377e-04
train#1720, train loss: 3.226433e-04
train#1730, train loss: 3.461518e-04
train#1740, train loss: 2.881583e-04
train#1750, train loss: 3.396872e-04
train#1760, train loss: 2.946814e-04
train#1770, train loss: 3.232652e-04
train#1780, train loss: 3.026241e-04
train#1790, train loss: 3.107887e-04
train#1800, train loss: 2.770696e-04
train#1810, train loss: 2.939246e-04
train#1820, train loss: 2.989384e-04
train#1830, train loss: 2.821266e-04
train#1840, train loss: 2.894271e-04
train#1850, train loss: 3.016060e-04
train#1860, train loss: 2.603629e-04
train#1870, train loss: 2.922983e-04
train#1880, train loss: 3.031981e-04
train#1890, train loss: 2.905020e-04
train#1900, train loss: 2.655870e-04
train#1910, train loss: 2.926053e-04
train#1920, train loss: 2.721871e-04
train#1930, train loss: 2.642970e-04
train#1940, train loss: 2.822890e-04
train#1950, train loss: 2.580728e-04
train#1960, train loss: 2.830251e-04
train#1970, train loss: 2.699838e-04
train#1980, train loss: 2.570163e-04
train#1990, train loss: 2.587218e-04
train#2000, train loss: 2.589739e-04
losses: [[  1.00000000e+01   5.13497651e-01]
 [  2.00000000e+01   4.71058875e-01]
 [  3.00000000e+01   3.43772322e-01]
 [  4.00000000e+01   2.35591590e-01]
 [  5.00000000e+01   1.62747189e-01]
 [  6.00000000e+01   1.04189508e-01]
 [  7.00000000e+01   8.41336846e-02]
 [  8.00000000e+01   7.13223368e-02]
 [  9.00000000e+01   6.05947003e-02]
 [  1.00000000e+02   6.07711561e-02]
 [  1.10000000e+02   5.09449244e-02]
 [  1.20000000e+02   4.76497449e-02]
 [  1.30000000e+02   4.23866361e-02]
 [  1.40000000e+02   3.79525200e-02]
 [  1.50000000e+02   3.52244414e-02]
 [  1.60000000e+02   3.52246128e-02]
 [  1.70000000e+02   3.16811837e-02]
 [  1.80000000e+02   2.95859519e-02]
 [  1.90000000e+02   2.78269816e-02]
 [  2.00000000e+02   2.51248833e-02]
 [  2.10000000e+02   2.12513786e-02]
 [  2.20000000e+02   2.32319403e-02]
 [  2.30000000e+02   1.99624486e-02]
 [  2.40000000e+02   1.81624424e-02]
 [  2.50000000e+02   1.68206878e-02]
 [  2.60000000e+02   1.60265844e-02]
 [  2.70000000e+02   1.39298104e-02]
 [  2.80000000e+02   1.21076619e-02]
 [  2.90000000e+02   1.08381649e-02]
 [  3.00000000e+02   9.85505804e-03]
 [  3.10000000e+02   7.96282198e-03]
 [  3.20000000e+02   7.29049789e-03]
 [  3.30000000e+02   6.29866263e-03]
 [  3.40000000e+02   5.54646738e-03]
 [  3.50000000e+02   3.99183528e-03]
 [  3.60000000e+02   4.15997254e-03]
 [  3.70000000e+02   4.11529653e-03]
 [  3.80000000e+02   3.75507958e-03]
 [  3.90000000e+02   3.16604250e-03]
 [  4.00000000e+02   3.40545946e-03]
 [  4.10000000e+02   3.13815055e-03]
 [  4.20000000e+02   3.09214671e-03]
 [  4.30000000e+02   2.85808626e-03]
 [  4.40000000e+02   2.64981855e-03]
 [  4.50000000e+02   3.05691781e-03]
 [  4.60000000e+02   2.83524278e-03]
 [  4.70000000e+02   2.70717265e-03]
 [  4.80000000e+02   2.59353733e-03]
 [  4.90000000e+02   2.91666854e-03]
 [  5.00000000e+02   2.64900038e-03]
 [  5.10000000e+02   2.29497836e-03]
 [  5.20000000e+02   2.50129937e-03]
 [  5.30000000e+02   2.64269742e-03]
 [  5.40000000e+02   2.31181085e-03]
 [  5.50000000e+02   2.38579372e-03]
 [  5.60000000e+02   2.12836824e-03]
 [  5.70000000e+02   2.17153737e-03]
 [  5.80000000e+02   2.15383340e-03]
 [  5.90000000e+02   2.27963366e-03]
 [  6.00000000e+02   2.14716047e-03]
 [  6.10000000e+02   2.08737608e-03]
 [  6.20000000e+02   2.13648169e-03]
 [  6.30000000e+02   2.13815179e-03]
 [  6.40000000e+02   2.05223053e-03]
 [  6.50000000e+02   2.01106723e-03]
 [  6.60000000e+02   1.91995234e-03]
 [  6.70000000e+02   1.76160154e-03]
 [  6.80000000e+02   1.85484381e-03]
 [  6.90000000e+02   1.97255495e-03]
 [  7.00000000e+02   1.70651078e-03]
 [  7.10000000e+02   1.88461086e-03]
 [  7.20000000e+02   1.70335767e-03]
 [  7.30000000e+02   1.80025818e-03]
 [  7.40000000e+02   1.68715953e-03]
 [  7.50000000e+02   1.77402410e-03]
 [  7.60000000e+02   1.70327176e-03]
 [  7.70000000e+02   1.41898636e-03]
 [  7.80000000e+02   1.58348947e-03]
 [  7.90000000e+02   1.49518612e-03]
 [  8.00000000e+02   1.61369739e-03]
 [  8.10000000e+02   1.56381121e-03]
 [  8.20000000e+02   1.47295301e-03]
 [  8.30000000e+02   1.40523014e-03]
 [  8.40000000e+02   1.51853869e-03]
 [  8.50000000e+02   1.41545769e-03]
 [  8.60000000e+02   1.40633876e-03]
 [  8.70000000e+02   1.40721502e-03]
 [  8.80000000e+02   1.44402531e-03]
 [  8.90000000e+02   1.35280937e-03]
 [  9.00000000e+02   1.30475138e-03]
 [  9.10000000e+02   1.18060503e-03]
 [  9.20000000e+02   1.21864316e-03]
 [  9.30000000e+02   1.16025214e-03]
 [  9.40000000e+02   1.11927034e-03]
 [  9.50000000e+02   1.15122611e-03]
 [  9.60000000e+02   1.16532680e-03]
 [  9.70000000e+02   1.10038300e-03]
 [  9.80000000e+02   1.11531548e-03]
 [  9.90000000e+02   1.06473512e-03]
 [  1.00000000e+03   9.09202558e-04]
 [  1.01000000e+03   9.82704572e-04]
 [  1.02000000e+03   8.44699505e-04]
 [  1.03000000e+03   1.06002251e-03]
 [  1.04000000e+03   8.57956009e-04]
 [  1.05000000e+03   9.75846197e-04]
 [  1.06000000e+03   7.20903976e-04]
 [  1.07000000e+03   7.87532656e-04]
 [  1.08000000e+03   7.56485038e-04]
 [  1.09000000e+03   8.10675905e-04]
 [  1.10000000e+03   7.82994204e-04]
 [  1.11000000e+03   7.42710545e-04]
 [  1.12000000e+03   7.58478651e-04]
 [  1.13000000e+03   6.89476670e-04]
 [  1.14000000e+03   7.75623543e-04]
 [  1.15000000e+03   8.26633302e-04]
 [  1.16000000e+03   7.54329725e-04]
 [  1.17000000e+03   6.65734347e-04]
 [  1.18000000e+03   6.63045328e-04]
 [  1.19000000e+03   5.99871622e-04]
 [  1.20000000e+03   6.29754737e-04]
 [  1.21000000e+03   6.21635932e-04]
 [  1.22000000e+03   6.09093928e-04]
 [  1.23000000e+03   6.96797506e-04]
 [  1.24000000e+03   6.34086144e-04]
 [  1.25000000e+03   5.88851282e-04]
 [  1.26000000e+03   5.61622961e-04]
 [  1.27000000e+03   5.66277420e-04]
 [  1.28000000e+03   5.84167545e-04]
 [  1.29000000e+03   5.67686686e-04]
 [  1.30000000e+03   4.93959873e-04]
 [  1.31000000e+03   5.15135878e-04]
 [  1.32000000e+03   5.48032112e-04]
 [  1.33000000e+03   5.50157274e-04]
 [  1.34000000e+03   4.93907020e-04]
 [  1.35000000e+03   5.06434822e-04]
 [  1.36000000e+03   4.97319154e-04]
 [  1.37000000e+03   5.32267790e-04]
 [  1.38000000e+03   4.90465784e-04]
 [  1.39000000e+03   4.95864253e-04]
 [  1.40000000e+03   4.51744156e-04]
 [  1.41000000e+03   3.92830931e-04]
 [  1.42000000e+03   4.15726972e-04]
 [  1.43000000e+03   4.15864051e-04]
 [  1.44000000e+03   4.12001042e-04]
 [  1.45000000e+03   4.28072293e-04]
 [  1.46000000e+03   4.31612571e-04]
 [  1.47000000e+03   4.16504656e-04]
 [  1.48000000e+03   4.23760532e-04]
 [  1.49000000e+03   3.68263485e-04]
 [  1.50000000e+03   3.97093594e-04]
 [  1.51000000e+03   3.88660294e-04]
 [  1.52000000e+03   3.71333765e-04]
 [  1.53000000e+03   4.28159459e-04]
 [  1.54000000e+03   3.64999840e-04]
 [  1.55000000e+03   3.54822056e-04]
 [  1.56000000e+03   3.82053840e-04]
 [  1.57000000e+03   3.53046868e-04]
 [  1.58000000e+03   3.46817600e-04]
 [  1.59000000e+03   3.41853272e-04]
 [  1.60000000e+03   2.92314449e-04]
 [  1.61000000e+03   3.53940530e-04]
 [  1.62000000e+03   3.55084398e-04]
 [  1.63000000e+03   3.28820839e-04]
 [  1.64000000e+03   3.24780645e-04]
 [  1.65000000e+03   2.97065097e-04]
 [  1.66000000e+03   3.46610206e-04]
 [  1.67000000e+03   3.08101909e-04]
 [  1.68000000e+03   3.24001623e-04]
 [  1.69000000e+03   3.48582224e-04]
 [  1.70000000e+03   3.35805118e-04]
 [  1.71000000e+03   3.15137731e-04]
 [  1.72000000e+03   3.22643289e-04]
 [  1.73000000e+03   3.46151821e-04]
 [  1.74000000e+03   2.88158306e-04]
 [  1.75000000e+03   3.39687249e-04]
 [  1.76000000e+03   2.94681406e-04]
 [  1.77000000e+03   3.23265238e-04]
 [  1.78000000e+03   3.02624132e-04]
 [  1.79000000e+03   3.10788688e-04]
 [  1.80000000e+03   2.77069630e-04]
 [  1.81000000e+03   2.93924619e-04]
 [  1.82000000e+03   2.98938365e-04]
 [  1.83000000e+03   2.82126595e-04]
 [  1.84000000e+03   2.89427087e-04]
 [  1.85000000e+03   3.01605993e-04]
 [  1.86000000e+03   2.60362867e-04]
 [  1.87000000e+03   2.92298326e-04]
 [  1.88000000e+03   3.03198060e-04]
 [  1.89000000e+03   2.90502037e-04]
 [  1.90000000e+03   2.65587005e-04]
 [  1.91000000e+03   2.92605313e-04]
 [  1.92000000e+03   2.72187113e-04]
 [  1.93000000e+03   2.64297007e-04]
 [  1.94000000e+03   2.82288995e-04]
 [  1.95000000e+03   2.58072774e-04]
 [  1.96000000e+03   2.83025118e-04]
 [  1.97000000e+03   2.69983837e-04]
 [  1.98000000e+03   2.57016305e-04]
 [  1.99000000e+03   2.58721790e-04]
 [  2.00000000e+03   2.58973945e-04]]
initial: [  0.00000000e+00   1.25333234e-01   2.48689887e-01   3.68124553e-01
   4.81753674e-01   5.87785252e-01   6.84547106e-01   7.70513243e-01
   8.44327926e-01   9.04827052e-01   9.51056516e-01   9.82287251e-01
   9.98026728e-01   9.98026728e-01   9.82287251e-01   9.51056516e-01
   9.04827052e-01   8.44327926e-01   7.70513243e-01   6.84547106e-01
   5.87785252e-01   4.81753674e-01   3.68124553e-01   2.48689887e-01
   1.25333234e-01  -3.21624530e-16  -1.25333234e-01  -2.48689887e-01
  -3.68124553e-01  -4.81753674e-01  -5.87785252e-01  -6.84547106e-01
  -7.70513243e-01  -8.44327926e-01  -9.04827052e-01  -9.51056516e-01
  -9.82287251e-01  -9.98026728e-01  -9.98026728e-01  -9.82287251e-01
  -9.51056516e-01  -9.04827052e-01  -8.44327926e-01  -7.70513243e-01
  -6.84547106e-01  -5.87785252e-01  -4.81753674e-01  -3.68124553e-01
  -2.48689887e-01  -1.25333234e-01]
prediction#1, output: 0.013113
prediction#2, output: 0.133540
prediction#3, output: 0.244523
prediction#4, output: 0.349302
prediction#5, output: 0.452466
prediction#6, output: 0.557272
prediction#7, output: 0.663860
prediction#8, output: 0.767836
prediction#9, output: 0.860386
prediction#10, output: 0.931543
prediction#11, output: 0.975275
prediction#12, output: 0.991897
prediction#13, output: 0.986086
prediction#14, output: 0.963490
prediction#15, output: 0.928675
prediction#16, output: 0.884616
prediction#17, output: 0.832915
prediction#18, output: 0.774157
prediction#19, output: 0.708212
prediction#20, output: 0.634440
prediction#21, output: 0.551863
prediction#22, output: 0.459344
prediction#23, output: 0.355851
prediction#24, output: 0.240855
prediction#25, output: 0.114877
prediction#26, output: -0.019947
prediction#27, output: -0.159594
prediction#28, output: -0.298535
prediction#29, output: -0.430859
prediction#30, output: -0.551597
prediction#31, output: -0.657520
prediction#32, output: -0.747127
prediction#33, output: -0.820146
prediction#34, output: -0.877029
prediction#35, output: -0.918620
prediction#36, output: -0.945956
prediction#37, output: -0.960110
prediction#38, output: -0.962052
prediction#39, output: -0.952523
prediction#40, output: -0.931935
prediction#41, output: -0.900303
prediction#42, output: -0.857197
prediction#43, output: -0.801734
prediction#44, output: -0.732645
prediction#45, output: -0.648506
prediction#46, output: -0.548280
prediction#47, output: -0.432308
prediction#48, output: -0.303589
prediction#49, output: -0.168454
prediction#50, output: -0.035146
prediction#51, output: 0.089766
prediction#52, output: 0.204376
prediction#53, output: 0.311214
prediction#54, output: 0.414769
prediction#55, output: 0.518982
prediction#56, output: 0.625305
prediction#57, output: 0.731080
prediction#58, output: 0.828896
prediction#59, output: 0.908654
prediction#60, output: 0.962436
prediction#61, output: 0.988339
prediction#62, output: 0.989883
prediction#63, output: 0.972688
prediction#64, output: 0.941824
prediction#65, output: 0.900825
prediction#66, output: 0.851738
prediction#67, output: 0.795473
prediction#68, output: 0.732125
prediction#69, output: 0.661217
prediction#70, output: 0.581873
prediction#71, output: 0.492989
prediction#72, output: 0.393459
prediction#73, output: 0.282524
prediction#74, output: 0.160269
prediction#75, output: 0.028208
prediction#76, output: -0.110296
prediction#77, output: -0.250149
prediction#78, output: -0.385422
prediction#79, output: -0.510683
prediction#80, output: -0.622057
prediction#81, output: -0.717476
prediction#82, output: -0.796299
prediction#83, output: -0.858771
prediction#84, output: -0.905624
prediction#85, output: -0.937845
prediction#86, output: -0.956511
prediction#87, output: -0.962644
prediction#88, output: -0.957076
prediction#89, output: -0.940346
prediction#90, output: -0.912614
prediction#91, output: -0.873610
prediction#92, output: -0.822607
prediction#93, output: -0.758457
prediction#94, output: -0.679747
prediction#95, output: -0.585217
prediction#96, output: -0.474585
prediction#97, output: -0.349781
prediction#98, output: -0.215996
prediction#99, output: -0.081131
prediction#100, output: 0.047208
outputs: [ 0.01311301  0.13354006  0.24452324  0.34930223  0.45246619  0.55727184
  0.66386026  0.76783603  0.86038578  0.93154269  0.97527504  0.9918974
  0.98608649  0.96348995  0.92867464  0.88461602  0.83291483  0.77415717
  0.7082116   0.63443953  0.55186272  0.45934409  0.35585111  0.24085523
  0.11487728 -0.01994736 -0.15959351 -0.29853466 -0.43085867 -0.55159652
 -0.65752041 -0.74712729 -0.82014614 -0.87702906 -0.91862017 -0.94595569
 -0.96010995 -0.9620524  -0.95252335 -0.93193537 -0.90030307 -0.85719675
 -0.80173373 -0.73264486 -0.64850599 -0.54828018 -0.43230787 -0.30358937
 -0.16845392 -0.03514604  0.08976635  0.20437618  0.31121379  0.41476923
  0.51898217  0.62530464  0.73108029  0.8288964   0.90865403  0.96243602
  0.98833936  0.98988253  0.97268844  0.94182438  0.90082508  0.85173845
  0.79547292  0.73212498  0.66121674  0.58187264  0.49298859  0.39345902
  0.28252417  0.16026904  0.02820768 -0.11029578 -0.25014931 -0.38542172
 -0.51068318 -0.6220569  -0.71747571 -0.7962988  -0.85877067 -0.90562367
 -0.93784469 -0.95651072 -0.96264356 -0.95707643 -0.9403463  -0.91261446
 -0.8736099  -0.82260698 -0.75845653 -0.67974657 -0.5852167  -0.47458458
 -0.34978139 -0.21599619 -0.08113085  0.04720839]

real	4m59.550s
user	2m55.480s
sys	4m22.494s
